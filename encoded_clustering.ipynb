{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-10T09:36:50.888936Z",
     "start_time": "2024-07-10T09:36:50.863821Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans, DBSCAN\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator, ClusterMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score, make_scorer, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.decomposition import PCA\n"
   ],
   "outputs": [],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T09:44:51.031467Z",
     "start_time": "2024-07-10T09:44:48.806856Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install umap",
   "id": "9879bb5161d9bb0c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting umap\r\n",
      "  Downloading umap-0.1.1.tar.gz (3.2 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hBuilding wheels for collected packages: umap\r\n",
      "  Building wheel for umap (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for umap: filename=umap-0.1.1-py3-none-any.whl size=3541 sha256=136cc31649c6bdf80ee7fb98c78234f44d4f89e06442d157c50cf793240b7f5d\r\n",
      "  Stored in directory: /Users/kimonanagnostopoulos/Library/Caches/pip/wheels/48/4a/1c/1d511cbb0413a448d8546e958f8e82b98d9bb493038d19ece2\r\n",
      "Successfully built umap\r\n",
      "Installing collected packages: umap\r\n",
      "Successfully installed umap-0.1.1\r\n"
     ]
    }
   ],
   "execution_count": 126
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T09:31:34.864492Z",
     "start_time": "2024-07-10T09:31:34.847682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "involvement_columns = ['Security', 'Humanities', 'Nat. Sci', 'Health', 'AI Ethics', 'Big Data', \n",
    "                           'Robotics', 'Documents', 'Multimedia', 'NLP', 'KRR', 'Graphs', 'DL/ML', \n",
    "                           'Funding', 'Application-Oriented', 'Number of Members', \n",
    "                           'Academic Collaborations', 'System Maturity', 'Demos', 'Industrial Collaborations']"
   ],
   "id": "1ffd804cbfcc54",
   "outputs": [],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T09:31:36.885344Z",
     "start_time": "2024-07-10T09:31:36.879599Z"
    }
   },
   "cell_type": "code",
   "source": "industry_cols = ['Security', 'Humanities', 'Nat. Sci', 'Health', 'AI Ethics', 'Big Data', 'Robotics', 'Documents', 'Multimedia', 'NLP', 'KRR', 'Graphs', 'DL/ML']",
   "id": "818397c956110c8",
   "outputs": [],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T09:31:37.817375Z",
     "start_time": "2024-07-10T09:31:37.811761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "comp_cols = ['Number of Members', 'Application-Oriented', 'Academic Collaborations', \n",
    "                      'System Maturity', 'Demos', 'Industrial Collaborations']"
   ],
   "id": "fccc870240c94fd3",
   "outputs": [],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T09:31:39.608753Z",
     "start_time": "2024-07-10T09:31:39.589859Z"
    }
   },
   "cell_type": "code",
   "source": [
    "feature_weights = {\n",
    "    'Security': 1.0, 'Humanities': 1.0, 'Nat. Sci': 1.0, 'Health': 1.0, 'AI Ethics': 1.0, 'Big Data': 1.0, 'Robotics': 1.0, \n",
    "    'Documents': 1.0, 'Multimedia': 1.0, 'NLP': 1.0, 'KRR': 1.0, 'Graphs': 1.0, 'DL/ML': 1.0, \n",
    "    'Number of Members': 0.5, 'Application-Oriented': 0.5, 'Academic Collaborations': 0.5, 'System Maturity': 0.5, \n",
    "    'Demos': 0.5, 'Industrial Collaborations': 0.5\n",
    "}"
   ],
   "id": "8ef12a5f45f7560d",
   "outputs": [],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T09:31:43.043049Z",
     "start_time": "2024-07-10T09:31:43.033425Z"
    }
   },
   "cell_type": "code",
   "source": "weights = {'Strong': 3, 'Good': 2, 'Average': 1, 'None': 0}",
   "id": "1262eacd8d6fb1f8",
   "outputs": [],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T11:20:43.375216Z",
     "start_time": "2024-07-10T11:20:43.362450Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_and_preprocess_data(file_path):\n",
    "    data = pd.read_csv(file_path, index_col=0).transpose()\n",
    "    for column in involvement_columns:\n",
    "        if column in data.columns:\n",
    "            data[column] = data[column].map(weights).fillna(0)\n",
    "    return data"
   ],
   "id": "39694507271f9e98",
   "outputs": [],
   "execution_count": 215
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T09:31:46.153573Z",
     "start_time": "2024-07-10T09:31:46.114129Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def assign_weights(data):\n",
    "    for column, weight in feature_weights.items():\n",
    "        if column in data.columns:\n",
    "            data[column] = data[column]*weight"
   ],
   "id": "5cbaa5839cffc193",
   "outputs": [],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T11:20:54.925614Z",
     "start_time": "2024-07-10T11:20:54.917358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def standardize_data(data):\n",
    "    scaler = StandardScaler()\n",
    "    return pd.DataFrame(scaler.fit_transform(data), columns=data.columns, index=data.index)"
   ],
   "id": "15218cb0ed324409",
   "outputs": [],
   "execution_count": 216
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T09:54:46.202309Z",
     "start_time": "2024-07-10T09:54:44.281730Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, LeakyReLU, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model"
   ],
   "id": "b334d7fdd0e6cfa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/kimonanagnostopoulos/miniconda3/lib/python3.12/site-packages (2.16.2)\r\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/kimonanagnostopoulos/miniconda3/lib/python3.12/site-packages (from tensorflow) (2.1.0)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/kimonanagnostopoulos/miniconda3/lib/python3.12/site-packages (from tensorflow) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/kimonanagnostopoulos/miniconda3/lib/python3.12/site-packages (from tensorflow) (24.3.25)\r\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/kimonanagnostopoulos/miniconda3/lib/python3.12/site-packages (from tensorflow) (0.6.0)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/kimonanagnostopoulos/miniconda3/lib/python3.12/site-packages (from tensorflow) (0.2.0)\r\n",
      "Requirement already satisfied: h5py>=3.10.0 in /Users/kimonanagnostopoulos/miniconda3/lib/python3.12/site-packages (from tensorflow) (3.11.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/kimonanagnostopoulos/miniconda3/lib/python3.12/site-packages (from tensorflow) (18.1.1)\r\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /Users/kimonanagnostopoulos/miniconda3/lib/python3.12/site-packages (from tensorflow) (0.3.2)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/kimonanagnostopoulos/miniconda3/lib/python3.12/site-packages (from tensorflow) (3.3.0)\r\n",
      "Requirement already satisfied: packaging in /Users/kimonanagnostopoulos/miniconda3/lib/python3.12/site-packages (from tensorflow) (23.1)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/kimonanagnostopoulos/miniconda3/lib/python3.12/site-packages (from tensorflow) (4.25.3)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/kimonanagnostopoulos/miniconda3/lib/python3.12/site-packages (from tensorflow) (2.31.0)\r\n",
      "Requirement already satisfied: setuptools in /Users/kimonanagnostopoulos/miniconda3/lib/python3.12/site-packages (from tensorflow) (68.2.2)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/kimonanagnostopoulos/miniconda3/lib/python3.12/site-packages (from tensorflow) (1.16.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/kimonanagnostopoulos/miniconda3/lib/python3.12/site-packages (from tensorflow) (2.4.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/kimonanagnostopoulos/miniconda3/lib/python3.12/site-packages (from tensorflow) (4.12.2)\r\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/kimonanagnostopoulos/miniconda3/lib/python3.12/site-packages (from tensorflow) (1.16.0)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/kimonanagnostopoulos/miniconda3/lib/python3.12/site-packages (from tensorflow) (1.64.1)\r\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /Users/kimonanagnostopoulos/miniconda3/lib/python3.12/site-packages (from tensorflow) (2.16.2)\r\n",
      "Requirement already satisfied: keras>=3.0.0 in /Users/kimonanagnostopoulos/miniconda3/lib/python3.12/site-packages (from tensorflow) (3.4.1)\r\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /Users/kimonanagnostopoulos/miniconda3/lib/python3.12/site-packages (from tensorflow) (1.26.4)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/kimonanagnostopoulos/miniconda3/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\r\n",
      "Requirement already satisfied: rich in /Users/kimonanagnostopoulos/miniconda3/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow) (13.7.1)\r\n",
      "Requirement already satisfied: namex in /Users/kimonanagnostopoulos/miniconda3/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow) (0.0.8)\r\n",
      "Requirement already satisfied: optree in /Users/kimonanagnostopoulos/miniconda3/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow) (0.12.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kimonanagnostopoulos/miniconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kimonanagnostopoulos/miniconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/kimonanagnostopoulos/miniconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.1.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kimonanagnostopoulos/miniconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/kimonanagnostopoulos/miniconda3/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/kimonanagnostopoulos/miniconda3/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/kimonanagnostopoulos/miniconda3/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/kimonanagnostopoulos/miniconda3/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/kimonanagnostopoulos/miniconda3/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/kimonanagnostopoulos/miniconda3/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow) (2.17.2)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/kimonanagnostopoulos/miniconda3/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\r\n"
     ]
    }
   ],
   "execution_count": 136
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Hyperparameter Optimization\n",
    "-Adjusting encoding dimension\n",
    "-Learning Rate and Epochs\n",
    "-Additional Layers"
   ],
   "id": "8b2fcbad7e4d4943"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T11:27:33.363793Z",
     "start_time": "2024-07-10T11:27:33.349217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_autoencoder(input_dim, encoding_dim, layer_sizes, dropout_rate=0.2):\n",
    "    input_layer = Input(shape=(input_dim,), name='input_layer')\n",
    "    x = input_layer\n",
    "    \n",
    "    # Add encoder layers\n",
    "    for size in layer_sizes:\n",
    "        x = Dense(size)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    encoded = Dense(encoding_dim, activation='relu', name='encoded_layer')(x)\n",
    "    \n",
    "    # Add decoder layers (reverse of encoder)\n",
    "    for size in reversed(layer_sizes):\n",
    "        x = Dense(size)(encoded)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    decoded = Dense(input_dim, activation='sigmoid')(x)\n",
    "    \n",
    "    autoencoder = Model(inputs=input_layer, outputs=decoded)\n",
    "    autoencoder.compile(optimizer=Adam(), loss='mean_squared_error')\n",
    "    \n",
    "    return autoencoder\n"
   ],
   "id": "5d55abf7502e12cc",
   "outputs": [],
   "execution_count": 235
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T11:22:30.085030Z",
     "start_time": "2024-07-10T11:22:30.071158Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_autoencoder(autoencoder, data, epochs=50, batch_size=32):\n",
    "    print(f\"Data shape: {data.shape}\")\n",
    "    autoencoder.fit(data, data, epochs=epochs, batch_size=batch_size, shuffle=True, verbose=2)\n"
   ],
   "id": "6c187d5c382e14e0",
   "outputs": [],
   "execution_count": 219
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T11:22:40.399988Z",
     "start_time": "2024-07-10T11:22:40.385098Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_encoded_data(autoencoder, data):\n",
    "    encoder_model = Model(inputs=autoencoder.input, outputs=autoencoder.get_layer('encoded_layer').output)\n",
    "    return encoder_model.predict(data)\n"
   ],
   "id": "7bc294711ee29cbb",
   "outputs": [],
   "execution_count": 220
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T11:22:48.174523Z",
     "start_time": "2024-07-10T11:22:48.162433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def apply_agglomerative_clustering(data, n_clusters):\n",
    "    clustering = AgglomerativeClustering(n_clusters=n_clusters)\n",
    "    return clustering.fit_predict(data)"
   ],
   "id": "439a9e0fff6c923",
   "outputs": [],
   "execution_count": 221
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T11:22:57.858701Z",
     "start_time": "2024-07-10T11:22:57.845850Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def apply_kmeans_clustering(data, n_clusters):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, init='k-means++', random_state=42)\n",
    "    kmeans.fit(data)\n",
    "    return kmeans.labels_"
   ],
   "id": "2cd54c922d5f36db",
   "outputs": [],
   "execution_count": 222
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T11:23:05.172627Z",
     "start_time": "2024-07-10T11:23:05.143346Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def apply_dbscan_clustering(data, eps, min_samples):\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "    return dbscan.fit_predict(data)"
   ],
   "id": "7ad4ebcde6339115",
   "outputs": [],
   "execution_count": 223
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T11:23:12.993073Z",
     "start_time": "2024-07-10T11:23:12.978541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_clustering(data, labels):\n",
    "    silhouette_avg = silhouette_score(data, labels)\n",
    "    davies_bouldin = davies_bouldin_score(data, labels)\n",
    "    return silhouette_avg, davies_bouldin"
   ],
   "id": "94adc84dc30eddc3",
   "outputs": [],
   "execution_count": 224
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T11:23:22.254443Z",
     "start_time": "2024-07-10T11:23:22.239677Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def find_optimal_clusters(data, clustering_func, cluster_range):\n",
    "    best_score = -1\n",
    "    best_n_clusters = 0\n",
    "    for n_clusters in cluster_range:\n",
    "        labels = clustering_func(data, n_clusters)\n",
    "        silhouette_avg = silhouette_score(data, labels)\n",
    "        if silhouette_avg > best_score:\n",
    "            best_score = silhouette_avg\n",
    "            best_n_clusters = n_clusters\n",
    "    return best_n_clusters"
   ],
   "id": "a14d266ac37a25b3",
   "outputs": [],
   "execution_count": 225
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T11:23:47.415982Z",
     "start_time": "2024-07-10T11:23:47.400352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def visualize_clusters(data, labels, method='pca'):\n",
    "    if method == 'pca':\n",
    "        reducer = PCA(n_components=2)\n",
    "    elif method == 'tsne':\n",
    "        from sklearn.manifold import TSNE\n",
    "        reducer = TSNE(n_components=2, random_state=42)\n",
    "    else:\n",
    "        raise ValueError(\"Method not recognized: choose 'pca', or 'tsne'\")\n",
    "        \n",
    "    reduced_data = reducer.fit_transform(data)\n",
    "    plt.scatter(reduced_data[:, 0], reduced_data[:, 1], c=labels, cmap='viridis')\n",
    "    plt.title(f'Clusters visualization using {method.upper()}')\n",
    "    plt.show()"
   ],
   "id": "6288e2e78d126a14",
   "outputs": [],
   "execution_count": 226
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T11:59:27.952490Z",
     "start_time": "2024-07-10T11:59:27.846385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Main execution\n",
    "filepath = 'data/synthetic_data.csv'\n",
    "\n",
    "# Load and preprocess data\n",
    "dfs = load_and_preprocess_data(filepath)\n",
    "assign_weights(dfs)\n",
    "df_scaled = standardize_data(dfs)\n",
    "input_dim = df_scaled.shape[1]"
   ],
   "id": "54a6cde770010eb4",
   "outputs": [],
   "execution_count": 261
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T11:24:53.025904Z",
     "start_time": "2024-07-10T11:24:52.992090Z"
    }
   },
   "cell_type": "code",
   "source": "df_scaled",
   "id": "3ac4ce41aedfb7ff",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Field                         Security  Humanities  Nat. Sci    Health  \\\n",
       "Hall, Nelson and Parks       -0.448676    1.977899 -0.470697 -0.688054   \n",
       "Krueger LLC                   0.790760   -0.905336  2.940148 -0.688054   \n",
       "Lewis Ltd                    -0.448676   -0.905336 -0.470697 -0.688054   \n",
       "Simpson Group                -0.448676   -0.905336  2.940148 -0.688054   \n",
       "Campbell, Gonzalez and Perez  3.269633   -0.905336  1.234726 -0.688054   \n",
       "...                                ...         ...       ...       ...   \n",
       "Hill and Sons                -0.448676   -0.905336 -0.470697 -0.688054   \n",
       "Anderson, Thomas and Miller  -0.448676   -0.905336 -0.470697 -0.688054   \n",
       "Williams PLC                 -0.448676   -0.905336 -0.470697 -0.688054   \n",
       "Williams-Beard               -0.448676   -0.905336 -0.470697  1.040725   \n",
       "Richardson-Fowler            -0.448676   -0.905336 -0.470697  1.040725   \n",
       "\n",
       "Field                         AI Ethics  Big Data  Robotics  Documents  \\\n",
       "Hall, Nelson and Parks        -0.706794 -0.224874 -0.302825   2.124205   \n",
       "Krueger LLC                   -0.706794 -1.079909  3.302236  -0.526633   \n",
       "Lewis Ltd                     -0.706794 -0.224874 -0.302825  -0.526633   \n",
       "Simpson Group                 -0.706794  1.485195 -0.302825   1.240593   \n",
       "Campbell, Gonzalez and Perez  -0.706794 -0.224874 -0.302825  -0.526633   \n",
       "...                                 ...       ...       ...        ...   \n",
       "Hill and Sons                 -0.706794  1.485195 -0.302825   2.124205   \n",
       "Anderson, Thomas and Miller   -0.706794  0.630161 -0.302825  -0.526633   \n",
       "Williams PLC                   1.175481 -1.079909 -0.302825   1.240593   \n",
       "Williams-Beard                 1.175481 -1.079909 -0.302825  -0.526633   \n",
       "Richardson-Fowler             -0.706794 -1.079909 -0.302825  -0.526633   \n",
       "\n",
       "Field                         Multimedia       NLP       KRR    Graphs  \\\n",
       "Hall, Nelson and Parks         -0.539798 -0.723123 -1.325477 -0.586008   \n",
       "Krueger LLC                    -0.539798 -0.723123  0.766831 -0.586008   \n",
       "Lewis Ltd                      -0.539798  1.799400  0.766831 -0.586008   \n",
       "Simpson Group                  -0.539798  0.958559 -1.325477 -0.586008   \n",
       "Campbell, Gonzalez and Perez   -0.539798  1.799400 -0.279323 -0.586008   \n",
       "...                                  ...       ...       ...       ...   \n",
       "Hill and Sons                  -0.539798 -0.723123 -0.279323 -0.586008   \n",
       "Anderson, Thomas and Miller    -0.539798  0.958559 -1.325477 -0.586008   \n",
       "Williams PLC                   -0.539798 -0.723123  0.766831 -0.586008   \n",
       "Williams-Beard                 -0.539798 -0.723123  0.766831  1.434709   \n",
       "Richardson-Fowler              -0.539798  1.799400 -1.325477 -0.586008   \n",
       "\n",
       "Field                            DL/ML   Funding  Application-Oriented  \\\n",
       "Hall, Nelson and Parks        0.444830  0.458095             -0.251883   \n",
       "Krueger LLC                  -0.566148 -1.207704              0.848042   \n",
       "Lewis Ltd                    -0.566148 -1.207704             -0.251883   \n",
       "Simpson Group                 1.455809 -1.207704             -0.251883   \n",
       "Campbell, Gonzalez and Perez  0.444830  1.290994              0.848042   \n",
       "...                                ...       ...                   ...   \n",
       "Hill and Sons                -0.566148 -1.207704             -1.351808   \n",
       "Anderson, Thomas and Miller  -1.577126  0.458095             -2.451733   \n",
       "Williams PLC                  0.444830  1.290994              0.848042   \n",
       "Williams-Beard                1.455809 -0.374805              0.848042   \n",
       "Richardson-Fowler            -1.577126  1.290994             -0.251883   \n",
       "\n",
       "Field                         Number of Members  Academic Collaborations  \\\n",
       "Hall, Nelson and Parks                 1.343749                 1.155235   \n",
       "Krueger LLC                            0.084378                 1.155235   \n",
       "Lewis Ltd                              1.343749                 1.155235   \n",
       "Simpson Group                          0.084378                 1.155235   \n",
       "Campbell, Gonzalez and Perez           0.084378                 1.155235   \n",
       "...                                         ...                      ...   \n",
       "Hill and Sons                         -1.174993                 1.155235   \n",
       "Anderson, Thomas and Miller           -1.174993                 1.155235   \n",
       "Williams PLC                          -1.174993                 1.155235   \n",
       "Williams-Beard                         0.084378                 1.155235   \n",
       "Richardson-Fowler                      1.343749                 1.155235   \n",
       "\n",
       "Field                         System Maturity     Demos  \\\n",
       "Hall, Nelson and Parks               1.042366  1.202662   \n",
       "Krueger LLC                         -0.171098  0.029333   \n",
       "Lewis Ltd                            1.042366  1.202662   \n",
       "Simpson Group                       -2.598027 -1.143995   \n",
       "Campbell, Gonzalez and Perez        -0.171098 -1.143995   \n",
       "...                                       ...       ...   \n",
       "Hill and Sons                        1.042366 -1.143995   \n",
       "Anderson, Thomas and Miller         -0.171098  0.029333   \n",
       "Williams PLC                        -0.171098  0.029333   \n",
       "Williams-Beard                      -0.171098 -1.143995   \n",
       "Richardson-Fowler                    1.042366 -1.143995   \n",
       "\n",
       "Field                         Industrial Collaborations  \n",
       "Hall, Nelson and Parks                        -0.154439  \n",
       "Krueger LLC                                   -0.154439  \n",
       "Lewis Ltd                                      1.918574  \n",
       "Simpson Group                                 -1.190946  \n",
       "Campbell, Gonzalez and Perez                  -0.154439  \n",
       "...                                                 ...  \n",
       "Hill and Sons                                 -0.154439  \n",
       "Anderson, Thomas and Miller                   -1.190946  \n",
       "Williams PLC                                  -0.154439  \n",
       "Williams-Beard                                 0.882067  \n",
       "Richardson-Fowler                              0.882067  \n",
       "\n",
       "[1000 rows x 20 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Field</th>\n",
       "      <th>Security</th>\n",
       "      <th>Humanities</th>\n",
       "      <th>Nat. Sci</th>\n",
       "      <th>Health</th>\n",
       "      <th>AI Ethics</th>\n",
       "      <th>Big Data</th>\n",
       "      <th>Robotics</th>\n",
       "      <th>Documents</th>\n",
       "      <th>Multimedia</th>\n",
       "      <th>NLP</th>\n",
       "      <th>KRR</th>\n",
       "      <th>Graphs</th>\n",
       "      <th>DL/ML</th>\n",
       "      <th>Funding</th>\n",
       "      <th>Application-Oriented</th>\n",
       "      <th>Number of Members</th>\n",
       "      <th>Academic Collaborations</th>\n",
       "      <th>System Maturity</th>\n",
       "      <th>Demos</th>\n",
       "      <th>Industrial Collaborations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Hall, Nelson and Parks</th>\n",
       "      <td>-0.448676</td>\n",
       "      <td>1.977899</td>\n",
       "      <td>-0.470697</td>\n",
       "      <td>-0.688054</td>\n",
       "      <td>-0.706794</td>\n",
       "      <td>-0.224874</td>\n",
       "      <td>-0.302825</td>\n",
       "      <td>2.124205</td>\n",
       "      <td>-0.539798</td>\n",
       "      <td>-0.723123</td>\n",
       "      <td>-1.325477</td>\n",
       "      <td>-0.586008</td>\n",
       "      <td>0.444830</td>\n",
       "      <td>0.458095</td>\n",
       "      <td>-0.251883</td>\n",
       "      <td>1.343749</td>\n",
       "      <td>1.155235</td>\n",
       "      <td>1.042366</td>\n",
       "      <td>1.202662</td>\n",
       "      <td>-0.154439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Krueger LLC</th>\n",
       "      <td>0.790760</td>\n",
       "      <td>-0.905336</td>\n",
       "      <td>2.940148</td>\n",
       "      <td>-0.688054</td>\n",
       "      <td>-0.706794</td>\n",
       "      <td>-1.079909</td>\n",
       "      <td>3.302236</td>\n",
       "      <td>-0.526633</td>\n",
       "      <td>-0.539798</td>\n",
       "      <td>-0.723123</td>\n",
       "      <td>0.766831</td>\n",
       "      <td>-0.586008</td>\n",
       "      <td>-0.566148</td>\n",
       "      <td>-1.207704</td>\n",
       "      <td>0.848042</td>\n",
       "      <td>0.084378</td>\n",
       "      <td>1.155235</td>\n",
       "      <td>-0.171098</td>\n",
       "      <td>0.029333</td>\n",
       "      <td>-0.154439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lewis Ltd</th>\n",
       "      <td>-0.448676</td>\n",
       "      <td>-0.905336</td>\n",
       "      <td>-0.470697</td>\n",
       "      <td>-0.688054</td>\n",
       "      <td>-0.706794</td>\n",
       "      <td>-0.224874</td>\n",
       "      <td>-0.302825</td>\n",
       "      <td>-0.526633</td>\n",
       "      <td>-0.539798</td>\n",
       "      <td>1.799400</td>\n",
       "      <td>0.766831</td>\n",
       "      <td>-0.586008</td>\n",
       "      <td>-0.566148</td>\n",
       "      <td>-1.207704</td>\n",
       "      <td>-0.251883</td>\n",
       "      <td>1.343749</td>\n",
       "      <td>1.155235</td>\n",
       "      <td>1.042366</td>\n",
       "      <td>1.202662</td>\n",
       "      <td>1.918574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Simpson Group</th>\n",
       "      <td>-0.448676</td>\n",
       "      <td>-0.905336</td>\n",
       "      <td>2.940148</td>\n",
       "      <td>-0.688054</td>\n",
       "      <td>-0.706794</td>\n",
       "      <td>1.485195</td>\n",
       "      <td>-0.302825</td>\n",
       "      <td>1.240593</td>\n",
       "      <td>-0.539798</td>\n",
       "      <td>0.958559</td>\n",
       "      <td>-1.325477</td>\n",
       "      <td>-0.586008</td>\n",
       "      <td>1.455809</td>\n",
       "      <td>-1.207704</td>\n",
       "      <td>-0.251883</td>\n",
       "      <td>0.084378</td>\n",
       "      <td>1.155235</td>\n",
       "      <td>-2.598027</td>\n",
       "      <td>-1.143995</td>\n",
       "      <td>-1.190946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Campbell, Gonzalez and Perez</th>\n",
       "      <td>3.269633</td>\n",
       "      <td>-0.905336</td>\n",
       "      <td>1.234726</td>\n",
       "      <td>-0.688054</td>\n",
       "      <td>-0.706794</td>\n",
       "      <td>-0.224874</td>\n",
       "      <td>-0.302825</td>\n",
       "      <td>-0.526633</td>\n",
       "      <td>-0.539798</td>\n",
       "      <td>1.799400</td>\n",
       "      <td>-0.279323</td>\n",
       "      <td>-0.586008</td>\n",
       "      <td>0.444830</td>\n",
       "      <td>1.290994</td>\n",
       "      <td>0.848042</td>\n",
       "      <td>0.084378</td>\n",
       "      <td>1.155235</td>\n",
       "      <td>-0.171098</td>\n",
       "      <td>-1.143995</td>\n",
       "      <td>-0.154439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hill and Sons</th>\n",
       "      <td>-0.448676</td>\n",
       "      <td>-0.905336</td>\n",
       "      <td>-0.470697</td>\n",
       "      <td>-0.688054</td>\n",
       "      <td>-0.706794</td>\n",
       "      <td>1.485195</td>\n",
       "      <td>-0.302825</td>\n",
       "      <td>2.124205</td>\n",
       "      <td>-0.539798</td>\n",
       "      <td>-0.723123</td>\n",
       "      <td>-0.279323</td>\n",
       "      <td>-0.586008</td>\n",
       "      <td>-0.566148</td>\n",
       "      <td>-1.207704</td>\n",
       "      <td>-1.351808</td>\n",
       "      <td>-1.174993</td>\n",
       "      <td>1.155235</td>\n",
       "      <td>1.042366</td>\n",
       "      <td>-1.143995</td>\n",
       "      <td>-0.154439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anderson, Thomas and Miller</th>\n",
       "      <td>-0.448676</td>\n",
       "      <td>-0.905336</td>\n",
       "      <td>-0.470697</td>\n",
       "      <td>-0.688054</td>\n",
       "      <td>-0.706794</td>\n",
       "      <td>0.630161</td>\n",
       "      <td>-0.302825</td>\n",
       "      <td>-0.526633</td>\n",
       "      <td>-0.539798</td>\n",
       "      <td>0.958559</td>\n",
       "      <td>-1.325477</td>\n",
       "      <td>-0.586008</td>\n",
       "      <td>-1.577126</td>\n",
       "      <td>0.458095</td>\n",
       "      <td>-2.451733</td>\n",
       "      <td>-1.174993</td>\n",
       "      <td>1.155235</td>\n",
       "      <td>-0.171098</td>\n",
       "      <td>0.029333</td>\n",
       "      <td>-1.190946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Williams PLC</th>\n",
       "      <td>-0.448676</td>\n",
       "      <td>-0.905336</td>\n",
       "      <td>-0.470697</td>\n",
       "      <td>-0.688054</td>\n",
       "      <td>1.175481</td>\n",
       "      <td>-1.079909</td>\n",
       "      <td>-0.302825</td>\n",
       "      <td>1.240593</td>\n",
       "      <td>-0.539798</td>\n",
       "      <td>-0.723123</td>\n",
       "      <td>0.766831</td>\n",
       "      <td>-0.586008</td>\n",
       "      <td>0.444830</td>\n",
       "      <td>1.290994</td>\n",
       "      <td>0.848042</td>\n",
       "      <td>-1.174993</td>\n",
       "      <td>1.155235</td>\n",
       "      <td>-0.171098</td>\n",
       "      <td>0.029333</td>\n",
       "      <td>-0.154439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Williams-Beard</th>\n",
       "      <td>-0.448676</td>\n",
       "      <td>-0.905336</td>\n",
       "      <td>-0.470697</td>\n",
       "      <td>1.040725</td>\n",
       "      <td>1.175481</td>\n",
       "      <td>-1.079909</td>\n",
       "      <td>-0.302825</td>\n",
       "      <td>-0.526633</td>\n",
       "      <td>-0.539798</td>\n",
       "      <td>-0.723123</td>\n",
       "      <td>0.766831</td>\n",
       "      <td>1.434709</td>\n",
       "      <td>1.455809</td>\n",
       "      <td>-0.374805</td>\n",
       "      <td>0.848042</td>\n",
       "      <td>0.084378</td>\n",
       "      <td>1.155235</td>\n",
       "      <td>-0.171098</td>\n",
       "      <td>-1.143995</td>\n",
       "      <td>0.882067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Richardson-Fowler</th>\n",
       "      <td>-0.448676</td>\n",
       "      <td>-0.905336</td>\n",
       "      <td>-0.470697</td>\n",
       "      <td>1.040725</td>\n",
       "      <td>-0.706794</td>\n",
       "      <td>-1.079909</td>\n",
       "      <td>-0.302825</td>\n",
       "      <td>-0.526633</td>\n",
       "      <td>-0.539798</td>\n",
       "      <td>1.799400</td>\n",
       "      <td>-1.325477</td>\n",
       "      <td>-0.586008</td>\n",
       "      <td>-1.577126</td>\n",
       "      <td>1.290994</td>\n",
       "      <td>-0.251883</td>\n",
       "      <td>1.343749</td>\n",
       "      <td>1.155235</td>\n",
       "      <td>1.042366</td>\n",
       "      <td>-1.143995</td>\n",
       "      <td>0.882067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 20 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 230
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T11:25:11.501415Z",
     "start_time": "2024-07-10T11:25:11.491383Z"
    }
   },
   "cell_type": "code",
   "source": "input_dim",
   "id": "6285a2e3acbf6242",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 231
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T11:28:35.602905Z",
     "start_time": "2024-07-10T11:28:35.594057Z"
    }
   },
   "cell_type": "code",
   "source": [
    "layer_configurations = [\n",
    "    [64, 32],\n",
    "    [128, 64, 32],\n",
    "    [256, 128, 64, 32],\n",
    "    [128, 64]\n",
    "]"
   ],
   "id": "8c2516c472c6c6a6",
   "outputs": [],
   "execution_count": 238
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T11:28:39.717421Z",
     "start_time": "2024-07-10T11:28:39.710528Z"
    }
   },
   "cell_type": "code",
   "source": [
    "encoding_dims = [8, 10, 12]\n",
    "batch_sizes = [32, 64, 128]\n",
    "epochs_list = [50, 100]\n",
    "dropout_rates = [0.2, 0.3]\n",
    "\n",
    "best_params = None\n",
    "best_score = -1\n"
   ],
   "id": "6183aeb3552c0310",
   "outputs": [],
   "execution_count": 240
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T11:44:02.489628Z",
     "start_time": "2024-07-10T11:28:40.955372Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for layer_sizes in layer_configurations:\n",
    "    for encoding_dim in encoding_dims:\n",
    "        for batch_size in batch_sizes:\n",
    "            for epochs in epochs_list:\n",
    "                for dropout_rate in dropout_rates:\n",
    "                    print(f\"Testing with layers={layer_sizes}, encoding_dim={encoding_dim}, batch_size={batch_size}, epochs={epochs}, dropout_rate={dropout_rate}\")\n",
    "                    \n",
    "                    autoencoder = create_autoencoder(input_dim, encoding_dim, layer_sizes, dropout_rate)\n",
    "                    train_autoencoder(autoencoder, df_scaled, epochs=epochs, batch_size=batch_size)\n",
    "                    encoded_data = get_encoded_data(autoencoder, df_scaled)\n",
    "                    \n",
    "                    optimal_clusters_kmeans = find_optimal_clusters(encoded_data, apply_kmeans_clustering, range(2, 11))\n",
    "                    best_labels_kmeans = apply_kmeans_clustering(encoded_data, optimal_clusters_kmeans)\n",
    "                    silhouette_avg_kmeans, davies_bouldin_kmeans = evaluate_clustering(encoded_data, best_labels_kmeans)\n",
    "                    \n",
    "                    if silhouette_avg_kmeans > best_score:\n",
    "                        best_score = silhouette_avg_kmeans\n",
    "                        best_params = {\n",
    "                            'layer_sizes': layer_sizes,\n",
    "                            'encoding_dim': encoding_dim,\n",
    "                            'batch_size': batch_size,\n",
    "                            'epochs': epochs,\n",
    "                            'dropout_rate': dropout_rate\n",
    "                        }\n",
    "                        print(f\"New best score: {best_score} with params: {best_params}\")\n",
    "\n",
    "print(f\"Best parameters found: {best_params} with silhouette score: {best_score}\")"
   ],
   "id": "291f0d3e435aba0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with layers=[64, 32], encoding_dim=8, batch_size=32, epochs=50, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "32/32 - 2s - 52ms/step - loss: 1.2038\n",
      "Epoch 2/50\n",
      "32/32 - 0s - 2ms/step - loss: 1.0818\n",
      "Epoch 3/50\n",
      "32/32 - 0s - 2ms/step - loss: 1.0112\n",
      "Epoch 4/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.9653\n",
      "Epoch 5/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.9350\n",
      "Epoch 6/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.9124\n",
      "Epoch 7/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8975\n",
      "Epoch 8/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8858\n",
      "Epoch 9/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8733\n",
      "Epoch 10/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8628\n",
      "Epoch 11/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8528\n",
      "Epoch 12/50\n",
      "32/32 - 0s - 897us/step - loss: 0.8455\n",
      "Epoch 13/50\n",
      "32/32 - 0s - 958us/step - loss: 0.8372\n",
      "Epoch 14/50\n",
      "32/32 - 0s - 927us/step - loss: 0.8344\n",
      "Epoch 15/50\n",
      "32/32 - 0s - 908us/step - loss: 0.8283\n",
      "Epoch 16/50\n",
      "32/32 - 0s - 858us/step - loss: 0.8215\n",
      "Epoch 17/50\n",
      "32/32 - 0s - 880us/step - loss: 0.8220\n",
      "Epoch 18/50\n",
      "32/32 - 0s - 899us/step - loss: 0.8156\n",
      "Epoch 19/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8109\n",
      "Epoch 20/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8072\n",
      "Epoch 21/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8053\n",
      "Epoch 22/50\n",
      "32/32 - 0s - 964us/step - loss: 0.7989\n",
      "Epoch 23/50\n",
      "32/32 - 0s - 866us/step - loss: 0.7971\n",
      "Epoch 24/50\n",
      "32/32 - 0s - 866us/step - loss: 0.7962\n",
      "Epoch 25/50\n",
      "32/32 - 0s - 994us/step - loss: 0.7944\n",
      "Epoch 26/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7907\n",
      "Epoch 27/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7888\n",
      "Epoch 28/50\n",
      "32/32 - 0s - 896us/step - loss: 0.7853\n",
      "Epoch 29/50\n",
      "32/32 - 0s - 968us/step - loss: 0.7849\n",
      "Epoch 30/50\n",
      "32/32 - 0s - 880us/step - loss: 0.7826\n",
      "Epoch 31/50\n",
      "32/32 - 0s - 973us/step - loss: 0.7805\n",
      "Epoch 32/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7779\n",
      "Epoch 33/50\n",
      "32/32 - 0s - 888us/step - loss: 0.7789\n",
      "Epoch 34/50\n",
      "32/32 - 0s - 870us/step - loss: 0.7745\n",
      "Epoch 35/50\n",
      "32/32 - 0s - 887us/step - loss: 0.7719\n",
      "Epoch 36/50\n",
      "32/32 - 0s - 865us/step - loss: 0.7693\n",
      "Epoch 37/50\n",
      "32/32 - 0s - 880us/step - loss: 0.7698\n",
      "Epoch 38/50\n",
      "32/32 - 0s - 837us/step - loss: 0.7677\n",
      "Epoch 39/50\n",
      "32/32 - 0s - 939us/step - loss: 0.7698\n",
      "Epoch 40/50\n",
      "32/32 - 0s - 861us/step - loss: 0.7670\n",
      "Epoch 41/50\n",
      "32/32 - 0s - 864us/step - loss: 0.7671\n",
      "Epoch 42/50\n",
      "32/32 - 0s - 857us/step - loss: 0.7641\n",
      "Epoch 43/50\n",
      "32/32 - 0s - 878us/step - loss: 0.7634\n",
      "Epoch 44/50\n",
      "32/32 - 0s - 861us/step - loss: 0.7619\n",
      "Epoch 45/50\n",
      "32/32 - 0s - 878us/step - loss: 0.7628\n",
      "Epoch 46/50\n",
      "32/32 - 0s - 848us/step - loss: 0.7611\n",
      "Epoch 47/50\n",
      "32/32 - 0s - 891us/step - loss: 0.7591\n",
      "Epoch 48/50\n",
      "32/32 - 0s - 855us/step - loss: 0.7552\n",
      "Epoch 49/50\n",
      "32/32 - 0s - 855us/step - loss: 0.7570\n",
      "Epoch 50/50\n",
      "32/32 - 0s - 874us/step - loss: 0.7548\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "New best score: 0.24114930629730225 with params: {'layer_sizes': [64, 32], 'encoding_dim': 8, 'batch_size': 32, 'epochs': 50, 'dropout_rate': 0.2}\n",
      "Testing with layers=[64, 32], encoding_dim=8, batch_size=32, epochs=50, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "32/32 - 1s - 31ms/step - loss: 1.2322\n",
      "Epoch 2/50\n",
      "32/32 - 0s - 977us/step - loss: 1.1197\n",
      "Epoch 3/50\n",
      "32/32 - 0s - 1ms/step - loss: 1.0534\n",
      "Epoch 4/50\n",
      "32/32 - 0s - 848us/step - loss: 1.0090\n",
      "Epoch 5/50\n",
      "32/32 - 0s - 857us/step - loss: 0.9781\n",
      "Epoch 6/50\n",
      "32/32 - 0s - 888us/step - loss: 0.9590\n",
      "Epoch 7/50\n",
      "32/32 - 0s - 898us/step - loss: 0.9432\n",
      "Epoch 8/50\n",
      "32/32 - 0s - 839us/step - loss: 0.9300\n",
      "Epoch 9/50\n",
      "32/32 - 0s - 848us/step - loss: 0.9192\n",
      "Epoch 10/50\n",
      "32/32 - 0s - 853us/step - loss: 0.9116\n",
      "Epoch 11/50\n",
      "32/32 - 0s - 869us/step - loss: 0.9068\n",
      "Epoch 12/50\n",
      "32/32 - 0s - 865us/step - loss: 0.8961\n",
      "Epoch 13/50\n",
      "32/32 - 0s - 856us/step - loss: 0.8857\n",
      "Epoch 14/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8847\n",
      "Epoch 15/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8811\n",
      "Epoch 16/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8728\n",
      "Epoch 17/50\n",
      "32/32 - 0s - 893us/step - loss: 0.8707\n",
      "Epoch 18/50\n",
      "32/32 - 0s - 840us/step - loss: 0.8622\n",
      "Epoch 19/50\n",
      "32/32 - 0s - 884us/step - loss: 0.8607\n",
      "Epoch 20/50\n",
      "32/32 - 0s - 847us/step - loss: 0.8534\n",
      "Epoch 21/50\n",
      "32/32 - 0s - 868us/step - loss: 0.8495\n",
      "Epoch 22/50\n",
      "32/32 - 0s - 859us/step - loss: 0.8468\n",
      "Epoch 23/50\n",
      "32/32 - 0s - 867us/step - loss: 0.8418\n",
      "Epoch 24/50\n",
      "32/32 - 0s - 891us/step - loss: 0.8402\n",
      "Epoch 25/50\n",
      "32/32 - 0s - 853us/step - loss: 0.8389\n",
      "Epoch 26/50\n",
      "32/32 - 0s - 911us/step - loss: 0.8289\n",
      "Epoch 27/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8325\n",
      "Epoch 28/50\n",
      "32/32 - 0s - 864us/step - loss: 0.8247\n",
      "Epoch 29/50\n",
      "32/32 - 0s - 905us/step - loss: 0.8230\n",
      "Epoch 30/50\n",
      "32/32 - 0s - 840us/step - loss: 0.8239\n",
      "Epoch 31/50\n",
      "32/32 - 0s - 850us/step - loss: 0.8197\n",
      "Epoch 32/50\n",
      "32/32 - 0s - 864us/step - loss: 0.8168\n",
      "Epoch 33/50\n",
      "32/32 - 0s - 837us/step - loss: 0.8141\n",
      "Epoch 34/50\n",
      "32/32 - 0s - 858us/step - loss: 0.8127\n",
      "Epoch 35/50\n",
      "32/32 - 0s - 851us/step - loss: 0.8133\n",
      "Epoch 36/50\n",
      "32/32 - 0s - 840us/step - loss: 0.8083\n",
      "Epoch 37/50\n",
      "32/32 - 0s - 850us/step - loss: 0.8076\n",
      "Epoch 38/50\n",
      "32/32 - 0s - 843us/step - loss: 0.8069\n",
      "Epoch 39/50\n",
      "32/32 - 0s - 878us/step - loss: 0.8037\n",
      "Epoch 40/50\n",
      "32/32 - 0s - 838us/step - loss: 0.8051\n",
      "Epoch 41/50\n",
      "32/32 - 0s - 852us/step - loss: 0.8019\n",
      "Epoch 42/50\n",
      "32/32 - 0s - 850us/step - loss: 0.8002\n",
      "Epoch 43/50\n",
      "32/32 - 0s - 833us/step - loss: 0.8013\n",
      "Epoch 44/50\n",
      "32/32 - 0s - 858us/step - loss: 0.8015\n",
      "Epoch 45/50\n",
      "32/32 - 0s - 912us/step - loss: 0.7954\n",
      "Epoch 46/50\n",
      "32/32 - 0s - 873us/step - loss: 0.7964\n",
      "Epoch 47/50\n",
      "32/32 - 0s - 867us/step - loss: 0.7959\n",
      "Epoch 48/50\n",
      "32/32 - 0s - 852us/step - loss: 0.7948\n",
      "Epoch 49/50\n",
      "32/32 - 0s - 846us/step - loss: 0.7939\n",
      "Epoch 50/50\n",
      "32/32 - 0s - 846us/step - loss: 0.7932\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "New best score: 0.2478095144033432 with params: {'layer_sizes': [64, 32], 'encoding_dim': 8, 'batch_size': 32, 'epochs': 50, 'dropout_rate': 0.3}\n",
      "Testing with layers=[64, 32], encoding_dim=8, batch_size=32, epochs=100, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "32/32 - 1s - 30ms/step - loss: 1.2328\n",
      "Epoch 2/100\n",
      "32/32 - 0s - 967us/step - loss: 1.1063\n",
      "Epoch 3/100\n",
      "32/32 - 0s - 947us/step - loss: 1.0314\n",
      "Epoch 4/100\n",
      "32/32 - 0s - 854us/step - loss: 0.9785\n",
      "Epoch 5/100\n",
      "32/32 - 0s - 933us/step - loss: 0.9448\n",
      "Epoch 6/100\n",
      "32/32 - 0s - 885us/step - loss: 0.9183\n",
      "Epoch 7/100\n",
      "32/32 - 0s - 874us/step - loss: 0.9023\n",
      "Epoch 8/100\n",
      "32/32 - 0s - 909us/step - loss: 0.8892\n",
      "Epoch 9/100\n",
      "32/32 - 0s - 884us/step - loss: 0.8788\n",
      "Epoch 10/100\n",
      "32/32 - 0s - 859us/step - loss: 0.8672\n",
      "Epoch 11/100\n",
      "32/32 - 0s - 848us/step - loss: 0.8530\n",
      "Epoch 12/100\n",
      "32/32 - 0s - 856us/step - loss: 0.8479\n",
      "Epoch 13/100\n",
      "32/32 - 0s - 859us/step - loss: 0.8424\n",
      "Epoch 14/100\n",
      "32/32 - 0s - 910us/step - loss: 0.8357\n",
      "Epoch 15/100\n",
      "32/32 - 0s - 863us/step - loss: 0.8308\n",
      "Epoch 16/100\n",
      "32/32 - 0s - 898us/step - loss: 0.8238\n",
      "Epoch 17/100\n",
      "32/32 - 0s - 854us/step - loss: 0.8215\n",
      "Epoch 18/100\n",
      "32/32 - 0s - 863us/step - loss: 0.8154\n",
      "Epoch 19/100\n",
      "32/32 - 0s - 858us/step - loss: 0.8118\n",
      "Epoch 20/100\n",
      "32/32 - 0s - 861us/step - loss: 0.8098\n",
      "Epoch 21/100\n",
      "32/32 - 0s - 866us/step - loss: 0.8071\n",
      "Epoch 22/100\n",
      "32/32 - 0s - 848us/step - loss: 0.8034\n",
      "Epoch 23/100\n",
      "32/32 - 0s - 872us/step - loss: 0.8014\n",
      "Epoch 24/100\n",
      "32/32 - 0s - 893us/step - loss: 0.7991\n",
      "Epoch 25/100\n",
      "32/32 - 0s - 858us/step - loss: 0.7950\n",
      "Epoch 26/100\n",
      "32/32 - 0s - 829us/step - loss: 0.7919\n",
      "Epoch 27/100\n",
      "32/32 - 0s - 879us/step - loss: 0.7886\n",
      "Epoch 28/100\n",
      "32/32 - 0s - 849us/step - loss: 0.7920\n",
      "Epoch 29/100\n",
      "32/32 - 0s - 861us/step - loss: 0.7843\n",
      "Epoch 30/100\n",
      "32/32 - 0s - 842us/step - loss: 0.7866\n",
      "Epoch 31/100\n",
      "32/32 - 0s - 877us/step - loss: 0.7865\n",
      "Epoch 32/100\n",
      "32/32 - 0s - 901us/step - loss: 0.7831\n",
      "Epoch 33/100\n",
      "32/32 - 0s - 840us/step - loss: 0.7780\n",
      "Epoch 34/100\n",
      "32/32 - 0s - 858us/step - loss: 0.7774\n",
      "Epoch 35/100\n",
      "32/32 - 0s - 846us/step - loss: 0.7753\n",
      "Epoch 36/100\n",
      "32/32 - 0s - 861us/step - loss: 0.7735\n",
      "Epoch 37/100\n",
      "32/32 - 0s - 871us/step - loss: 0.7754\n",
      "Epoch 38/100\n",
      "32/32 - 0s - 853us/step - loss: 0.7729\n",
      "Epoch 39/100\n",
      "32/32 - 0s - 862us/step - loss: 0.7702\n",
      "Epoch 40/100\n",
      "32/32 - 0s - 840us/step - loss: 0.7728\n",
      "Epoch 41/100\n",
      "32/32 - 0s - 868us/step - loss: 0.7697\n",
      "Epoch 42/100\n",
      "32/32 - 0s - 896us/step - loss: 0.7685\n",
      "Epoch 43/100\n",
      "32/32 - 0s - 856us/step - loss: 0.7613\n",
      "Epoch 44/100\n",
      "32/32 - 0s - 851us/step - loss: 0.7622\n",
      "Epoch 45/100\n",
      "32/32 - 0s - 865us/step - loss: 0.7614\n",
      "Epoch 46/100\n",
      "32/32 - 0s - 857us/step - loss: 0.7587\n",
      "Epoch 47/100\n",
      "32/32 - 0s - 866us/step - loss: 0.7610\n",
      "Epoch 48/100\n",
      "32/32 - 0s - 847us/step - loss: 0.7608\n",
      "Epoch 49/100\n",
      "32/32 - 0s - 862us/step - loss: 0.7558\n",
      "Epoch 50/100\n",
      "32/32 - 0s - 892us/step - loss: 0.7562\n",
      "Epoch 51/100\n",
      "32/32 - 0s - 853us/step - loss: 0.7541\n",
      "Epoch 52/100\n",
      "32/32 - 0s - 864us/step - loss: 0.7557\n",
      "Epoch 53/100\n",
      "32/32 - 0s - 857us/step - loss: 0.7555\n",
      "Epoch 54/100\n",
      "32/32 - 0s - 836us/step - loss: 0.7544\n",
      "Epoch 55/100\n",
      "32/32 - 0s - 922us/step - loss: 0.7553\n",
      "Epoch 56/100\n",
      "32/32 - 0s - 835us/step - loss: 0.7530\n",
      "Epoch 57/100\n",
      "32/32 - 0s - 833us/step - loss: 0.7480\n",
      "Epoch 58/100\n",
      "32/32 - 0s - 870us/step - loss: 0.7493\n",
      "Epoch 59/100\n",
      "32/32 - 0s - 859us/step - loss: 0.7474\n",
      "Epoch 60/100\n",
      "32/32 - 0s - 848us/step - loss: 0.7475\n",
      "Epoch 61/100\n",
      "32/32 - 0s - 870us/step - loss: 0.7464\n",
      "Epoch 62/100\n",
      "32/32 - 0s - 875us/step - loss: 0.7433\n",
      "Epoch 63/100\n",
      "32/32 - 0s - 841us/step - loss: 0.7478\n",
      "Epoch 64/100\n",
      "32/32 - 0s - 856us/step - loss: 0.7425\n",
      "Epoch 65/100\n",
      "32/32 - 0s - 844us/step - loss: 0.7449\n",
      "Epoch 66/100\n",
      "32/32 - 0s - 899us/step - loss: 0.7419\n",
      "Epoch 67/100\n",
      "32/32 - 0s - 876us/step - loss: 0.7417\n",
      "Epoch 68/100\n",
      "32/32 - 0s - 884us/step - loss: 0.7439\n",
      "Epoch 69/100\n",
      "32/32 - 0s - 856us/step - loss: 0.7418\n",
      "Epoch 70/100\n",
      "32/32 - 0s - 862us/step - loss: 0.7379\n",
      "Epoch 71/100\n",
      "32/32 - 0s - 923us/step - loss: 0.7413\n",
      "Epoch 72/100\n",
      "32/32 - 0s - 859us/step - loss: 0.7425\n",
      "Epoch 73/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7389\n",
      "Epoch 74/100\n",
      "32/32 - 0s - 930us/step - loss: 0.7403\n",
      "Epoch 75/100\n",
      "32/32 - 0s - 838us/step - loss: 0.7417\n",
      "Epoch 76/100\n",
      "32/32 - 0s - 855us/step - loss: 0.7408\n",
      "Epoch 77/100\n",
      "32/32 - 0s - 835us/step - loss: 0.7387\n",
      "Epoch 78/100\n",
      "32/32 - 0s - 934us/step - loss: 0.7356\n",
      "Epoch 79/100\n",
      "32/32 - 0s - 851us/step - loss: 0.7333\n",
      "Epoch 80/100\n",
      "32/32 - 0s - 939us/step - loss: 0.7362\n",
      "Epoch 81/100\n",
      "32/32 - 0s - 859us/step - loss: 0.7307\n",
      "Epoch 82/100\n",
      "32/32 - 0s - 867us/step - loss: 0.7341\n",
      "Epoch 83/100\n",
      "32/32 - 0s - 840us/step - loss: 0.7344\n",
      "Epoch 84/100\n",
      "32/32 - 0s - 890us/step - loss: 0.7327\n",
      "Epoch 85/100\n",
      "32/32 - 0s - 895us/step - loss: 0.7332\n",
      "Epoch 86/100\n",
      "32/32 - 0s - 888us/step - loss: 0.7335\n",
      "Epoch 87/100\n",
      "32/32 - 0s - 912us/step - loss: 0.7327\n",
      "Epoch 88/100\n",
      "32/32 - 0s - 853us/step - loss: 0.7300\n",
      "Epoch 89/100\n",
      "32/32 - 0s - 978us/step - loss: 0.7314\n",
      "Epoch 90/100\n",
      "32/32 - 0s - 839us/step - loss: 0.7323\n",
      "Epoch 91/100\n",
      "32/32 - 0s - 847us/step - loss: 0.7320\n",
      "Epoch 92/100\n",
      "32/32 - 0s - 929us/step - loss: 0.7303\n",
      "Epoch 93/100\n",
      "32/32 - 0s - 851us/step - loss: 0.7298\n",
      "Epoch 94/100\n",
      "32/32 - 0s - 855us/step - loss: 0.7290\n",
      "Epoch 95/100\n",
      "32/32 - 0s - 857us/step - loss: 0.7300\n",
      "Epoch 96/100\n",
      "32/32 - 0s - 863us/step - loss: 0.7297\n",
      "Epoch 97/100\n",
      "32/32 - 0s - 834us/step - loss: 0.7275\n",
      "Epoch 98/100\n",
      "32/32 - 0s - 830us/step - loss: 0.7293\n",
      "Epoch 99/100\n",
      "32/32 - 0s - 860us/step - loss: 0.7290\n",
      "Epoch 100/100\n",
      "32/32 - 0s - 845us/step - loss: 0.7277\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "New best score: 0.2830658257007599 with params: {'layer_sizes': [64, 32], 'encoding_dim': 8, 'batch_size': 32, 'epochs': 100, 'dropout_rate': 0.2}\n",
      "Testing with layers=[64, 32], encoding_dim=8, batch_size=32, epochs=100, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "32/32 - 1s - 32ms/step - loss: 1.2383\n",
      "Epoch 2/100\n",
      "32/32 - 0s - 948us/step - loss: 1.1352\n",
      "Epoch 3/100\n",
      "32/32 - 0s - 1ms/step - loss: 1.0676\n",
      "Epoch 4/100\n",
      "32/32 - 0s - 875us/step - loss: 1.0119\n",
      "Epoch 5/100\n",
      "32/32 - 0s - 860us/step - loss: 0.9787\n",
      "Epoch 6/100\n",
      "32/32 - 0s - 849us/step - loss: 0.9538\n",
      "Epoch 7/100\n",
      "32/32 - 0s - 858us/step - loss: 0.9327\n",
      "Epoch 8/100\n",
      "32/32 - 0s - 890us/step - loss: 0.9171\n",
      "Epoch 9/100\n",
      "32/32 - 0s - 847us/step - loss: 0.9064\n",
      "Epoch 10/100\n",
      "32/32 - 0s - 865us/step - loss: 0.8954\n",
      "Epoch 11/100\n",
      "32/32 - 0s - 852us/step - loss: 0.8882\n",
      "Epoch 12/100\n",
      "32/32 - 0s - 946us/step - loss: 0.8780\n",
      "Epoch 13/100\n",
      "32/32 - 0s - 841us/step - loss: 0.8735\n",
      "Epoch 14/100\n",
      "32/32 - 0s - 849us/step - loss: 0.8688\n",
      "Epoch 15/100\n",
      "32/32 - 0s - 856us/step - loss: 0.8640\n",
      "Epoch 16/100\n",
      "32/32 - 0s - 856us/step - loss: 0.8589\n",
      "Epoch 17/100\n",
      "32/32 - 0s - 834us/step - loss: 0.8551\n",
      "Epoch 18/100\n",
      "32/32 - 0s - 875us/step - loss: 0.8503\n",
      "Epoch 19/100\n",
      "32/32 - 0s - 849us/step - loss: 0.8424\n",
      "Epoch 20/100\n",
      "32/32 - 0s - 862us/step - loss: 0.8400\n",
      "Epoch 21/100\n",
      "32/32 - 0s - 942us/step - loss: 0.8364\n",
      "Epoch 22/100\n",
      "32/32 - 0s - 875us/step - loss: 0.8338\n",
      "Epoch 23/100\n",
      "32/32 - 0s - 860us/step - loss: 0.8307\n",
      "Epoch 24/100\n",
      "32/32 - 0s - 864us/step - loss: 0.8283\n",
      "Epoch 25/100\n",
      "32/32 - 0s - 875us/step - loss: 0.8234\n",
      "Epoch 26/100\n",
      "32/32 - 0s - 885us/step - loss: 0.8206\n",
      "Epoch 27/100\n",
      "32/32 - 0s - 842us/step - loss: 0.8185\n",
      "Epoch 28/100\n",
      "32/32 - 0s - 854us/step - loss: 0.8207\n",
      "Epoch 29/100\n",
      "32/32 - 0s - 892us/step - loss: 0.8135\n",
      "Epoch 30/100\n",
      "32/32 - 0s - 845us/step - loss: 0.8115\n",
      "Epoch 31/100\n",
      "32/32 - 0s - 875us/step - loss: 0.8077\n",
      "Epoch 32/100\n",
      "32/32 - 0s - 905us/step - loss: 0.8085\n",
      "Epoch 33/100\n",
      "32/32 - 0s - 850us/step - loss: 0.8052\n",
      "Epoch 34/100\n",
      "32/32 - 0s - 845us/step - loss: 0.8031\n",
      "Epoch 35/100\n",
      "32/32 - 0s - 938us/step - loss: 0.8069\n",
      "Epoch 36/100\n",
      "32/32 - 0s - 868us/step - loss: 0.7970\n",
      "Epoch 37/100\n",
      "32/32 - 0s - 856us/step - loss: 0.7977\n",
      "Epoch 38/100\n",
      "32/32 - 0s - 857us/step - loss: 0.7996\n",
      "Epoch 39/100\n",
      "32/32 - 0s - 870us/step - loss: 0.7933\n",
      "Epoch 40/100\n",
      "32/32 - 0s - 841us/step - loss: 0.7918\n",
      "Epoch 41/100\n",
      "32/32 - 0s - 863us/step - loss: 0.7928\n",
      "Epoch 42/100\n",
      "32/32 - 0s - 847us/step - loss: 0.7926\n",
      "Epoch 43/100\n",
      "32/32 - 0s - 849us/step - loss: 0.7918\n",
      "Epoch 44/100\n",
      "32/32 - 0s - 875us/step - loss: 0.7894\n",
      "Epoch 45/100\n",
      "32/32 - 0s - 892us/step - loss: 0.7932\n",
      "Epoch 46/100\n",
      "32/32 - 0s - 880us/step - loss: 0.7857\n",
      "Epoch 47/100\n",
      "32/32 - 0s - 877us/step - loss: 0.7857\n",
      "Epoch 48/100\n",
      "32/32 - 0s - 853us/step - loss: 0.7863\n",
      "Epoch 49/100\n",
      "32/32 - 0s - 876us/step - loss: 0.7834\n",
      "Epoch 50/100\n",
      "32/32 - 0s - 854us/step - loss: 0.7850\n",
      "Epoch 51/100\n",
      "32/32 - 0s - 842us/step - loss: 0.7807\n",
      "Epoch 52/100\n",
      "32/32 - 0s - 862us/step - loss: 0.7810\n",
      "Epoch 53/100\n",
      "32/32 - 0s - 863us/step - loss: 0.7817\n",
      "Epoch 54/100\n",
      "32/32 - 0s - 865us/step - loss: 0.7773\n",
      "Epoch 55/100\n",
      "32/32 - 0s - 853us/step - loss: 0.7769\n",
      "Epoch 56/100\n",
      "32/32 - 0s - 883us/step - loss: 0.7748\n",
      "Epoch 57/100\n",
      "32/32 - 0s - 852us/step - loss: 0.7782\n",
      "Epoch 58/100\n",
      "32/32 - 0s - 842us/step - loss: 0.7761\n",
      "Epoch 59/100\n",
      "32/32 - 0s - 858us/step - loss: 0.7749\n",
      "Epoch 60/100\n",
      "32/32 - 0s - 857us/step - loss: 0.7748\n",
      "Epoch 61/100\n",
      "32/32 - 0s - 867us/step - loss: 0.7726\n",
      "Epoch 62/100\n",
      "32/32 - 0s - 863us/step - loss: 0.7760\n",
      "Epoch 63/100\n",
      "32/32 - 0s - 874us/step - loss: 0.7732\n",
      "Epoch 64/100\n",
      "32/32 - 0s - 855us/step - loss: 0.7701\n",
      "Epoch 65/100\n",
      "32/32 - 0s - 878us/step - loss: 0.7724\n",
      "Epoch 66/100\n",
      "32/32 - 0s - 831us/step - loss: 0.7698\n",
      "Epoch 67/100\n",
      "32/32 - 0s - 870us/step - loss: 0.7681\n",
      "Epoch 68/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7673\n",
      "Epoch 69/100\n",
      "32/32 - 0s - 853us/step - loss: 0.7661\n",
      "Epoch 70/100\n",
      "32/32 - 0s - 854us/step - loss: 0.7685\n",
      "Epoch 71/100\n",
      "32/32 - 0s - 865us/step - loss: 0.7662\n",
      "Epoch 72/100\n",
      "32/32 - 0s - 849us/step - loss: 0.7642\n",
      "Epoch 73/100\n",
      "32/32 - 0s - 862us/step - loss: 0.7667\n",
      "Epoch 74/100\n",
      "32/32 - 0s - 915us/step - loss: 0.7650\n",
      "Epoch 75/100\n",
      "32/32 - 0s - 857us/step - loss: 0.7682\n",
      "Epoch 76/100\n",
      "32/32 - 0s - 847us/step - loss: 0.7627\n",
      "Epoch 77/100\n",
      "32/32 - 0s - 880us/step - loss: 0.7684\n",
      "Epoch 78/100\n",
      "32/32 - 0s - 842us/step - loss: 0.7660\n",
      "Epoch 79/100\n",
      "32/32 - 0s - 858us/step - loss: 0.7626\n",
      "Epoch 80/100\n",
      "32/32 - 0s - 841us/step - loss: 0.7635\n",
      "Epoch 81/100\n",
      "32/32 - 0s - 890us/step - loss: 0.7605\n",
      "Epoch 82/100\n",
      "32/32 - 0s - 878us/step - loss: 0.7596\n",
      "Epoch 83/100\n",
      "32/32 - 0s - 865us/step - loss: 0.7615\n",
      "Epoch 84/100\n",
      "32/32 - 0s - 865us/step - loss: 0.7606\n",
      "Epoch 85/100\n",
      "32/32 - 0s - 866us/step - loss: 0.7637\n",
      "Epoch 86/100\n",
      "32/32 - 0s - 859us/step - loss: 0.7600\n",
      "Epoch 87/100\n",
      "32/32 - 0s - 895us/step - loss: 0.7621\n",
      "Epoch 88/100\n",
      "32/32 - 0s - 880us/step - loss: 0.7601\n",
      "Epoch 89/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7612\n",
      "Epoch 90/100\n",
      "32/32 - 0s - 983us/step - loss: 0.7605\n",
      "Epoch 91/100\n",
      "32/32 - 0s - 941us/step - loss: 0.7586\n",
      "Epoch 92/100\n",
      "32/32 - 0s - 880us/step - loss: 0.7586\n",
      "Epoch 93/100\n",
      "32/32 - 0s - 933us/step - loss: 0.7565\n",
      "Epoch 94/100\n",
      "32/32 - 0s - 859us/step - loss: 0.7592\n",
      "Epoch 95/100\n",
      "32/32 - 0s - 855us/step - loss: 0.7599\n",
      "Epoch 96/100\n",
      "32/32 - 0s - 858us/step - loss: 0.7574\n",
      "Epoch 97/100\n",
      "32/32 - 0s - 883us/step - loss: 0.7556\n",
      "Epoch 98/100\n",
      "32/32 - 0s - 847us/step - loss: 0.7576\n",
      "Epoch 99/100\n",
      "32/32 - 0s - 857us/step - loss: 0.7535\n",
      "Epoch 100/100\n",
      "32/32 - 0s - 855us/step - loss: 0.7548\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Testing with layers=[64, 32], encoding_dim=8, batch_size=64, epochs=50, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "16/16 - 1s - 64ms/step - loss: 1.2486\n",
      "Epoch 2/50\n",
      "16/16 - 0s - 1ms/step - loss: 1.1624\n",
      "Epoch 3/50\n",
      "16/16 - 0s - 1ms/step - loss: 1.0978\n",
      "Epoch 4/50\n",
      "16/16 - 0s - 2ms/step - loss: 1.0509\n",
      "Epoch 5/50\n",
      "16/16 - 0s - 1ms/step - loss: 1.0149\n",
      "Epoch 6/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.9832\n",
      "Epoch 7/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.9597\n",
      "Epoch 8/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.9365\n",
      "Epoch 9/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.9237\n",
      "Epoch 10/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.9095\n",
      "Epoch 11/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8983\n",
      "Epoch 12/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8872\n",
      "Epoch 13/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8768\n",
      "Epoch 14/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8710\n",
      "Epoch 15/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8623\n",
      "Epoch 16/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8602\n",
      "Epoch 17/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8522\n",
      "Epoch 18/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8410\n",
      "Epoch 19/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8424\n",
      "Epoch 20/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8381\n",
      "Epoch 21/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8312\n",
      "Epoch 22/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8270\n",
      "Epoch 23/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8250\n",
      "Epoch 24/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8185\n",
      "Epoch 25/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8144\n",
      "Epoch 26/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8121\n",
      "Epoch 27/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8092\n",
      "Epoch 28/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8087\n",
      "Epoch 29/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8057\n",
      "Epoch 30/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8001\n",
      "Epoch 31/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7974\n",
      "Epoch 32/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7981\n",
      "Epoch 33/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7921\n",
      "Epoch 34/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7925\n",
      "Epoch 35/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7879\n",
      "Epoch 36/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7893\n",
      "Epoch 37/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7843\n",
      "Epoch 38/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7851\n",
      "Epoch 39/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7854\n",
      "Epoch 40/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7808\n",
      "Epoch 41/50\n",
      "16/16 - 0s - 5ms/step - loss: 0.7807\n",
      "Epoch 42/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7776\n",
      "Epoch 43/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7754\n",
      "Epoch 44/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7726\n",
      "Epoch 45/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7711\n",
      "Epoch 46/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7714\n",
      "Epoch 47/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7733\n",
      "Epoch 48/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7707\n",
      "Epoch 49/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7683\n",
      "Epoch 50/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7658\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Testing with layers=[64, 32], encoding_dim=8, batch_size=64, epochs=50, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "16/16 - 2s - 119ms/step - loss: 1.2302\n",
      "Epoch 2/50\n",
      "16/16 - 0s - 2ms/step - loss: 1.1589\n",
      "Epoch 3/50\n",
      "16/16 - 0s - 2ms/step - loss: 1.1028\n",
      "Epoch 4/50\n",
      "16/16 - 0s - 2ms/step - loss: 1.0641\n",
      "Epoch 5/50\n",
      "16/16 - 0s - 1ms/step - loss: 1.0263\n",
      "Epoch 6/50\n",
      "16/16 - 0s - 2ms/step - loss: 1.0001\n",
      "Epoch 7/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.9778\n",
      "Epoch 8/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.9640\n",
      "Epoch 9/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.9535\n",
      "Epoch 10/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.9377\n",
      "Epoch 11/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.9254\n",
      "Epoch 12/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.9180\n",
      "Epoch 13/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.9112\n",
      "Epoch 14/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.9027\n",
      "Epoch 15/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8981\n",
      "Epoch 16/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8881\n",
      "Epoch 17/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8845\n",
      "Epoch 18/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8792\n",
      "Epoch 19/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8716\n",
      "Epoch 20/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8706\n",
      "Epoch 21/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8642\n",
      "Epoch 22/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8625\n",
      "Epoch 23/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8555\n",
      "Epoch 24/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8542\n",
      "Epoch 25/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8505\n",
      "Epoch 26/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8452\n",
      "Epoch 27/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8445\n",
      "Epoch 28/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8425\n",
      "Epoch 29/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8375\n",
      "Epoch 30/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8323\n",
      "Epoch 31/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8347\n",
      "Epoch 32/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8299\n",
      "Epoch 33/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8256\n",
      "Epoch 34/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8229\n",
      "Epoch 35/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8224\n",
      "Epoch 36/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8192\n",
      "Epoch 37/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8182\n",
      "Epoch 38/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8175\n",
      "Epoch 39/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8142\n",
      "Epoch 40/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8152\n",
      "Epoch 41/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8146\n",
      "Epoch 42/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8134\n",
      "Epoch 43/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8119\n",
      "Epoch 44/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8115\n",
      "Epoch 45/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8099\n",
      "Epoch 46/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8085\n",
      "Epoch 47/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8019\n",
      "Epoch 48/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8066\n",
      "Epoch 49/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8006\n",
      "Epoch 50/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8004\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Testing with layers=[64, 32], encoding_dim=8, batch_size=64, epochs=100, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "16/16 - 1s - 69ms/step - loss: 1.2441\n",
      "Epoch 2/100\n",
      "16/16 - 0s - 2ms/step - loss: 1.1503\n",
      "Epoch 3/100\n",
      "16/16 - 0s - 2ms/step - loss: 1.0842\n",
      "Epoch 4/100\n",
      "16/16 - 0s - 2ms/step - loss: 1.0396\n",
      "Epoch 5/100\n",
      "16/16 - 0s - 2ms/step - loss: 1.0001\n",
      "Epoch 6/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.9774\n",
      "Epoch 7/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.9529\n",
      "Epoch 8/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.9363\n",
      "Epoch 9/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.9225\n",
      "Epoch 10/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.9041\n",
      "Epoch 11/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8949\n",
      "Epoch 12/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8828\n",
      "Epoch 13/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8786\n",
      "Epoch 14/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8668\n",
      "Epoch 15/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8630\n",
      "Epoch 16/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8540\n",
      "Epoch 17/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8501\n",
      "Epoch 18/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8425\n",
      "Epoch 19/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8422\n",
      "Epoch 20/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8369\n",
      "Epoch 21/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8311\n",
      "Epoch 22/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8256\n",
      "Epoch 23/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8206\n",
      "Epoch 24/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8196\n",
      "Epoch 25/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8181\n",
      "Epoch 26/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8142\n",
      "Epoch 27/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.8124\n",
      "Epoch 28/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.8080\n",
      "Epoch 29/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8062\n",
      "Epoch 30/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8025\n",
      "Epoch 31/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7988\n",
      "Epoch 32/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8000\n",
      "Epoch 33/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7938\n",
      "Epoch 34/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7948\n",
      "Epoch 35/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7926\n",
      "Epoch 36/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7897\n",
      "Epoch 37/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7889\n",
      "Epoch 38/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7855\n",
      "Epoch 39/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7839\n",
      "Epoch 40/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7841\n",
      "Epoch 41/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7826\n",
      "Epoch 42/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7813\n",
      "Epoch 43/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7824\n",
      "Epoch 44/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7783\n",
      "Epoch 45/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7733\n",
      "Epoch 46/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7738\n",
      "Epoch 47/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7720\n",
      "Epoch 48/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7701\n",
      "Epoch 49/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7689\n",
      "Epoch 50/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7707\n",
      "Epoch 51/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7666\n",
      "Epoch 52/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7651\n",
      "Epoch 53/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7645\n",
      "Epoch 54/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7635\n",
      "Epoch 55/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7612\n",
      "Epoch 56/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7630\n",
      "Epoch 57/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7610\n",
      "Epoch 58/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7627\n",
      "Epoch 59/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7596\n",
      "Epoch 60/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7563\n",
      "Epoch 61/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7559\n",
      "Epoch 62/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7558\n",
      "Epoch 63/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7552\n",
      "Epoch 64/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7517\n",
      "Epoch 65/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7571\n",
      "Epoch 66/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7519\n",
      "Epoch 67/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7513\n",
      "Epoch 68/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7509\n",
      "Epoch 69/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7522\n",
      "Epoch 70/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7467\n",
      "Epoch 71/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7482\n",
      "Epoch 72/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7491\n",
      "Epoch 73/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7445\n",
      "Epoch 74/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7462\n",
      "Epoch 75/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7428\n",
      "Epoch 76/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7425\n",
      "Epoch 77/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7445\n",
      "Epoch 78/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7440\n",
      "Epoch 79/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7421\n",
      "Epoch 80/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7410\n",
      "Epoch 81/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7402\n",
      "Epoch 82/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7408\n",
      "Epoch 83/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7385\n",
      "Epoch 84/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7393\n",
      "Epoch 85/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7403\n",
      "Epoch 86/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7386\n",
      "Epoch 87/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7425\n",
      "Epoch 88/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7384\n",
      "Epoch 89/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7387\n",
      "Epoch 90/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7385\n",
      "Epoch 91/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7368\n",
      "Epoch 92/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7357\n",
      "Epoch 93/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7348\n",
      "Epoch 94/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7343\n",
      "Epoch 95/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7344\n",
      "Epoch 96/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7348\n",
      "Epoch 97/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7330\n",
      "Epoch 98/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7306\n",
      "Epoch 99/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7318\n",
      "Epoch 100/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7297\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Testing with layers=[64, 32], encoding_dim=8, batch_size=64, epochs=100, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "16/16 - 2s - 109ms/step - loss: 1.2764\n",
      "Epoch 2/100\n",
      "16/16 - 0s - 2ms/step - loss: 1.1902\n",
      "Epoch 3/100\n",
      "16/16 - 0s - 2ms/step - loss: 1.1345\n",
      "Epoch 4/100\n",
      "16/16 - 0s - 1ms/step - loss: 1.0886\n",
      "Epoch 5/100\n",
      "16/16 - 0s - 2ms/step - loss: 1.0485\n",
      "Epoch 6/100\n",
      "16/16 - 0s - 1ms/step - loss: 1.0156\n",
      "Epoch 7/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.9901\n",
      "Epoch 8/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.9732\n",
      "Epoch 9/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.9585\n",
      "Epoch 10/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.9431\n",
      "Epoch 11/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.9319\n",
      "Epoch 12/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.9235\n",
      "Epoch 13/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.9195\n",
      "Epoch 14/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.9124\n",
      "Epoch 15/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.9050\n",
      "Epoch 16/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8971\n",
      "Epoch 17/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8905\n",
      "Epoch 18/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8872\n",
      "Epoch 19/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8811\n",
      "Epoch 20/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8749\n",
      "Epoch 21/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8723\n",
      "Epoch 22/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8672\n",
      "Epoch 23/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8663\n",
      "Epoch 24/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8640\n",
      "Epoch 25/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8590\n",
      "Epoch 26/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8530\n",
      "Epoch 27/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8509\n",
      "Epoch 28/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8494\n",
      "Epoch 29/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8462\n",
      "Epoch 30/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8431\n",
      "Epoch 31/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8411\n",
      "Epoch 32/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8376\n",
      "Epoch 33/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8334\n",
      "Epoch 34/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8317\n",
      "Epoch 35/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8311\n",
      "Epoch 36/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8282\n",
      "Epoch 37/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8278\n",
      "Epoch 38/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8201\n",
      "Epoch 39/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8214\n",
      "Epoch 40/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8208\n",
      "Epoch 41/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8224\n",
      "Epoch 42/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8148\n",
      "Epoch 43/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8173\n",
      "Epoch 44/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8133\n",
      "Epoch 45/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8123\n",
      "Epoch 46/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8091\n",
      "Epoch 47/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8122\n",
      "Epoch 48/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8093\n",
      "Epoch 49/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8086\n",
      "Epoch 50/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8069\n",
      "Epoch 51/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8072\n",
      "Epoch 52/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8026\n",
      "Epoch 53/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8026\n",
      "Epoch 54/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8028\n",
      "Epoch 55/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7996\n",
      "Epoch 56/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7982\n",
      "Epoch 57/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7990\n",
      "Epoch 58/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7971\n",
      "Epoch 59/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7987\n",
      "Epoch 60/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7981\n",
      "Epoch 61/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7961\n",
      "Epoch 62/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7934\n",
      "Epoch 63/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7931\n",
      "Epoch 64/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7940\n",
      "Epoch 65/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7928\n",
      "Epoch 66/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7942\n",
      "Epoch 67/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7945\n",
      "Epoch 68/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7928\n",
      "Epoch 69/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7923\n",
      "Epoch 70/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7910\n",
      "Epoch 71/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7874\n",
      "Epoch 72/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7855\n",
      "Epoch 73/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7866\n",
      "Epoch 74/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7853\n",
      "Epoch 75/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7836\n",
      "Epoch 76/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7854\n",
      "Epoch 77/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7860\n",
      "Epoch 78/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7875\n",
      "Epoch 79/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7825\n",
      "Epoch 80/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7855\n",
      "Epoch 81/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7793\n",
      "Epoch 82/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7837\n",
      "Epoch 83/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7794\n",
      "Epoch 84/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7774\n",
      "Epoch 85/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7833\n",
      "Epoch 86/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7790\n",
      "Epoch 87/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7806\n",
      "Epoch 88/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7795\n",
      "Epoch 89/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7795\n",
      "Epoch 90/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7799\n",
      "Epoch 91/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7752\n",
      "Epoch 92/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7776\n",
      "Epoch 93/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7754\n",
      "Epoch 94/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7774\n",
      "Epoch 95/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7783\n",
      "Epoch 96/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7732\n",
      "Epoch 97/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7719\n",
      "Epoch 98/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7745\n",
      "Epoch 99/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7715\n",
      "Epoch 100/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7726\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Testing with layers=[64, 32], encoding_dim=8, batch_size=128, epochs=50, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "8/8 - 1s - 167ms/step - loss: 1.2263\n",
      "Epoch 2/50\n",
      "8/8 - 0s - 2ms/step - loss: 1.1750\n",
      "Epoch 3/50\n",
      "8/8 - 0s - 2ms/step - loss: 1.1249\n",
      "Epoch 4/50\n",
      "8/8 - 0s - 3ms/step - loss: 1.0914\n",
      "Epoch 5/50\n",
      "8/8 - 0s - 3ms/step - loss: 1.0594\n",
      "Epoch 6/50\n",
      "8/8 - 0s - 2ms/step - loss: 1.0360\n",
      "Epoch 7/50\n",
      "8/8 - 0s - 2ms/step - loss: 1.0148\n",
      "Epoch 8/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.9917\n",
      "Epoch 9/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.9736\n",
      "Epoch 10/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.9589\n",
      "Epoch 11/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.9453\n",
      "Epoch 12/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.9358\n",
      "Epoch 13/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.9192\n",
      "Epoch 14/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.9133\n",
      "Epoch 15/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.9064\n",
      "Epoch 16/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8947\n",
      "Epoch 17/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8911\n",
      "Epoch 18/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8861\n",
      "Epoch 19/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8792\n",
      "Epoch 20/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8705\n",
      "Epoch 21/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8684\n",
      "Epoch 22/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8653\n",
      "Epoch 23/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8603\n",
      "Epoch 24/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8570\n",
      "Epoch 25/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8518\n",
      "Epoch 26/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8485\n",
      "Epoch 27/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8438\n",
      "Epoch 28/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8410\n",
      "Epoch 29/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8381\n",
      "Epoch 30/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8349\n",
      "Epoch 31/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8312\n",
      "Epoch 32/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8319\n",
      "Epoch 33/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8246\n",
      "Epoch 34/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8221\n",
      "Epoch 35/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8207\n",
      "Epoch 36/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8194\n",
      "Epoch 37/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8160\n",
      "Epoch 38/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.8147\n",
      "Epoch 39/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8109\n",
      "Epoch 40/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8098\n",
      "Epoch 41/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8080\n",
      "Epoch 42/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8053\n",
      "Epoch 43/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8040\n",
      "Epoch 44/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8048\n",
      "Epoch 45/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8012\n",
      "Epoch 46/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8008\n",
      "Epoch 47/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7967\n",
      "Epoch 48/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7952\n",
      "Epoch 49/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7944\n",
      "Epoch 50/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7934\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Testing with layers=[64, 32], encoding_dim=8, batch_size=128, epochs=50, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "8/8 - 1s - 184ms/step - loss: 1.2962\n",
      "Epoch 2/50\n",
      "8/8 - 0s - 3ms/step - loss: 1.2446\n",
      "Epoch 3/50\n",
      "8/8 - 0s - 2ms/step - loss: 1.1946\n",
      "Epoch 4/50\n",
      "8/8 - 0s - 2ms/step - loss: 1.1643\n",
      "Epoch 5/50\n",
      "8/8 - 0s - 3ms/step - loss: 1.1248\n",
      "Epoch 6/50\n",
      "8/8 - 0s - 2ms/step - loss: 1.0997\n",
      "Epoch 7/50\n",
      "8/8 - 0s - 2ms/step - loss: 1.0743\n",
      "Epoch 8/50\n",
      "8/8 - 0s - 2ms/step - loss: 1.0545\n",
      "Epoch 9/50\n",
      "8/8 - 0s - 2ms/step - loss: 1.0328\n",
      "Epoch 10/50\n",
      "8/8 - 0s - 2ms/step - loss: 1.0147\n",
      "Epoch 11/50\n",
      "8/8 - 0s - 2ms/step - loss: 1.0004\n",
      "Epoch 12/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.9855\n",
      "Epoch 13/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.9767\n",
      "Epoch 14/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.9632\n",
      "Epoch 15/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.9518\n",
      "Epoch 16/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.9466\n",
      "Epoch 17/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.9405\n",
      "Epoch 18/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.9278\n",
      "Epoch 19/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.9234\n",
      "Epoch 20/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.9172\n",
      "Epoch 21/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.9130\n",
      "Epoch 22/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.9084\n",
      "Epoch 23/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.9054\n",
      "Epoch 24/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8997\n",
      "Epoch 25/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8956\n",
      "Epoch 26/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8898\n",
      "Epoch 27/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8880\n",
      "Epoch 28/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8813\n",
      "Epoch 29/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8803\n",
      "Epoch 30/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8764\n",
      "Epoch 31/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8765\n",
      "Epoch 32/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8703\n",
      "Epoch 33/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8673\n",
      "Epoch 34/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8643\n",
      "Epoch 35/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8579\n",
      "Epoch 36/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8591\n",
      "Epoch 37/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8530\n",
      "Epoch 38/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8526\n",
      "Epoch 39/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8523\n",
      "Epoch 40/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8475\n",
      "Epoch 41/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8480\n",
      "Epoch 42/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8419\n",
      "Epoch 43/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8408\n",
      "Epoch 44/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8341\n",
      "Epoch 45/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8378\n",
      "Epoch 46/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8335\n",
      "Epoch 47/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8363\n",
      "Epoch 48/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8307\n",
      "Epoch 49/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8304\n",
      "Epoch 50/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8277\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Testing with layers=[64, 32], encoding_dim=8, batch_size=128, epochs=100, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "8/8 - 1s - 124ms/step - loss: 1.2318\n",
      "Epoch 2/100\n",
      "8/8 - 0s - 3ms/step - loss: 1.1893\n",
      "Epoch 3/100\n",
      "8/8 - 0s - 2ms/step - loss: 1.1399\n",
      "Epoch 4/100\n",
      "8/8 - 0s - 3ms/step - loss: 1.1037\n",
      "Epoch 5/100\n",
      "8/8 - 0s - 2ms/step - loss: 1.0750\n",
      "Epoch 6/100\n",
      "8/8 - 0s - 3ms/step - loss: 1.0437\n",
      "Epoch 7/100\n",
      "8/8 - 0s - 2ms/step - loss: 1.0253\n",
      "Epoch 8/100\n",
      "8/8 - 0s - 2ms/step - loss: 1.0042\n",
      "Epoch 9/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.9864\n",
      "Epoch 10/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.9675\n",
      "Epoch 11/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.9546\n",
      "Epoch 12/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.9437\n",
      "Epoch 13/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.9284\n",
      "Epoch 14/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.9191\n",
      "Epoch 15/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.9116\n",
      "Epoch 16/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.9008\n",
      "Epoch 17/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8946\n",
      "Epoch 18/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8917\n",
      "Epoch 19/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8801\n",
      "Epoch 20/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.8789\n",
      "Epoch 21/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.8705\n",
      "Epoch 22/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8667\n",
      "Epoch 23/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8652\n",
      "Epoch 24/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8617\n",
      "Epoch 25/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8550\n",
      "Epoch 26/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.8518\n",
      "Epoch 27/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8508\n",
      "Epoch 28/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8453\n",
      "Epoch 29/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8449\n",
      "Epoch 30/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8399\n",
      "Epoch 31/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8378\n",
      "Epoch 32/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8348\n",
      "Epoch 33/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8308\n",
      "Epoch 34/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8278\n",
      "Epoch 35/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8297\n",
      "Epoch 36/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8248\n",
      "Epoch 37/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8218\n",
      "Epoch 38/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8197\n",
      "Epoch 39/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.8163\n",
      "Epoch 40/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.8163\n",
      "Epoch 41/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8141\n",
      "Epoch 42/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8099\n",
      "Epoch 43/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8093\n",
      "Epoch 44/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8076\n",
      "Epoch 45/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8057\n",
      "Epoch 46/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8032\n",
      "Epoch 47/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8029\n",
      "Epoch 48/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8005\n",
      "Epoch 49/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8001\n",
      "Epoch 50/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7962\n",
      "Epoch 51/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7969\n",
      "Epoch 52/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7964\n",
      "Epoch 53/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7919\n",
      "Epoch 54/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7901\n",
      "Epoch 55/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7890\n",
      "Epoch 56/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7904\n",
      "Epoch 57/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7888\n",
      "Epoch 58/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7872\n",
      "Epoch 59/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7877\n",
      "Epoch 60/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7846\n",
      "Epoch 61/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7828\n",
      "Epoch 62/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7788\n",
      "Epoch 63/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7778\n",
      "Epoch 64/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7807\n",
      "Epoch 65/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7776\n",
      "Epoch 66/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7766\n",
      "Epoch 67/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7758\n",
      "Epoch 68/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7727\n",
      "Epoch 69/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7730\n",
      "Epoch 70/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7707\n",
      "Epoch 71/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7699\n",
      "Epoch 72/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7696\n",
      "Epoch 73/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7705\n",
      "Epoch 74/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7676\n",
      "Epoch 75/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7685\n",
      "Epoch 76/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7642\n",
      "Epoch 77/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7665\n",
      "Epoch 78/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7650\n",
      "Epoch 79/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7647\n",
      "Epoch 80/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7624\n",
      "Epoch 81/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7632\n",
      "Epoch 82/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7597\n",
      "Epoch 83/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7596\n",
      "Epoch 84/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7600\n",
      "Epoch 85/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7565\n",
      "Epoch 86/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7580\n",
      "Epoch 87/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7580\n",
      "Epoch 88/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7555\n",
      "Epoch 89/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7561\n",
      "Epoch 90/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7559\n",
      "Epoch 91/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7536\n",
      "Epoch 92/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7535\n",
      "Epoch 93/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7508\n",
      "Epoch 94/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7524\n",
      "Epoch 95/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7523\n",
      "Epoch 96/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7500\n",
      "Epoch 97/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7477\n",
      "Epoch 98/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7495\n",
      "Epoch 99/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7472\n",
      "Epoch 100/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7468\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Testing with layers=[64, 32], encoding_dim=8, batch_size=128, epochs=100, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "8/8 - 2s - 213ms/step - loss: 1.2557\n",
      "Epoch 2/100\n",
      "8/8 - 0s - 5ms/step - loss: 1.2047\n",
      "Epoch 3/100\n",
      "8/8 - 0s - 4ms/step - loss: 1.1573\n",
      "Epoch 4/100\n",
      "8/8 - 0s - 4ms/step - loss: 1.1278\n",
      "Epoch 5/100\n",
      "8/8 - 0s - 4ms/step - loss: 1.0928\n",
      "Epoch 6/100\n",
      "8/8 - 0s - 4ms/step - loss: 1.0679\n",
      "Epoch 7/100\n",
      "8/8 - 0s - 4ms/step - loss: 1.0430\n",
      "Epoch 8/100\n",
      "8/8 - 0s - 3ms/step - loss: 1.0245\n",
      "Epoch 9/100\n",
      "8/8 - 0s - 3ms/step - loss: 1.0130\n",
      "Epoch 10/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.9916\n",
      "Epoch 11/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.9820\n",
      "Epoch 12/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.9722\n",
      "Epoch 13/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.9641\n",
      "Epoch 14/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.9477\n",
      "Epoch 15/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.9422\n",
      "Epoch 16/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.9318\n",
      "Epoch 17/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.9301\n",
      "Epoch 18/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.9226\n",
      "Epoch 19/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.9141\n",
      "Epoch 20/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.9040\n",
      "Epoch 21/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.9052\n",
      "Epoch 22/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8969\n",
      "Epoch 23/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8927\n",
      "Epoch 24/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8883\n",
      "Epoch 25/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8903\n",
      "Epoch 26/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8807\n",
      "Epoch 27/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8772\n",
      "Epoch 28/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8736\n",
      "Epoch 29/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8747\n",
      "Epoch 30/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8665\n",
      "Epoch 31/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8662\n",
      "Epoch 32/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8659\n",
      "Epoch 33/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8599\n",
      "Epoch 34/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8578\n",
      "Epoch 35/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8556\n",
      "Epoch 36/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8537\n",
      "Epoch 37/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8536\n",
      "Epoch 38/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8472\n",
      "Epoch 39/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8477\n",
      "Epoch 40/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8453\n",
      "Epoch 41/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8429\n",
      "Epoch 42/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8424\n",
      "Epoch 43/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8410\n",
      "Epoch 44/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8373\n",
      "Epoch 45/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8357\n",
      "Epoch 46/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8341\n",
      "Epoch 47/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8331\n",
      "Epoch 48/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.8329\n",
      "Epoch 49/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.8286\n",
      "Epoch 50/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8305\n",
      "Epoch 51/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8272\n",
      "Epoch 52/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8242\n",
      "Epoch 53/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8226\n",
      "Epoch 54/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8215\n",
      "Epoch 55/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8217\n",
      "Epoch 56/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8204\n",
      "Epoch 57/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8193\n",
      "Epoch 58/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8185\n",
      "Epoch 59/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8153\n",
      "Epoch 60/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8149\n",
      "Epoch 61/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8171\n",
      "Epoch 62/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8074\n",
      "Epoch 63/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8092\n",
      "Epoch 64/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8101\n",
      "Epoch 65/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8086\n",
      "Epoch 66/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8093\n",
      "Epoch 67/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8103\n",
      "Epoch 68/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8086\n",
      "Epoch 69/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8068\n",
      "Epoch 70/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8090\n",
      "Epoch 71/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8071\n",
      "Epoch 72/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8014\n",
      "Epoch 73/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8053\n",
      "Epoch 74/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8024\n",
      "Epoch 75/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8010\n",
      "Epoch 76/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8008\n",
      "Epoch 77/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7986\n",
      "Epoch 78/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7954\n",
      "Epoch 79/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7984\n",
      "Epoch 80/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7987\n",
      "Epoch 81/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7961\n",
      "Epoch 82/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7987\n",
      "Epoch 83/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7953\n",
      "Epoch 84/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7958\n",
      "Epoch 85/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7939\n",
      "Epoch 86/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7957\n",
      "Epoch 87/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7910\n",
      "Epoch 88/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7933\n",
      "Epoch 89/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7958\n",
      "Epoch 90/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7912\n",
      "Epoch 91/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7966\n",
      "Epoch 92/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7896\n",
      "Epoch 93/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7882\n",
      "Epoch 94/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7880\n",
      "Epoch 95/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7868\n",
      "Epoch 96/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7917\n",
      "Epoch 97/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7867\n",
      "Epoch 98/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7905\n",
      "Epoch 99/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7862\n",
      "Epoch 100/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7870\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "New best score: 0.2935844361782074 with params: {'layer_sizes': [64, 32], 'encoding_dim': 8, 'batch_size': 128, 'epochs': 100, 'dropout_rate': 0.3}\n",
      "Testing with layers=[64, 32], encoding_dim=10, batch_size=32, epochs=50, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "32/32 - 1s - 31ms/step - loss: 1.2280\n",
      "Epoch 2/50\n",
      "32/32 - 0s - 925us/step - loss: 1.1031\n",
      "Epoch 3/50\n",
      "32/32 - 0s - 2ms/step - loss: 1.0216\n",
      "Epoch 4/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.9720\n",
      "Epoch 5/50\n",
      "32/32 - 0s - 835us/step - loss: 0.9388\n",
      "Epoch 6/50\n",
      "32/32 - 0s - 855us/step - loss: 0.9107\n",
      "Epoch 7/50\n",
      "32/32 - 0s - 816us/step - loss: 0.8918\n",
      "Epoch 8/50\n",
      "32/32 - 0s - 835us/step - loss: 0.8782\n",
      "Epoch 9/50\n",
      "32/32 - 0s - 837us/step - loss: 0.8639\n",
      "Epoch 10/50\n",
      "32/32 - 0s - 865us/step - loss: 0.8561\n",
      "Epoch 11/50\n",
      "32/32 - 0s - 831us/step - loss: 0.8478\n",
      "Epoch 12/50\n",
      "32/32 - 0s - 873us/step - loss: 0.8383\n",
      "Epoch 13/50\n",
      "32/32 - 0s - 896us/step - loss: 0.8296\n",
      "Epoch 14/50\n",
      "32/32 - 0s - 868us/step - loss: 0.8247\n",
      "Epoch 15/50\n",
      "32/32 - 0s - 811us/step - loss: 0.8147\n",
      "Epoch 16/50\n",
      "32/32 - 0s - 866us/step - loss: 0.8097\n",
      "Epoch 17/50\n",
      "32/32 - 0s - 884us/step - loss: 0.8020\n",
      "Epoch 18/50\n",
      "32/32 - 0s - 825us/step - loss: 0.7954\n",
      "Epoch 19/50\n",
      "32/32 - 0s - 929us/step - loss: 0.7929\n",
      "Epoch 20/50\n",
      "32/32 - 0s - 830us/step - loss: 0.7863\n",
      "Epoch 21/50\n",
      "32/32 - 0s - 841us/step - loss: 0.7857\n",
      "Epoch 22/50\n",
      "32/32 - 0s - 829us/step - loss: 0.7780\n",
      "Epoch 23/50\n",
      "32/32 - 0s - 840us/step - loss: 0.7750\n",
      "Epoch 24/50\n",
      "32/32 - 0s - 866us/step - loss: 0.7696\n",
      "Epoch 25/50\n",
      "32/32 - 0s - 864us/step - loss: 0.7679\n",
      "Epoch 26/50\n",
      "32/32 - 0s - 847us/step - loss: 0.7622\n",
      "Epoch 27/50\n",
      "32/32 - 0s - 830us/step - loss: 0.7649\n",
      "Epoch 28/50\n",
      "32/32 - 0s - 865us/step - loss: 0.7597\n",
      "Epoch 29/50\n",
      "32/32 - 0s - 982us/step - loss: 0.7555\n",
      "Epoch 30/50\n",
      "32/32 - 0s - 853us/step - loss: 0.7548\n",
      "Epoch 31/50\n",
      "32/32 - 0s - 899us/step - loss: 0.7543\n",
      "Epoch 32/50\n",
      "32/32 - 0s - 845us/step - loss: 0.7499\n",
      "Epoch 33/50\n",
      "32/32 - 0s - 893us/step - loss: 0.7503\n",
      "Epoch 34/50\n",
      "32/32 - 0s - 968us/step - loss: 0.7454\n",
      "Epoch 35/50\n",
      "32/32 - 0s - 884us/step - loss: 0.7456\n",
      "Epoch 36/50\n",
      "32/32 - 0s - 884us/step - loss: 0.7384\n",
      "Epoch 37/50\n",
      "32/32 - 0s - 869us/step - loss: 0.7410\n",
      "Epoch 38/50\n",
      "32/32 - 0s - 842us/step - loss: 0.7389\n",
      "Epoch 39/50\n",
      "32/32 - 0s - 835us/step - loss: 0.7418\n",
      "Epoch 40/50\n",
      "32/32 - 0s - 889us/step - loss: 0.7347\n",
      "Epoch 41/50\n",
      "32/32 - 0s - 842us/step - loss: 0.7382\n",
      "Epoch 42/50\n",
      "32/32 - 0s - 882us/step - loss: 0.7335\n",
      "Epoch 43/50\n",
      "32/32 - 0s - 851us/step - loss: 0.7310\n",
      "Epoch 44/50\n",
      "32/32 - 0s - 846us/step - loss: 0.7320\n",
      "Epoch 45/50\n",
      "32/32 - 0s - 861us/step - loss: 0.7288\n",
      "Epoch 46/50\n",
      "32/32 - 0s - 899us/step - loss: 0.7288\n",
      "Epoch 47/50\n",
      "32/32 - 0s - 902us/step - loss: 0.7314\n",
      "Epoch 48/50\n",
      "32/32 - 0s - 894us/step - loss: 0.7267\n",
      "Epoch 49/50\n",
      "32/32 - 0s - 885us/step - loss: 0.7257\n",
      "Epoch 50/50\n",
      "32/32 - 0s - 878us/step - loss: 0.7276\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n",
      "Testing with layers=[64, 32], encoding_dim=10, batch_size=32, epochs=50, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "32/32 - 1s - 31ms/step - loss: 1.2468\n",
      "Epoch 2/50\n",
      "32/32 - 0s - 968us/step - loss: 1.1290\n",
      "Epoch 3/50\n",
      "32/32 - 0s - 1ms/step - loss: 1.0501\n",
      "Epoch 4/50\n",
      "32/32 - 0s - 849us/step - loss: 1.0059\n",
      "Epoch 5/50\n",
      "32/32 - 0s - 837us/step - loss: 0.9700\n",
      "Epoch 6/50\n",
      "32/32 - 0s - 839us/step - loss: 0.9455\n",
      "Epoch 7/50\n",
      "32/32 - 0s - 838us/step - loss: 0.9264\n",
      "Epoch 8/50\n",
      "32/32 - 0s - 837us/step - loss: 0.9124\n",
      "Epoch 9/50\n",
      "32/32 - 0s - 823us/step - loss: 0.9003\n",
      "Epoch 10/50\n",
      "32/32 - 0s - 836us/step - loss: 0.8918\n",
      "Epoch 11/50\n",
      "32/32 - 0s - 966us/step - loss: 0.8833\n",
      "Epoch 12/50\n",
      "32/32 - 0s - 858us/step - loss: 0.8732\n",
      "Epoch 13/50\n",
      "32/32 - 0s - 842us/step - loss: 0.8648\n",
      "Epoch 14/50\n",
      "32/32 - 0s - 874us/step - loss: 0.8616\n",
      "Epoch 15/50\n",
      "32/32 - 0s - 858us/step - loss: 0.8558\n",
      "Epoch 16/50\n",
      "32/32 - 0s - 899us/step - loss: 0.8497\n",
      "Epoch 17/50\n",
      "32/32 - 0s - 847us/step - loss: 0.8405\n",
      "Epoch 18/50\n",
      "32/32 - 0s - 925us/step - loss: 0.8356\n",
      "Epoch 19/50\n",
      "32/32 - 0s - 856us/step - loss: 0.8318\n",
      "Epoch 20/50\n",
      "32/32 - 0s - 861us/step - loss: 0.8265\n",
      "Epoch 21/50\n",
      "32/32 - 0s - 910us/step - loss: 0.8239\n",
      "Epoch 22/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8202\n",
      "Epoch 23/50\n",
      "32/32 - 0s - 872us/step - loss: 0.8150\n",
      "Epoch 24/50\n",
      "32/32 - 0s - 837us/step - loss: 0.8148\n",
      "Epoch 25/50\n",
      "32/32 - 0s - 888us/step - loss: 0.8133\n",
      "Epoch 26/50\n",
      "32/32 - 0s - 844us/step - loss: 0.8094\n",
      "Epoch 27/50\n",
      "32/32 - 0s - 860us/step - loss: 0.8064\n",
      "Epoch 28/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8064\n",
      "Epoch 29/50\n",
      "32/32 - 0s - 862us/step - loss: 0.7988\n",
      "Epoch 30/50\n",
      "32/32 - 0s - 883us/step - loss: 0.8013\n",
      "Epoch 31/50\n",
      "32/32 - 0s - 905us/step - loss: 0.7961\n",
      "Epoch 32/50\n",
      "32/32 - 0s - 839us/step - loss: 0.7955\n",
      "Epoch 33/50\n",
      "32/32 - 0s - 852us/step - loss: 0.7905\n",
      "Epoch 34/50\n",
      "32/32 - 0s - 942us/step - loss: 0.7913\n",
      "Epoch 35/50\n",
      "32/32 - 0s - 896us/step - loss: 0.7883\n",
      "Epoch 36/50\n",
      "32/32 - 0s - 878us/step - loss: 0.7864\n",
      "Epoch 37/50\n",
      "32/32 - 0s - 837us/step - loss: 0.7818\n",
      "Epoch 38/50\n",
      "32/32 - 0s - 833us/step - loss: 0.7864\n",
      "Epoch 39/50\n",
      "32/32 - 0s - 838us/step - loss: 0.7813\n",
      "Epoch 40/50\n",
      "32/32 - 0s - 847us/step - loss: 0.7819\n",
      "Epoch 41/50\n",
      "32/32 - 0s - 851us/step - loss: 0.7815\n",
      "Epoch 42/50\n",
      "32/32 - 0s - 831us/step - loss: 0.7746\n",
      "Epoch 43/50\n",
      "32/32 - 0s - 831us/step - loss: 0.7757\n",
      "Epoch 44/50\n",
      "32/32 - 0s - 860us/step - loss: 0.7751\n",
      "Epoch 45/50\n",
      "32/32 - 0s - 828us/step - loss: 0.7751\n",
      "Epoch 46/50\n",
      "32/32 - 0s - 868us/step - loss: 0.7662\n",
      "Epoch 47/50\n",
      "32/32 - 0s - 854us/step - loss: 0.7695\n",
      "Epoch 48/50\n",
      "32/32 - 0s - 830us/step - loss: 0.7704\n",
      "Epoch 49/50\n",
      "32/32 - 0s - 838us/step - loss: 0.7654\n",
      "Epoch 50/50\n",
      "32/32 - 0s - 880us/step - loss: 0.7665\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Testing with layers=[64, 32], encoding_dim=10, batch_size=32, epochs=100, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "32/32 - 1s - 34ms/step - loss: 1.2146\n",
      "Epoch 2/100\n",
      "32/32 - 0s - 982us/step - loss: 1.0923\n",
      "Epoch 3/100\n",
      "32/32 - 0s - 1ms/step - loss: 1.0129\n",
      "Epoch 4/100\n",
      "32/32 - 0s - 928us/step - loss: 0.9644\n",
      "Epoch 5/100\n",
      "32/32 - 0s - 952us/step - loss: 0.9300\n",
      "Epoch 6/100\n",
      "32/32 - 0s - 849us/step - loss: 0.9082\n",
      "Epoch 7/100\n",
      "32/32 - 0s - 850us/step - loss: 0.8881\n",
      "Epoch 8/100\n",
      "32/32 - 0s - 904us/step - loss: 0.8757\n",
      "Epoch 9/100\n",
      "32/32 - 0s - 858us/step - loss: 0.8653\n",
      "Epoch 10/100\n",
      "32/32 - 0s - 857us/step - loss: 0.8567\n",
      "Epoch 11/100\n",
      "32/32 - 0s - 848us/step - loss: 0.8452\n",
      "Epoch 12/100\n",
      "32/32 - 0s - 832us/step - loss: 0.8342\n",
      "Epoch 13/100\n",
      "32/32 - 0s - 933us/step - loss: 0.8281\n",
      "Epoch 14/100\n",
      "32/32 - 0s - 889us/step - loss: 0.8197\n",
      "Epoch 15/100\n",
      "32/32 - 0s - 859us/step - loss: 0.8132\n",
      "Epoch 16/100\n",
      "32/32 - 0s - 841us/step - loss: 0.8065\n",
      "Epoch 17/100\n",
      "32/32 - 0s - 849us/step - loss: 0.8019\n",
      "Epoch 18/100\n",
      "32/32 - 0s - 837us/step - loss: 0.7976\n",
      "Epoch 19/100\n",
      "32/32 - 0s - 840us/step - loss: 0.7937\n",
      "Epoch 20/100\n",
      "32/32 - 0s - 834us/step - loss: 0.7863\n",
      "Epoch 21/100\n",
      "32/32 - 0s - 943us/step - loss: 0.7797\n",
      "Epoch 22/100\n",
      "32/32 - 0s - 921us/step - loss: 0.7781\n",
      "Epoch 23/100\n",
      "32/32 - 0s - 821us/step - loss: 0.7722\n",
      "Epoch 24/100\n",
      "32/32 - 0s - 861us/step - loss: 0.7700\n",
      "Epoch 25/100\n",
      "32/32 - 0s - 989us/step - loss: 0.7653\n",
      "Epoch 26/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7688\n",
      "Epoch 27/100\n",
      "32/32 - 0s - 966us/step - loss: 0.7622\n",
      "Epoch 28/100\n",
      "32/32 - 0s - 833us/step - loss: 0.7591\n",
      "Epoch 29/100\n",
      "32/32 - 0s - 838us/step - loss: 0.7586\n",
      "Epoch 30/100\n",
      "32/32 - 0s - 855us/step - loss: 0.7577\n",
      "Epoch 31/100\n",
      "32/32 - 0s - 901us/step - loss: 0.7523\n",
      "Epoch 32/100\n",
      "32/32 - 0s - 894us/step - loss: 0.7514\n",
      "Epoch 33/100\n",
      "32/32 - 0s - 910us/step - loss: 0.7487\n",
      "Epoch 34/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7516\n",
      "Epoch 35/100\n",
      "32/32 - 0s - 977us/step - loss: 0.7478\n",
      "Epoch 36/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7443\n",
      "Epoch 37/100\n",
      "32/32 - 0s - 901us/step - loss: 0.7431\n",
      "Epoch 38/100\n",
      "32/32 - 0s - 851us/step - loss: 0.7389\n",
      "Epoch 39/100\n",
      "32/32 - 0s - 819us/step - loss: 0.7416\n",
      "Epoch 40/100\n",
      "32/32 - 0s - 931us/step - loss: 0.7378\n",
      "Epoch 41/100\n",
      "32/32 - 0s - 875us/step - loss: 0.7342\n",
      "Epoch 42/100\n",
      "32/32 - 0s - 862us/step - loss: 0.7358\n",
      "Epoch 43/100\n",
      "32/32 - 0s - 844us/step - loss: 0.7321\n",
      "Epoch 44/100\n",
      "32/32 - 0s - 839us/step - loss: 0.7339\n",
      "Epoch 45/100\n",
      "32/32 - 0s - 931us/step - loss: 0.7287\n",
      "Epoch 46/100\n",
      "32/32 - 0s - 829us/step - loss: 0.7290\n",
      "Epoch 47/100\n",
      "32/32 - 0s - 857us/step - loss: 0.7279\n",
      "Epoch 48/100\n",
      "32/32 - 0s - 851us/step - loss: 0.7273\n",
      "Epoch 49/100\n",
      "32/32 - 0s - 834us/step - loss: 0.7279\n",
      "Epoch 50/100\n",
      "32/32 - 0s - 830us/step - loss: 0.7258\n",
      "Epoch 51/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7279\n",
      "Epoch 52/100\n",
      "32/32 - 0s - 923us/step - loss: 0.7271\n",
      "Epoch 53/100\n",
      "32/32 - 0s - 855us/step - loss: 0.7218\n",
      "Epoch 54/100\n",
      "32/32 - 0s - 878us/step - loss: 0.7227\n",
      "Epoch 55/100\n",
      "32/32 - 0s - 856us/step - loss: 0.7187\n",
      "Epoch 56/100\n",
      "32/32 - 0s - 885us/step - loss: 0.7192\n",
      "Epoch 57/100\n",
      "32/32 - 0s - 967us/step - loss: 0.7223\n",
      "Epoch 58/100\n",
      "32/32 - 0s - 924us/step - loss: 0.7164\n",
      "Epoch 59/100\n",
      "32/32 - 0s - 854us/step - loss: 0.7174\n",
      "Epoch 60/100\n",
      "32/32 - 0s - 876us/step - loss: 0.7184\n",
      "Epoch 61/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7136\n",
      "Epoch 62/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7143\n",
      "Epoch 63/100\n",
      "32/32 - 0s - 977us/step - loss: 0.7149\n",
      "Epoch 64/100\n",
      "32/32 - 0s - 965us/step - loss: 0.7177\n",
      "Epoch 65/100\n",
      "32/32 - 0s - 952us/step - loss: 0.7136\n",
      "Epoch 66/100\n",
      "32/32 - 0s - 999us/step - loss: 0.7100\n",
      "Epoch 67/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7093\n",
      "Epoch 68/100\n",
      "32/32 - 0s - 853us/step - loss: 0.7092\n",
      "Epoch 69/100\n",
      "32/32 - 0s - 853us/step - loss: 0.7083\n",
      "Epoch 70/100\n",
      "32/32 - 0s - 887us/step - loss: 0.7104\n",
      "Epoch 71/100\n",
      "32/32 - 0s - 848us/step - loss: 0.7067\n",
      "Epoch 72/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7084\n",
      "Epoch 73/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7068\n",
      "Epoch 74/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7014\n",
      "Epoch 75/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7059\n",
      "Epoch 76/100\n",
      "32/32 - 0s - 929us/step - loss: 0.7041\n",
      "Epoch 77/100\n",
      "32/32 - 0s - 964us/step - loss: 0.7045\n",
      "Epoch 78/100\n",
      "32/32 - 0s - 847us/step - loss: 0.7019\n",
      "Epoch 79/100\n",
      "32/32 - 0s - 833us/step - loss: 0.6995\n",
      "Epoch 80/100\n",
      "32/32 - 0s - 934us/step - loss: 0.7038\n",
      "Epoch 81/100\n",
      "32/32 - 0s - 892us/step - loss: 0.7030\n",
      "Epoch 82/100\n",
      "32/32 - 0s - 846us/step - loss: 0.7018\n",
      "Epoch 83/100\n",
      "32/32 - 0s - 850us/step - loss: 0.7007\n",
      "Epoch 84/100\n",
      "32/32 - 0s - 833us/step - loss: 0.6998\n",
      "Epoch 85/100\n",
      "32/32 - 0s - 919us/step - loss: 0.6955\n",
      "Epoch 86/100\n",
      "32/32 - 0s - 847us/step - loss: 0.6979\n",
      "Epoch 87/100\n",
      "32/32 - 0s - 851us/step - loss: 0.7005\n",
      "Epoch 88/100\n",
      "32/32 - 0s - 843us/step - loss: 0.7002\n",
      "Epoch 89/100\n",
      "32/32 - 0s - 857us/step - loss: 0.6968\n",
      "Epoch 90/100\n",
      "32/32 - 0s - 876us/step - loss: 0.6948\n",
      "Epoch 91/100\n",
      "32/32 - 0s - 857us/step - loss: 0.6973\n",
      "Epoch 92/100\n",
      "32/32 - 0s - 847us/step - loss: 0.6934\n",
      "Epoch 93/100\n",
      "32/32 - 0s - 833us/step - loss: 0.6982\n",
      "Epoch 94/100\n",
      "32/32 - 0s - 851us/step - loss: 0.6968\n",
      "Epoch 95/100\n",
      "32/32 - 0s - 818us/step - loss: 0.6941\n",
      "Epoch 96/100\n",
      "32/32 - 0s - 862us/step - loss: 0.6940\n",
      "Epoch 97/100\n",
      "32/32 - 0s - 846us/step - loss: 0.6902\n",
      "Epoch 98/100\n",
      "32/32 - 0s - 850us/step - loss: 0.6911\n",
      "Epoch 99/100\n",
      "32/32 - 0s - 902us/step - loss: 0.6897\n",
      "Epoch 100/100\n",
      "32/32 - 0s - 875us/step - loss: 0.6913\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Testing with layers=[64, 32], encoding_dim=10, batch_size=32, epochs=100, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "32/32 - 2s - 59ms/step - loss: 1.2155\n",
      "Epoch 2/100\n",
      "32/32 - 0s - 1ms/step - loss: 1.1087\n",
      "Epoch 3/100\n",
      "32/32 - 0s - 1ms/step - loss: 1.0384\n",
      "Epoch 4/100\n",
      "32/32 - 0s - 940us/step - loss: 0.9922\n",
      "Epoch 5/100\n",
      "32/32 - 0s - 958us/step - loss: 0.9645\n",
      "Epoch 6/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.9404\n",
      "Epoch 7/100\n",
      "32/32 - 0s - 904us/step - loss: 0.9282\n",
      "Epoch 8/100\n",
      "32/32 - 0s - 865us/step - loss: 0.9049\n",
      "Epoch 9/100\n",
      "32/32 - 0s - 826us/step - loss: 0.8966\n",
      "Epoch 10/100\n",
      "32/32 - 0s - 901us/step - loss: 0.8862\n",
      "Epoch 11/100\n",
      "32/32 - 0s - 884us/step - loss: 0.8792\n",
      "Epoch 12/100\n",
      "32/32 - 0s - 904us/step - loss: 0.8684\n",
      "Epoch 13/100\n",
      "32/32 - 0s - 897us/step - loss: 0.8602\n",
      "Epoch 14/100\n",
      "32/32 - 0s - 845us/step - loss: 0.8553\n",
      "Epoch 15/100\n",
      "32/32 - 0s - 860us/step - loss: 0.8476\n",
      "Epoch 16/100\n",
      "32/32 - 0s - 885us/step - loss: 0.8436\n",
      "Epoch 17/100\n",
      "32/32 - 0s - 844us/step - loss: 0.8369\n",
      "Epoch 18/100\n",
      "32/32 - 0s - 890us/step - loss: 0.8308\n",
      "Epoch 19/100\n",
      "32/32 - 0s - 866us/step - loss: 0.8273\n",
      "Epoch 20/100\n",
      "32/32 - 0s - 852us/step - loss: 0.8208\n",
      "Epoch 21/100\n",
      "32/32 - 0s - 907us/step - loss: 0.8136\n",
      "Epoch 22/100\n",
      "32/32 - 0s - 960us/step - loss: 0.8126\n",
      "Epoch 23/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8090\n",
      "Epoch 24/100\n",
      "32/32 - 0s - 999us/step - loss: 0.8101\n",
      "Epoch 25/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8037\n",
      "Epoch 26/100\n",
      "32/32 - 0s - 995us/step - loss: 0.8007\n",
      "Epoch 27/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7958\n",
      "Epoch 28/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8001\n",
      "Epoch 29/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7904\n",
      "Epoch 30/100\n",
      "32/32 - 0s - 943us/step - loss: 0.7940\n",
      "Epoch 31/100\n",
      "32/32 - 0s - 955us/step - loss: 0.7883\n",
      "Epoch 32/100\n",
      "32/32 - 0s - 954us/step - loss: 0.7886\n",
      "Epoch 33/100\n",
      "32/32 - 0s - 853us/step - loss: 0.7859\n",
      "Epoch 34/100\n",
      "32/32 - 0s - 878us/step - loss: 0.7846\n",
      "Epoch 35/100\n",
      "32/32 - 0s - 936us/step - loss: 0.7802\n",
      "Epoch 36/100\n",
      "32/32 - 0s - 980us/step - loss: 0.7821\n",
      "Epoch 37/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7787\n",
      "Epoch 38/100\n",
      "32/32 - 0s - 949us/step - loss: 0.7763\n",
      "Epoch 39/100\n",
      "32/32 - 0s - 898us/step - loss: 0.7786\n",
      "Epoch 40/100\n",
      "32/32 - 0s - 849us/step - loss: 0.7741\n",
      "Epoch 41/100\n",
      "32/32 - 0s - 854us/step - loss: 0.7744\n",
      "Epoch 42/100\n",
      "32/32 - 0s - 835us/step - loss: 0.7712\n",
      "Epoch 43/100\n",
      "32/32 - 0s - 876us/step - loss: 0.7684\n",
      "Epoch 44/100\n",
      "32/32 - 0s - 858us/step - loss: 0.7667\n",
      "Epoch 45/100\n",
      "32/32 - 0s - 859us/step - loss: 0.7721\n",
      "Epoch 46/100\n",
      "32/32 - 0s - 883us/step - loss: 0.7673\n",
      "Epoch 47/100\n",
      "32/32 - 0s - 848us/step - loss: 0.7671\n",
      "Epoch 48/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7699\n",
      "Epoch 49/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7633\n",
      "Epoch 50/100\n",
      "32/32 - 0s - 994us/step - loss: 0.7630\n",
      "Epoch 51/100\n",
      "32/32 - 0s - 982us/step - loss: 0.7639\n",
      "Epoch 52/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7619\n",
      "Epoch 53/100\n",
      "32/32 - 0s - 980us/step - loss: 0.7594\n",
      "Epoch 54/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7581\n",
      "Epoch 55/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7600\n",
      "Epoch 56/100\n",
      "32/32 - 0s - 917us/step - loss: 0.7562\n",
      "Epoch 57/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7576\n",
      "Epoch 58/100\n",
      "32/32 - 0s - 995us/step - loss: 0.7567\n",
      "Epoch 59/100\n",
      "32/32 - 0s - 985us/step - loss: 0.7565\n",
      "Epoch 60/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7525\n",
      "Epoch 61/100\n",
      "32/32 - 0s - 987us/step - loss: 0.7561\n",
      "Epoch 62/100\n",
      "32/32 - 0s - 963us/step - loss: 0.7551\n",
      "Epoch 63/100\n",
      "32/32 - 0s - 981us/step - loss: 0.7501\n",
      "Epoch 64/100\n",
      "32/32 - 0s - 924us/step - loss: 0.7539\n",
      "Epoch 65/100\n",
      "32/32 - 0s - 937us/step - loss: 0.7519\n",
      "Epoch 66/100\n",
      "32/32 - 0s - 860us/step - loss: 0.7531\n",
      "Epoch 67/100\n",
      "32/32 - 0s - 927us/step - loss: 0.7527\n",
      "Epoch 68/100\n",
      "32/32 - 0s - 828us/step - loss: 0.7509\n",
      "Epoch 69/100\n",
      "32/32 - 0s - 842us/step - loss: 0.7474\n",
      "Epoch 70/100\n",
      "32/32 - 0s - 835us/step - loss: 0.7516\n",
      "Epoch 71/100\n",
      "32/32 - 0s - 861us/step - loss: 0.7508\n",
      "Epoch 72/100\n",
      "32/32 - 0s - 859us/step - loss: 0.7501\n",
      "Epoch 73/100\n",
      "32/32 - 0s - 823us/step - loss: 0.7481\n",
      "Epoch 74/100\n",
      "32/32 - 0s - 874us/step - loss: 0.7445\n",
      "Epoch 75/100\n",
      "32/32 - 0s - 850us/step - loss: 0.7477\n",
      "Epoch 76/100\n",
      "32/32 - 0s - 849us/step - loss: 0.7460\n",
      "Epoch 77/100\n",
      "32/32 - 0s - 839us/step - loss: 0.7442\n",
      "Epoch 78/100\n",
      "32/32 - 0s - 841us/step - loss: 0.7447\n",
      "Epoch 79/100\n",
      "32/32 - 0s - 850us/step - loss: 0.7469\n",
      "Epoch 80/100\n",
      "32/32 - 0s - 870us/step - loss: 0.7408\n",
      "Epoch 81/100\n",
      "32/32 - 0s - 863us/step - loss: 0.7429\n",
      "Epoch 82/100\n",
      "32/32 - 0s - 983us/step - loss: 0.7467\n",
      "Epoch 83/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7441\n",
      "Epoch 84/100\n",
      "32/32 - 0s - 978us/step - loss: 0.7396\n",
      "Epoch 85/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7442\n",
      "Epoch 86/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7402\n",
      "Epoch 87/100\n",
      "32/32 - 0s - 915us/step - loss: 0.7418\n",
      "Epoch 88/100\n",
      "32/32 - 0s - 870us/step - loss: 0.7413\n",
      "Epoch 89/100\n",
      "32/32 - 0s - 824us/step - loss: 0.7419\n",
      "Epoch 90/100\n",
      "32/32 - 0s - 916us/step - loss: 0.7388\n",
      "Epoch 91/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7422\n",
      "Epoch 92/100\n",
      "32/32 - 0s - 954us/step - loss: 0.7419\n",
      "Epoch 93/100\n",
      "32/32 - 0s - 961us/step - loss: 0.7362\n",
      "Epoch 94/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7390\n",
      "Epoch 95/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7367\n",
      "Epoch 96/100\n",
      "32/32 - 0s - 923us/step - loss: 0.7367\n",
      "Epoch 97/100\n",
      "32/32 - 0s - 955us/step - loss: 0.7330\n",
      "Epoch 98/100\n",
      "32/32 - 0s - 948us/step - loss: 0.7377\n",
      "Epoch 99/100\n",
      "32/32 - 0s - 902us/step - loss: 0.7370\n",
      "Epoch 100/100\n",
      "32/32 - 0s - 888us/step - loss: 0.7304\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Testing with layers=[64, 32], encoding_dim=10, batch_size=64, epochs=50, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "16/16 - 1s - 64ms/step - loss: 1.2326\n",
      "Epoch 2/50\n",
      "16/16 - 0s - 1ms/step - loss: 1.1460\n",
      "Epoch 3/50\n",
      "16/16 - 0s - 2ms/step - loss: 1.0854\n",
      "Epoch 4/50\n",
      "16/16 - 0s - 1ms/step - loss: 1.0379\n",
      "Epoch 5/50\n",
      "16/16 - 0s - 1ms/step - loss: 1.0013\n",
      "Epoch 6/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.9714\n",
      "Epoch 7/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.9446\n",
      "Epoch 8/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.9265\n",
      "Epoch 9/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.9093\n",
      "Epoch 10/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8971\n",
      "Epoch 11/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8835\n",
      "Epoch 12/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8684\n",
      "Epoch 13/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8582\n",
      "Epoch 14/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8522\n",
      "Epoch 15/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8423\n",
      "Epoch 16/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8311\n",
      "Epoch 17/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8275\n",
      "Epoch 18/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8210\n",
      "Epoch 19/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8120\n",
      "Epoch 20/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8067\n",
      "Epoch 21/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8021\n",
      "Epoch 22/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7989\n",
      "Epoch 23/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7904\n",
      "Epoch 24/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7862\n",
      "Epoch 25/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7874\n",
      "Epoch 26/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7814\n",
      "Epoch 27/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7774\n",
      "Epoch 28/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7719\n",
      "Epoch 29/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7685\n",
      "Epoch 30/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7672\n",
      "Epoch 31/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7660\n",
      "Epoch 32/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7640\n",
      "Epoch 33/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7611\n",
      "Epoch 34/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7584\n",
      "Epoch 35/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7571\n",
      "Epoch 36/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7567\n",
      "Epoch 37/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7543\n",
      "Epoch 38/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7529\n",
      "Epoch 39/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7511\n",
      "Epoch 40/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7489\n",
      "Epoch 41/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7477\n",
      "Epoch 42/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7478\n",
      "Epoch 43/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7421\n",
      "Epoch 44/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7440\n",
      "Epoch 45/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7428\n",
      "Epoch 46/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7379\n",
      "Epoch 47/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7374\n",
      "Epoch 48/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7382\n",
      "Epoch 49/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7393\n",
      "Epoch 50/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7354\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Testing with layers=[64, 32], encoding_dim=10, batch_size=64, epochs=50, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "16/16 - 1s - 63ms/step - loss: 1.2608\n",
      "Epoch 2/50\n",
      "16/16 - 0s - 2ms/step - loss: 1.1837\n",
      "Epoch 3/50\n",
      "16/16 - 0s - 2ms/step - loss: 1.1241\n",
      "Epoch 4/50\n",
      "16/16 - 0s - 2ms/step - loss: 1.0783\n",
      "Epoch 5/50\n",
      "16/16 - 0s - 2ms/step - loss: 1.0418\n",
      "Epoch 6/50\n",
      "16/16 - 0s - 2ms/step - loss: 1.0122\n",
      "Epoch 7/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.9888\n",
      "Epoch 8/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.9698\n",
      "Epoch 9/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.9477\n",
      "Epoch 10/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.9352\n",
      "Epoch 11/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.9274\n",
      "Epoch 12/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.9189\n",
      "Epoch 13/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.9075\n",
      "Epoch 14/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.9016\n",
      "Epoch 15/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8891\n",
      "Epoch 16/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8827\n",
      "Epoch 17/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8763\n",
      "Epoch 18/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8703\n",
      "Epoch 19/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8665\n",
      "Epoch 20/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8598\n",
      "Epoch 21/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8566\n",
      "Epoch 22/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8517\n",
      "Epoch 23/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8471\n",
      "Epoch 24/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8442\n",
      "Epoch 25/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8396\n",
      "Epoch 26/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8355\n",
      "Epoch 27/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8293\n",
      "Epoch 28/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8293\n",
      "Epoch 29/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8258\n",
      "Epoch 30/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8224\n",
      "Epoch 31/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8210\n",
      "Epoch 32/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8170\n",
      "Epoch 33/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8102\n",
      "Epoch 34/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8130\n",
      "Epoch 35/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8077\n",
      "Epoch 36/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8076\n",
      "Epoch 37/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8047\n",
      "Epoch 38/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8018\n",
      "Epoch 39/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8009\n",
      "Epoch 40/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8019\n",
      "Epoch 41/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7976\n",
      "Epoch 42/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7963\n",
      "Epoch 43/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7957\n",
      "Epoch 44/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7924\n",
      "Epoch 45/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7918\n",
      "Epoch 46/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7916\n",
      "Epoch 47/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7910\n",
      "Epoch 48/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7866\n",
      "Epoch 49/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7844\n",
      "Epoch 50/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7865\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Testing with layers=[64, 32], encoding_dim=10, batch_size=64, epochs=100, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "16/16 - 2s - 121ms/step - loss: 1.2213\n",
      "Epoch 2/100\n",
      "16/16 - 0s - 2ms/step - loss: 1.1324\n",
      "Epoch 3/100\n",
      "16/16 - 0s - 2ms/step - loss: 1.0705\n",
      "Epoch 4/100\n",
      "16/16 - 0s - 2ms/step - loss: 1.0266\n",
      "Epoch 5/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.9929\n",
      "Epoch 6/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.9632\n",
      "Epoch 7/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.9425\n",
      "Epoch 8/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.9185\n",
      "Epoch 9/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.9071\n",
      "Epoch 10/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8959\n",
      "Epoch 11/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8835\n",
      "Epoch 12/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8730\n",
      "Epoch 13/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8663\n",
      "Epoch 14/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8532\n",
      "Epoch 15/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8452\n",
      "Epoch 16/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8409\n",
      "Epoch 17/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8301\n",
      "Epoch 18/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8273\n",
      "Epoch 19/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8224\n",
      "Epoch 20/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8132\n",
      "Epoch 21/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8123\n",
      "Epoch 22/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8025\n",
      "Epoch 23/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7973\n",
      "Epoch 24/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7949\n",
      "Epoch 25/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7880\n",
      "Epoch 26/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7864\n",
      "Epoch 27/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7841\n",
      "Epoch 28/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7800\n",
      "Epoch 29/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7745\n",
      "Epoch 30/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7713\n",
      "Epoch 31/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7689\n",
      "Epoch 32/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7696\n",
      "Epoch 33/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7641\n",
      "Epoch 34/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7631\n",
      "Epoch 35/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7585\n",
      "Epoch 36/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7575\n",
      "Epoch 37/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7574\n",
      "Epoch 38/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7528\n",
      "Epoch 39/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7510\n",
      "Epoch 40/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7487\n",
      "Epoch 41/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7496\n",
      "Epoch 42/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7479\n",
      "Epoch 43/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7460\n",
      "Epoch 44/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7452\n",
      "Epoch 45/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7420\n",
      "Epoch 46/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7367\n",
      "Epoch 47/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7377\n",
      "Epoch 48/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7379\n",
      "Epoch 49/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7365\n",
      "Epoch 50/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7339\n",
      "Epoch 51/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7359\n",
      "Epoch 52/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7327\n",
      "Epoch 53/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7316\n",
      "Epoch 54/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7309\n",
      "Epoch 55/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7292\n",
      "Epoch 56/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7257\n",
      "Epoch 57/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7270\n",
      "Epoch 58/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7268\n",
      "Epoch 59/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7261\n",
      "Epoch 60/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7187\n",
      "Epoch 61/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7224\n",
      "Epoch 62/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7226\n",
      "Epoch 63/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7219\n",
      "Epoch 64/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7184\n",
      "Epoch 65/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7212\n",
      "Epoch 66/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7202\n",
      "Epoch 67/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7143\n",
      "Epoch 68/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7159\n",
      "Epoch 69/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7160\n",
      "Epoch 70/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7169\n",
      "Epoch 71/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7162\n",
      "Epoch 72/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7133\n",
      "Epoch 73/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7132\n",
      "Epoch 74/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7146\n",
      "Epoch 75/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7102\n",
      "Epoch 76/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7106\n",
      "Epoch 77/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7125\n",
      "Epoch 78/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7086\n",
      "Epoch 79/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7067\n",
      "Epoch 80/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7053\n",
      "Epoch 81/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7044\n",
      "Epoch 82/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7026\n",
      "Epoch 83/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7023\n",
      "Epoch 84/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7044\n",
      "Epoch 85/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7080\n",
      "Epoch 86/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7028\n",
      "Epoch 87/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7044\n",
      "Epoch 88/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7016\n",
      "Epoch 89/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7019\n",
      "Epoch 90/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6990\n",
      "Epoch 91/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6994\n",
      "Epoch 92/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6996\n",
      "Epoch 93/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6979\n",
      "Epoch 94/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6953\n",
      "Epoch 95/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6952\n",
      "Epoch 96/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6989\n",
      "Epoch 97/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6981\n",
      "Epoch 98/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6921\n",
      "Epoch 99/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6920\n",
      "Epoch 100/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6950\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Testing with layers=[64, 32], encoding_dim=10, batch_size=64, epochs=100, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "16/16 - 1s - 60ms/step - loss: 1.2554\n",
      "Epoch 2/100\n",
      "16/16 - 0s - 1ms/step - loss: 1.1833\n",
      "Epoch 3/100\n",
      "16/16 - 0s - 2ms/step - loss: 1.1225\n",
      "Epoch 4/100\n",
      "16/16 - 0s - 1ms/step - loss: 1.0702\n",
      "Epoch 5/100\n",
      "16/16 - 0s - 1ms/step - loss: 1.0349\n",
      "Epoch 6/100\n",
      "16/16 - 0s - 1ms/step - loss: 1.0030\n",
      "Epoch 7/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.9768\n",
      "Epoch 8/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.9517\n",
      "Epoch 9/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.9331\n",
      "Epoch 10/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.9241\n",
      "Epoch 11/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.9104\n",
      "Epoch 12/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8997\n",
      "Epoch 13/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8909\n",
      "Epoch 14/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8853\n",
      "Epoch 15/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8724\n",
      "Epoch 16/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8684\n",
      "Epoch 17/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8607\n",
      "Epoch 18/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8552\n",
      "Epoch 19/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8466\n",
      "Epoch 20/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8463\n",
      "Epoch 21/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8409\n",
      "Epoch 22/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8331\n",
      "Epoch 23/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8319\n",
      "Epoch 24/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8292\n",
      "Epoch 25/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8266\n",
      "Epoch 26/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8206\n",
      "Epoch 27/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8189\n",
      "Epoch 28/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8122\n",
      "Epoch 29/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8107\n",
      "Epoch 30/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8060\n",
      "Epoch 31/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8070\n",
      "Epoch 32/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8043\n",
      "Epoch 33/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7991\n",
      "Epoch 34/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8005\n",
      "Epoch 35/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7968\n",
      "Epoch 36/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7937\n",
      "Epoch 37/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7962\n",
      "Epoch 38/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7891\n",
      "Epoch 39/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7929\n",
      "Epoch 40/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7882\n",
      "Epoch 41/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7869\n",
      "Epoch 42/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7820\n",
      "Epoch 43/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7833\n",
      "Epoch 44/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7805\n",
      "Epoch 45/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7790\n",
      "Epoch 46/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7749\n",
      "Epoch 47/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7804\n",
      "Epoch 48/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7759\n",
      "Epoch 49/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7732\n",
      "Epoch 50/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7726\n",
      "Epoch 51/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7734\n",
      "Epoch 52/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7761\n",
      "Epoch 53/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7723\n",
      "Epoch 54/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7687\n",
      "Epoch 55/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7660\n",
      "Epoch 56/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7718\n",
      "Epoch 57/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7689\n",
      "Epoch 58/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7677\n",
      "Epoch 59/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7617\n",
      "Epoch 60/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7650\n",
      "Epoch 61/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7631\n",
      "Epoch 62/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7606\n",
      "Epoch 63/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7627\n",
      "Epoch 64/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7589\n",
      "Epoch 65/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7591\n",
      "Epoch 66/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7585\n",
      "Epoch 67/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7564\n",
      "Epoch 68/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7542\n",
      "Epoch 69/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7550\n",
      "Epoch 70/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7556\n",
      "Epoch 71/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7563\n",
      "Epoch 72/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7508\n",
      "Epoch 73/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7518\n",
      "Epoch 74/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7526\n",
      "Epoch 75/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7517\n",
      "Epoch 76/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7517\n",
      "Epoch 77/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7501\n",
      "Epoch 78/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7542\n",
      "Epoch 79/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7502\n",
      "Epoch 80/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7529\n",
      "Epoch 81/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7480\n",
      "Epoch 82/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7463\n",
      "Epoch 83/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7495\n",
      "Epoch 84/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7484\n",
      "Epoch 85/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7501\n",
      "Epoch 86/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7477\n",
      "Epoch 87/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7484\n",
      "Epoch 88/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7444\n",
      "Epoch 89/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7449\n",
      "Epoch 90/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7406\n",
      "Epoch 91/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7424\n",
      "Epoch 92/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7437\n",
      "Epoch 93/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7422\n",
      "Epoch 94/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7416\n",
      "Epoch 95/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7364\n",
      "Epoch 96/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7418\n",
      "Epoch 97/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7399\n",
      "Epoch 98/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7402\n",
      "Epoch 99/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7389\n",
      "Epoch 100/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7397\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Testing with layers=[64, 32], encoding_dim=10, batch_size=128, epochs=50, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "8/8 - 1s - 121ms/step - loss: 1.2748\n",
      "Epoch 2/50\n",
      "8/8 - 0s - 3ms/step - loss: 1.2200\n",
      "Epoch 3/50\n",
      "8/8 - 0s - 3ms/step - loss: 1.1643\n",
      "Epoch 4/50\n",
      "8/8 - 0s - 3ms/step - loss: 1.1218\n",
      "Epoch 5/50\n",
      "8/8 - 0s - 3ms/step - loss: 1.0906\n",
      "Epoch 6/50\n",
      "8/8 - 0s - 4ms/step - loss: 1.0599\n",
      "Epoch 7/50\n",
      "8/8 - 0s - 3ms/step - loss: 1.0341\n",
      "Epoch 8/50\n",
      "8/8 - 0s - 2ms/step - loss: 1.0149\n",
      "Epoch 9/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.9951\n",
      "Epoch 10/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.9777\n",
      "Epoch 11/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.9640\n",
      "Epoch 12/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.9500\n",
      "Epoch 13/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.9384\n",
      "Epoch 14/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.9302\n",
      "Epoch 15/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.9181\n",
      "Epoch 16/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.9104\n",
      "Epoch 17/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.9001\n",
      "Epoch 18/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8944\n",
      "Epoch 19/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8895\n",
      "Epoch 20/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8817\n",
      "Epoch 21/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8762\n",
      "Epoch 22/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8707\n",
      "Epoch 23/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8669\n",
      "Epoch 24/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8580\n",
      "Epoch 25/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8538\n",
      "Epoch 26/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8570\n",
      "Epoch 27/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8483\n",
      "Epoch 28/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8440\n",
      "Epoch 29/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8367\n",
      "Epoch 30/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8371\n",
      "Epoch 31/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8313\n",
      "Epoch 32/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8271\n",
      "Epoch 33/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8233\n",
      "Epoch 34/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8184\n",
      "Epoch 35/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8185\n",
      "Epoch 36/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8145\n",
      "Epoch 37/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8104\n",
      "Epoch 38/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8089\n",
      "Epoch 39/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8045\n",
      "Epoch 40/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7997\n",
      "Epoch 41/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7979\n",
      "Epoch 42/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7970\n",
      "Epoch 43/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7943\n",
      "Epoch 44/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7905\n",
      "Epoch 45/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7879\n",
      "Epoch 46/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7840\n",
      "Epoch 47/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7847\n",
      "Epoch 48/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7774\n",
      "Epoch 49/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7780\n",
      "Epoch 50/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7753\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Testing with layers=[64, 32], encoding_dim=10, batch_size=128, epochs=50, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "8/8 - 2s - 267ms/step - loss: 1.2694\n",
      "Epoch 2/50\n",
      "8/8 - 0s - 3ms/step - loss: 1.2180\n",
      "Epoch 3/50\n",
      "8/8 - 0s - 3ms/step - loss: 1.1745\n",
      "Epoch 4/50\n",
      "8/8 - 0s - 3ms/step - loss: 1.1400\n",
      "Epoch 5/50\n",
      "8/8 - 0s - 3ms/step - loss: 1.1056\n",
      "Epoch 6/50\n",
      "8/8 - 0s - 2ms/step - loss: 1.0800\n",
      "Epoch 7/50\n",
      "8/8 - 0s - 3ms/step - loss: 1.0517\n",
      "Epoch 8/50\n",
      "8/8 - 0s - 3ms/step - loss: 1.0348\n",
      "Epoch 9/50\n",
      "8/8 - 0s - 2ms/step - loss: 1.0120\n",
      "Epoch 10/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.9928\n",
      "Epoch 11/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.9821\n",
      "Epoch 12/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.9668\n",
      "Epoch 13/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.9550\n",
      "Epoch 14/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.9431\n",
      "Epoch 15/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.9337\n",
      "Epoch 16/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.9260\n",
      "Epoch 17/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.9193\n",
      "Epoch 18/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.9126\n",
      "Epoch 19/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.9049\n",
      "Epoch 20/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8968\n",
      "Epoch 21/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8922\n",
      "Epoch 22/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8823\n",
      "Epoch 23/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8803\n",
      "Epoch 24/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8740\n",
      "Epoch 25/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8691\n",
      "Epoch 26/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8655\n",
      "Epoch 27/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8661\n",
      "Epoch 28/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8619\n",
      "Epoch 29/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8522\n",
      "Epoch 30/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8529\n",
      "Epoch 31/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8471\n",
      "Epoch 32/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8464\n",
      "Epoch 33/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8456\n",
      "Epoch 34/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8366\n",
      "Epoch 35/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8417\n",
      "Epoch 36/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8350\n",
      "Epoch 37/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8324\n",
      "Epoch 38/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8310\n",
      "Epoch 39/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8238\n",
      "Epoch 40/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8244\n",
      "Epoch 41/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8239\n",
      "Epoch 42/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8188\n",
      "Epoch 43/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8195\n",
      "Epoch 44/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8182\n",
      "Epoch 45/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8145\n",
      "Epoch 46/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8126\n",
      "Epoch 47/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.8088\n",
      "Epoch 48/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.8081\n",
      "Epoch 49/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8077\n",
      "Epoch 50/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8054\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Testing with layers=[64, 32], encoding_dim=10, batch_size=128, epochs=100, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "8/8 - 1s - 123ms/step - loss: 1.2652\n",
      "Epoch 2/100\n",
      "8/8 - 0s - 3ms/step - loss: 1.2075\n",
      "Epoch 3/100\n",
      "8/8 - 0s - 2ms/step - loss: 1.1584\n",
      "Epoch 4/100\n",
      "8/8 - 0s - 2ms/step - loss: 1.1245\n",
      "Epoch 5/100\n",
      "8/8 - 0s - 2ms/step - loss: 1.0874\n",
      "Epoch 6/100\n",
      "8/8 - 0s - 2ms/step - loss: 1.0623\n",
      "Epoch 7/100\n",
      "8/8 - 0s - 2ms/step - loss: 1.0333\n",
      "Epoch 8/100\n",
      "8/8 - 0s - 2ms/step - loss: 1.0133\n",
      "Epoch 9/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.9913\n",
      "Epoch 10/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.9740\n",
      "Epoch 11/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.9583\n",
      "Epoch 12/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.9491\n",
      "Epoch 13/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.9351\n",
      "Epoch 14/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.9219\n",
      "Epoch 15/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.9108\n",
      "Epoch 16/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.9022\n",
      "Epoch 17/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8940\n",
      "Epoch 18/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8895\n",
      "Epoch 19/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8805\n",
      "Epoch 20/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8706\n",
      "Epoch 21/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8672\n",
      "Epoch 22/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8624\n",
      "Epoch 23/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8565\n",
      "Epoch 24/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8488\n",
      "Epoch 25/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8451\n",
      "Epoch 26/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8388\n",
      "Epoch 27/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8368\n",
      "Epoch 28/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8297\n",
      "Epoch 29/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8279\n",
      "Epoch 30/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8220\n",
      "Epoch 31/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8178\n",
      "Epoch 32/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8125\n",
      "Epoch 33/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8119\n",
      "Epoch 34/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8048\n",
      "Epoch 35/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8012\n",
      "Epoch 36/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7988\n",
      "Epoch 37/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7966\n",
      "Epoch 38/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7946\n",
      "Epoch 39/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7883\n",
      "Epoch 40/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7856\n",
      "Epoch 41/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7865\n",
      "Epoch 42/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7816\n",
      "Epoch 43/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7813\n",
      "Epoch 44/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7761\n",
      "Epoch 45/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7751\n",
      "Epoch 46/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7738\n",
      "Epoch 47/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7698\n",
      "Epoch 48/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7686\n",
      "Epoch 49/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7685\n",
      "Epoch 50/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7639\n",
      "Epoch 51/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7651\n",
      "Epoch 52/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7621\n",
      "Epoch 53/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7607\n",
      "Epoch 54/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7603\n",
      "Epoch 55/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7592\n",
      "Epoch 56/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7582\n",
      "Epoch 57/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7565\n",
      "Epoch 58/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7556\n",
      "Epoch 59/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7527\n",
      "Epoch 60/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7514\n",
      "Epoch 61/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7510\n",
      "Epoch 62/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7474\n",
      "Epoch 63/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7441\n",
      "Epoch 64/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7471\n",
      "Epoch 65/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7447\n",
      "Epoch 66/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7443\n",
      "Epoch 67/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7416\n",
      "Epoch 68/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7406\n",
      "Epoch 69/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7404\n",
      "Epoch 70/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7405\n",
      "Epoch 71/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7417\n",
      "Epoch 72/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7396\n",
      "Epoch 73/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7373\n",
      "Epoch 74/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7379\n",
      "Epoch 75/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7352\n",
      "Epoch 76/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7320\n",
      "Epoch 77/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7345\n",
      "Epoch 78/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7333\n",
      "Epoch 79/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7325\n",
      "Epoch 80/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7347\n",
      "Epoch 81/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7288\n",
      "Epoch 82/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7314\n",
      "Epoch 83/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7282\n",
      "Epoch 84/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7297\n",
      "Epoch 85/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7266\n",
      "Epoch 86/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7268\n",
      "Epoch 87/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7259\n",
      "Epoch 88/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7254\n",
      "Epoch 89/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7253\n",
      "Epoch 90/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7256\n",
      "Epoch 91/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7242\n",
      "Epoch 92/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7234\n",
      "Epoch 93/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7216\n",
      "Epoch 94/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7192\n",
      "Epoch 95/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7230\n",
      "Epoch 96/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7195\n",
      "Epoch 97/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7188\n",
      "Epoch 98/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7184\n",
      "Epoch 99/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7168\n",
      "Epoch 100/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7185\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Testing with layers=[64, 32], encoding_dim=10, batch_size=128, epochs=100, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "8/8 - 1s - 137ms/step - loss: 1.2734\n",
      "Epoch 2/100\n",
      "8/8 - 0s - 2ms/step - loss: 1.2265\n",
      "Epoch 3/100\n",
      "8/8 - 0s - 2ms/step - loss: 1.1788\n",
      "Epoch 4/100\n",
      "8/8 - 0s - 2ms/step - loss: 1.1391\n",
      "Epoch 5/100\n",
      "8/8 - 0s - 2ms/step - loss: 1.1052\n",
      "Epoch 6/100\n",
      "8/8 - 0s - 2ms/step - loss: 1.0800\n",
      "Epoch 7/100\n",
      "8/8 - 0s - 2ms/step - loss: 1.0581\n",
      "Epoch 8/100\n",
      "8/8 - 0s - 3ms/step - loss: 1.0360\n",
      "Epoch 9/100\n",
      "8/8 - 0s - 2ms/step - loss: 1.0147\n",
      "Epoch 10/100\n",
      "8/8 - 0s - 2ms/step - loss: 1.0026\n",
      "Epoch 11/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.9845\n",
      "Epoch 12/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.9703\n",
      "Epoch 13/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.9587\n",
      "Epoch 14/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.9503\n",
      "Epoch 15/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.9383\n",
      "Epoch 16/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.9321\n",
      "Epoch 17/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.9233\n",
      "Epoch 18/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.9177\n",
      "Epoch 19/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.9118\n",
      "Epoch 20/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.9040\n",
      "Epoch 21/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.9010\n",
      "Epoch 22/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8929\n",
      "Epoch 23/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8858\n",
      "Epoch 24/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8843\n",
      "Epoch 25/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8798\n",
      "Epoch 26/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8768\n",
      "Epoch 27/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8668\n",
      "Epoch 28/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8710\n",
      "Epoch 29/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8653\n",
      "Epoch 30/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8586\n",
      "Epoch 31/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8544\n",
      "Epoch 32/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8522\n",
      "Epoch 33/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8451\n",
      "Epoch 34/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8457\n",
      "Epoch 35/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8455\n",
      "Epoch 36/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8384\n",
      "Epoch 37/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8340\n",
      "Epoch 38/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8330\n",
      "Epoch 39/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8294\n",
      "Epoch 40/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8299\n",
      "Epoch 41/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8258\n",
      "Epoch 42/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8240\n",
      "Epoch 43/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8214\n",
      "Epoch 44/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8200\n",
      "Epoch 45/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8169\n",
      "Epoch 46/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8177\n",
      "Epoch 47/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8122\n",
      "Epoch 48/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8082\n",
      "Epoch 49/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8081\n",
      "Epoch 50/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8069\n",
      "Epoch 51/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8010\n",
      "Epoch 52/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8042\n",
      "Epoch 53/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8004\n",
      "Epoch 54/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7987\n",
      "Epoch 55/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7958\n",
      "Epoch 56/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7923\n",
      "Epoch 57/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7963\n",
      "Epoch 58/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7904\n",
      "Epoch 59/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7919\n",
      "Epoch 60/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7919\n",
      "Epoch 61/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7923\n",
      "Epoch 62/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7877\n",
      "Epoch 63/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7860\n",
      "Epoch 64/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7882\n",
      "Epoch 65/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7819\n",
      "Epoch 66/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7818\n",
      "Epoch 67/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7835\n",
      "Epoch 68/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7794\n",
      "Epoch 69/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7776\n",
      "Epoch 70/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7794\n",
      "Epoch 71/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7763\n",
      "Epoch 72/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7774\n",
      "Epoch 73/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7755\n",
      "Epoch 74/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7718\n",
      "Epoch 75/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7752\n",
      "Epoch 76/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7723\n",
      "Epoch 77/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7720\n",
      "Epoch 78/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7715\n",
      "Epoch 79/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7719\n",
      "Epoch 80/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7689\n",
      "Epoch 81/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7685\n",
      "Epoch 82/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7705\n",
      "Epoch 83/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7671\n",
      "Epoch 84/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7650\n",
      "Epoch 85/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7688\n",
      "Epoch 86/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7648\n",
      "Epoch 87/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7636\n",
      "Epoch 88/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7623\n",
      "Epoch 89/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7616\n",
      "Epoch 90/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7642\n",
      "Epoch 91/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7603\n",
      "Epoch 92/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7581\n",
      "Epoch 93/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7607\n",
      "Epoch 94/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7568\n",
      "Epoch 95/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7608\n",
      "Epoch 96/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7581\n",
      "Epoch 97/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7581\n",
      "Epoch 98/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7576\n",
      "Epoch 99/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7560\n",
      "Epoch 100/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7544\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Testing with layers=[64, 32], encoding_dim=12, batch_size=32, epochs=50, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "32/32 - 1s - 32ms/step - loss: 1.2121\n",
      "Epoch 2/50\n",
      "32/32 - 0s - 992us/step - loss: 1.0792\n",
      "Epoch 3/50\n",
      "32/32 - 0s - 1ms/step - loss: 1.0027\n",
      "Epoch 4/50\n",
      "32/32 - 0s - 834us/step - loss: 0.9534\n",
      "Epoch 5/50\n",
      "32/32 - 0s - 895us/step - loss: 0.9154\n",
      "Epoch 6/50\n",
      "32/32 - 0s - 820us/step - loss: 0.8888\n",
      "Epoch 7/50\n",
      "32/32 - 0s - 840us/step - loss: 0.8754\n",
      "Epoch 8/50\n",
      "32/32 - 0s - 928us/step - loss: 0.8555\n",
      "Epoch 9/50\n",
      "32/32 - 0s - 812us/step - loss: 0.8465\n",
      "Epoch 10/50\n",
      "32/32 - 0s - 832us/step - loss: 0.8346\n",
      "Epoch 11/50\n",
      "32/32 - 0s - 809us/step - loss: 0.8236\n",
      "Epoch 12/50\n",
      "32/32 - 0s - 857us/step - loss: 0.8140\n",
      "Epoch 13/50\n",
      "32/32 - 0s - 830us/step - loss: 0.8097\n",
      "Epoch 14/50\n",
      "32/32 - 0s - 797us/step - loss: 0.7973\n",
      "Epoch 15/50\n",
      "32/32 - 0s - 820us/step - loss: 0.7952\n",
      "Epoch 16/50\n",
      "32/32 - 0s - 829us/step - loss: 0.7886\n",
      "Epoch 17/50\n",
      "32/32 - 0s - 795us/step - loss: 0.7786\n",
      "Epoch 18/50\n",
      "32/32 - 0s - 832us/step - loss: 0.7752\n",
      "Epoch 19/50\n",
      "32/32 - 0s - 834us/step - loss: 0.7676\n",
      "Epoch 20/50\n",
      "32/32 - 0s - 914us/step - loss: 0.7689\n",
      "Epoch 21/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7624\n",
      "Epoch 22/50\n",
      "32/32 - 0s - 839us/step - loss: 0.7549\n",
      "Epoch 23/50\n",
      "32/32 - 0s - 818us/step - loss: 0.7516\n",
      "Epoch 24/50\n",
      "32/32 - 0s - 886us/step - loss: 0.7466\n",
      "Epoch 25/50\n",
      "32/32 - 0s - 805us/step - loss: 0.7452\n",
      "Epoch 26/50\n",
      "32/32 - 0s - 829us/step - loss: 0.7415\n",
      "Epoch 27/50\n",
      "32/32 - 0s - 817us/step - loss: 0.7392\n",
      "Epoch 28/50\n",
      "32/32 - 0s - 842us/step - loss: 0.7356\n",
      "Epoch 29/50\n",
      "32/32 - 0s - 801us/step - loss: 0.7328\n",
      "Epoch 30/50\n",
      "32/32 - 0s - 807us/step - loss: 0.7296\n",
      "Epoch 31/50\n",
      "32/32 - 0s - 906us/step - loss: 0.7281\n",
      "Epoch 32/50\n",
      "32/32 - 0s - 803us/step - loss: 0.7230\n",
      "Epoch 33/50\n",
      "32/32 - 0s - 818us/step - loss: 0.7237\n",
      "Epoch 34/50\n",
      "32/32 - 0s - 838us/step - loss: 0.7211\n",
      "Epoch 35/50\n",
      "32/32 - 0s - 877us/step - loss: 0.7213\n",
      "Epoch 36/50\n",
      "32/32 - 0s - 802us/step - loss: 0.7219\n",
      "Epoch 37/50\n",
      "32/32 - 0s - 873us/step - loss: 0.7182\n",
      "Epoch 38/50\n",
      "32/32 - 0s - 817us/step - loss: 0.7182\n",
      "Epoch 39/50\n",
      "32/32 - 0s - 795us/step - loss: 0.7143\n",
      "Epoch 40/50\n",
      "32/32 - 0s - 837us/step - loss: 0.7116\n",
      "Epoch 41/50\n",
      "32/32 - 0s - 800us/step - loss: 0.7110\n",
      "Epoch 42/50\n",
      "32/32 - 0s - 836us/step - loss: 0.7110\n",
      "Epoch 43/50\n",
      "32/32 - 0s - 846us/step - loss: 0.7083\n",
      "Epoch 44/50\n",
      "32/32 - 0s - 830us/step - loss: 0.7091\n",
      "Epoch 45/50\n",
      "32/32 - 0s - 814us/step - loss: 0.7080\n",
      "Epoch 46/50\n",
      "32/32 - 0s - 842us/step - loss: 0.7022\n",
      "Epoch 47/50\n",
      "32/32 - 0s - 800us/step - loss: 0.7046\n",
      "Epoch 48/50\n",
      "32/32 - 0s - 904us/step - loss: 0.7047\n",
      "Epoch 49/50\n",
      "32/32 - 0s - 817us/step - loss: 0.7029\n",
      "Epoch 50/50\n",
      "32/32 - 0s - 838us/step - loss: 0.7009\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Testing with layers=[64, 32], encoding_dim=12, batch_size=32, epochs=50, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "32/32 - 1s - 32ms/step - loss: 1.2185\n",
      "Epoch 2/50\n",
      "32/32 - 0s - 996us/step - loss: 1.1071\n",
      "Epoch 3/50\n",
      "32/32 - 0s - 1ms/step - loss: 1.0346\n",
      "Epoch 4/50\n",
      "32/32 - 0s - 822us/step - loss: 0.9976\n",
      "Epoch 5/50\n",
      "32/32 - 0s - 877us/step - loss: 0.9649\n",
      "Epoch 6/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.9441\n",
      "Epoch 7/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.9248\n",
      "Epoch 8/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.9138\n",
      "Epoch 9/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.9042\n",
      "Epoch 10/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8905\n",
      "Epoch 11/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8839\n",
      "Epoch 12/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8718\n",
      "Epoch 13/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8649\n",
      "Epoch 14/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8604\n",
      "Epoch 15/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8499\n",
      "Epoch 16/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8465\n",
      "Epoch 17/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8391\n",
      "Epoch 18/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8344\n",
      "Epoch 19/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8328\n",
      "Epoch 20/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.8243\n",
      "Epoch 21/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8225\n",
      "Epoch 22/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8122\n",
      "Epoch 23/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8087\n",
      "Epoch 24/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8021\n",
      "Epoch 25/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8034\n",
      "Epoch 26/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7982\n",
      "Epoch 27/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7901\n",
      "Epoch 28/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7914\n",
      "Epoch 29/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7895\n",
      "Epoch 30/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7782\n",
      "Epoch 31/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7799\n",
      "Epoch 32/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7750\n",
      "Epoch 33/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7748\n",
      "Epoch 34/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7722\n",
      "Epoch 35/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7690\n",
      "Epoch 36/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7701\n",
      "Epoch 37/50\n",
      "32/32 - 0s - 966us/step - loss: 0.7650\n",
      "Epoch 38/50\n",
      "32/32 - 0s - 944us/step - loss: 0.7618\n",
      "Epoch 39/50\n",
      "32/32 - 0s - 925us/step - loss: 0.7610\n",
      "Epoch 40/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7603\n",
      "Epoch 41/50\n",
      "32/32 - 0s - 997us/step - loss: 0.7568\n",
      "Epoch 42/50\n",
      "32/32 - 0s - 959us/step - loss: 0.7587\n",
      "Epoch 43/50\n",
      "32/32 - 0s - 877us/step - loss: 0.7602\n",
      "Epoch 44/50\n",
      "32/32 - 0s - 798us/step - loss: 0.7510\n",
      "Epoch 45/50\n",
      "32/32 - 0s - 813us/step - loss: 0.7529\n",
      "Epoch 46/50\n",
      "32/32 - 0s - 928us/step - loss: 0.7477\n",
      "Epoch 47/50\n",
      "32/32 - 0s - 949us/step - loss: 0.7503\n",
      "Epoch 48/50\n",
      "32/32 - 0s - 801us/step - loss: 0.7504\n",
      "Epoch 49/50\n",
      "32/32 - 0s - 834us/step - loss: 0.7466\n",
      "Epoch 50/50\n",
      "32/32 - 0s - 869us/step - loss: 0.7503\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Testing with layers=[64, 32], encoding_dim=12, batch_size=32, epochs=100, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "32/32 - 1s - 45ms/step - loss: 1.2167\n",
      "Epoch 2/100\n",
      "32/32 - 0s - 1ms/step - loss: 1.0820\n",
      "Epoch 3/100\n",
      "32/32 - 0s - 878us/step - loss: 1.0036\n",
      "Epoch 4/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.9523\n",
      "Epoch 5/100\n",
      "32/32 - 0s - 893us/step - loss: 0.9187\n",
      "Epoch 6/100\n",
      "32/32 - 0s - 860us/step - loss: 0.8928\n",
      "Epoch 7/100\n",
      "32/32 - 0s - 882us/step - loss: 0.8743\n",
      "Epoch 8/100\n",
      "32/32 - 0s - 906us/step - loss: 0.8579\n",
      "Epoch 9/100\n",
      "32/32 - 0s - 881us/step - loss: 0.8466\n",
      "Epoch 10/100\n",
      "32/32 - 0s - 850us/step - loss: 0.8368\n",
      "Epoch 11/100\n",
      "32/32 - 0s - 836us/step - loss: 0.8234\n",
      "Epoch 12/100\n",
      "32/32 - 0s - 927us/step - loss: 0.8159\n",
      "Epoch 13/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8062\n",
      "Epoch 14/100\n",
      "32/32 - 0s - 860us/step - loss: 0.7948\n",
      "Epoch 15/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7886\n",
      "Epoch 16/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7832\n",
      "Epoch 17/100\n",
      "32/32 - 0s - 861us/step - loss: 0.7790\n",
      "Epoch 18/100\n",
      "32/32 - 0s - 873us/step - loss: 0.7744\n",
      "Epoch 19/100\n",
      "32/32 - 0s - 839us/step - loss: 0.7707\n",
      "Epoch 20/100\n",
      "32/32 - 0s - 844us/step - loss: 0.7677\n",
      "Epoch 21/100\n",
      "32/32 - 0s - 904us/step - loss: 0.7634\n",
      "Epoch 22/100\n",
      "32/32 - 0s - 852us/step - loss: 0.7549\n",
      "Epoch 23/100\n",
      "32/32 - 0s - 836us/step - loss: 0.7498\n",
      "Epoch 24/100\n",
      "32/32 - 0s - 897us/step - loss: 0.7534\n",
      "Epoch 25/100\n",
      "32/32 - 0s - 886us/step - loss: 0.7498\n",
      "Epoch 26/100\n",
      "32/32 - 0s - 846us/step - loss: 0.7459\n",
      "Epoch 27/100\n",
      "32/32 - 0s - 842us/step - loss: 0.7443\n",
      "Epoch 28/100\n",
      "32/32 - 0s - 820us/step - loss: 0.7373\n",
      "Epoch 29/100\n",
      "32/32 - 0s - 865us/step - loss: 0.7356\n",
      "Epoch 30/100\n",
      "32/32 - 0s - 818us/step - loss: 0.7368\n",
      "Epoch 31/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7324\n",
      "Epoch 32/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7335\n",
      "Epoch 33/100\n",
      "32/32 - 0s - 889us/step - loss: 0.7295\n",
      "Epoch 34/100\n",
      "32/32 - 0s - 880us/step - loss: 0.7292\n",
      "Epoch 35/100\n",
      "32/32 - 0s - 914us/step - loss: 0.7265\n",
      "Epoch 36/100\n",
      "32/32 - 0s - 974us/step - loss: 0.7241\n",
      "Epoch 37/100\n",
      "32/32 - 0s - 874us/step - loss: 0.7250\n",
      "Epoch 38/100\n",
      "32/32 - 0s - 961us/step - loss: 0.7209\n",
      "Epoch 39/100\n",
      "32/32 - 0s - 849us/step - loss: 0.7151\n",
      "Epoch 40/100\n",
      "32/32 - 0s - 858us/step - loss: 0.7201\n",
      "Epoch 41/100\n",
      "32/32 - 0s - 977us/step - loss: 0.7157\n",
      "Epoch 42/100\n",
      "32/32 - 0s - 833us/step - loss: 0.7138\n",
      "Epoch 43/100\n",
      "32/32 - 0s - 840us/step - loss: 0.7141\n",
      "Epoch 44/100\n",
      "32/32 - 0s - 816us/step - loss: 0.7116\n",
      "Epoch 45/100\n",
      "32/32 - 0s - 840us/step - loss: 0.7097\n",
      "Epoch 46/100\n",
      "32/32 - 0s - 830us/step - loss: 0.7090\n",
      "Epoch 47/100\n",
      "32/32 - 0s - 829us/step - loss: 0.7061\n",
      "Epoch 48/100\n",
      "32/32 - 0s - 866us/step - loss: 0.7055\n",
      "Epoch 49/100\n",
      "32/32 - 0s - 846us/step - loss: 0.7044\n",
      "Epoch 50/100\n",
      "32/32 - 0s - 857us/step - loss: 0.7046\n",
      "Epoch 51/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7016\n",
      "Epoch 52/100\n",
      "32/32 - 0s - 843us/step - loss: 0.7018\n",
      "Epoch 53/100\n",
      "32/32 - 0s - 872us/step - loss: 0.6986\n",
      "Epoch 54/100\n",
      "32/32 - 0s - 834us/step - loss: 0.7037\n",
      "Epoch 55/100\n",
      "32/32 - 0s - 913us/step - loss: 0.7012\n",
      "Epoch 56/100\n",
      "32/32 - 0s - 810us/step - loss: 0.6986\n",
      "Epoch 57/100\n",
      "32/32 - 0s - 859us/step - loss: 0.6976\n",
      "Epoch 58/100\n",
      "32/32 - 0s - 831us/step - loss: 0.6962\n",
      "Epoch 59/100\n",
      "32/32 - 0s - 833us/step - loss: 0.6982\n",
      "Epoch 60/100\n",
      "32/32 - 0s - 827us/step - loss: 0.6995\n",
      "Epoch 61/100\n",
      "32/32 - 0s - 852us/step - loss: 0.6963\n",
      "Epoch 62/100\n",
      "32/32 - 0s - 799us/step - loss: 0.6939\n",
      "Epoch 63/100\n",
      "32/32 - 0s - 916us/step - loss: 0.6915\n",
      "Epoch 64/100\n",
      "32/32 - 0s - 847us/step - loss: 0.6935\n",
      "Epoch 65/100\n",
      "32/32 - 0s - 857us/step - loss: 0.6961\n",
      "Epoch 66/100\n",
      "32/32 - 0s - 853us/step - loss: 0.6899\n",
      "Epoch 67/100\n",
      "32/32 - 0s - 826us/step - loss: 0.6933\n",
      "Epoch 68/100\n",
      "32/32 - 0s - 968us/step - loss: 0.6906\n",
      "Epoch 69/100\n",
      "32/32 - 0s - 827us/step - loss: 0.6926\n",
      "Epoch 70/100\n",
      "32/32 - 0s - 942us/step - loss: 0.6901\n",
      "Epoch 71/100\n",
      "32/32 - 0s - 949us/step - loss: 0.6888\n",
      "Epoch 72/100\n",
      "32/32 - 0s - 887us/step - loss: 0.6897\n",
      "Epoch 73/100\n",
      "32/32 - 0s - 898us/step - loss: 0.6859\n",
      "Epoch 74/100\n",
      "32/32 - 0s - 929us/step - loss: 0.6883\n",
      "Epoch 75/100\n",
      "32/32 - 0s - 935us/step - loss: 0.6890\n",
      "Epoch 76/100\n",
      "32/32 - 0s - 990us/step - loss: 0.6874\n",
      "Epoch 77/100\n",
      "32/32 - 0s - 955us/step - loss: 0.6891\n",
      "Epoch 78/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6863\n",
      "Epoch 79/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6864\n",
      "Epoch 80/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6841\n",
      "Epoch 81/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6833\n",
      "Epoch 82/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6828\n",
      "Epoch 83/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6881\n",
      "Epoch 84/100\n",
      "32/32 - 0s - 990us/step - loss: 0.6818\n",
      "Epoch 85/100\n",
      "32/32 - 0s - 930us/step - loss: 0.6824\n",
      "Epoch 86/100\n",
      "32/32 - 0s - 956us/step - loss: 0.6825\n",
      "Epoch 87/100\n",
      "32/32 - 0s - 914us/step - loss: 0.6825\n",
      "Epoch 88/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6832\n",
      "Epoch 89/100\n",
      "32/32 - 0s - 5ms/step - loss: 0.6819\n",
      "Epoch 90/100\n",
      "32/32 - 0s - 6ms/step - loss: 0.6824\n",
      "Epoch 91/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6835\n",
      "Epoch 92/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6832\n",
      "Epoch 93/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6819\n",
      "Epoch 94/100\n",
      "32/32 - 0s - 877us/step - loss: 0.6782\n",
      "Epoch 95/100\n",
      "32/32 - 0s - 962us/step - loss: 0.6797\n",
      "Epoch 96/100\n",
      "32/32 - 0s - 891us/step - loss: 0.6795\n",
      "Epoch 97/100\n",
      "32/32 - 0s - 985us/step - loss: 0.6837\n",
      "Epoch 98/100\n",
      "32/32 - 0s - 917us/step - loss: 0.6796\n",
      "Epoch 99/100\n",
      "32/32 - 0s - 858us/step - loss: 0.6786\n",
      "Epoch 100/100\n",
      "32/32 - 0s - 861us/step - loss: 0.6792\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Testing with layers=[64, 32], encoding_dim=12, batch_size=32, epochs=100, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "32/32 - 1s - 36ms/step - loss: 1.2318\n",
      "Epoch 2/100\n",
      "32/32 - 0s - 1ms/step - loss: 1.1181\n",
      "Epoch 3/100\n",
      "32/32 - 0s - 1ms/step - loss: 1.0442\n",
      "Epoch 4/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.9984\n",
      "Epoch 5/100\n",
      "32/32 - 0s - 991us/step - loss: 0.9689\n",
      "Epoch 6/100\n",
      "32/32 - 0s - 880us/step - loss: 0.9468\n",
      "Epoch 7/100\n",
      "32/32 - 0s - 829us/step - loss: 0.9288\n",
      "Epoch 8/100\n",
      "32/32 - 0s - 849us/step - loss: 0.9180\n",
      "Epoch 9/100\n",
      "32/32 - 0s - 894us/step - loss: 0.9087\n",
      "Epoch 10/100\n",
      "32/32 - 0s - 832us/step - loss: 0.8948\n",
      "Epoch 11/100\n",
      "32/32 - 0s - 836us/step - loss: 0.8877\n",
      "Epoch 12/100\n",
      "32/32 - 0s - 830us/step - loss: 0.8816\n",
      "Epoch 13/100\n",
      "32/32 - 0s - 825us/step - loss: 0.8693\n",
      "Epoch 14/100\n",
      "32/32 - 0s - 860us/step - loss: 0.8671\n",
      "Epoch 15/100\n",
      "32/32 - 0s - 914us/step - loss: 0.8599\n",
      "Epoch 16/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8555\n",
      "Epoch 17/100\n",
      "32/32 - 0s - 977us/step - loss: 0.8493\n",
      "Epoch 18/100\n",
      "32/32 - 0s - 871us/step - loss: 0.8462\n",
      "Epoch 19/100\n",
      "32/32 - 0s - 860us/step - loss: 0.8344\n",
      "Epoch 20/100\n",
      "32/32 - 0s - 840us/step - loss: 0.8283\n",
      "Epoch 21/100\n",
      "32/32 - 0s - 807us/step - loss: 0.8298\n",
      "Epoch 22/100\n",
      "32/32 - 0s - 945us/step - loss: 0.8245\n",
      "Epoch 23/100\n",
      "32/32 - 0s - 830us/step - loss: 0.8186\n",
      "Epoch 24/100\n",
      "32/32 - 0s - 815us/step - loss: 0.8196\n",
      "Epoch 25/100\n",
      "32/32 - 0s - 926us/step - loss: 0.8116\n",
      "Epoch 26/100\n",
      "32/32 - 0s - 948us/step - loss: 0.8038\n",
      "Epoch 27/100\n",
      "32/32 - 0s - 868us/step - loss: 0.8035\n",
      "Epoch 28/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7989\n",
      "Epoch 29/100\n",
      "32/32 - 0s - 947us/step - loss: 0.7965\n",
      "Epoch 30/100\n",
      "32/32 - 0s - 909us/step - loss: 0.7925\n",
      "Epoch 31/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7932\n",
      "Epoch 32/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7879\n",
      "Epoch 33/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7860\n",
      "Epoch 34/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7831\n",
      "Epoch 35/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7787\n",
      "Epoch 36/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7765\n",
      "Epoch 37/100\n",
      "32/32 - 0s - 837us/step - loss: 0.7720\n",
      "Epoch 38/100\n",
      "32/32 - 0s - 832us/step - loss: 0.7722\n",
      "Epoch 39/100\n",
      "32/32 - 0s - 840us/step - loss: 0.7711\n",
      "Epoch 40/100\n",
      "32/32 - 0s - 836us/step - loss: 0.7690\n",
      "Epoch 41/100\n",
      "32/32 - 0s - 819us/step - loss: 0.7695\n",
      "Epoch 42/100\n",
      "32/32 - 0s - 827us/step - loss: 0.7664\n",
      "Epoch 43/100\n",
      "32/32 - 0s - 852us/step - loss: 0.7652\n",
      "Epoch 44/100\n",
      "32/32 - 0s - 861us/step - loss: 0.7630\n",
      "Epoch 45/100\n",
      "32/32 - 0s - 827us/step - loss: 0.7600\n",
      "Epoch 46/100\n",
      "32/32 - 0s - 917us/step - loss: 0.7612\n",
      "Epoch 47/100\n",
      "32/32 - 0s - 835us/step - loss: 0.7556\n",
      "Epoch 48/100\n",
      "32/32 - 0s - 824us/step - loss: 0.7594\n",
      "Epoch 49/100\n",
      "32/32 - 0s - 889us/step - loss: 0.7556\n",
      "Epoch 50/100\n",
      "32/32 - 0s - 849us/step - loss: 0.7560\n",
      "Epoch 51/100\n",
      "32/32 - 0s - 844us/step - loss: 0.7518\n",
      "Epoch 52/100\n",
      "32/32 - 0s - 853us/step - loss: 0.7520\n",
      "Epoch 53/100\n",
      "32/32 - 0s - 901us/step - loss: 0.7514\n",
      "Epoch 54/100\n",
      "32/32 - 0s - 861us/step - loss: 0.7453\n",
      "Epoch 55/100\n",
      "32/32 - 0s - 861us/step - loss: 0.7476\n",
      "Epoch 56/100\n",
      "32/32 - 0s - 826us/step - loss: 0.7485\n",
      "Epoch 57/100\n",
      "32/32 - 0s - 829us/step - loss: 0.7491\n",
      "Epoch 58/100\n",
      "32/32 - 0s - 824us/step - loss: 0.7421\n",
      "Epoch 59/100\n",
      "32/32 - 0s - 845us/step - loss: 0.7460\n",
      "Epoch 60/100\n",
      "32/32 - 0s - 846us/step - loss: 0.7435\n",
      "Epoch 61/100\n",
      "32/32 - 0s - 877us/step - loss: 0.7442\n",
      "Epoch 62/100\n",
      "32/32 - 0s - 878us/step - loss: 0.7463\n",
      "Epoch 63/100\n",
      "32/32 - 0s - 851us/step - loss: 0.7403\n",
      "Epoch 64/100\n",
      "32/32 - 0s - 903us/step - loss: 0.7354\n",
      "Epoch 65/100\n",
      "32/32 - 0s - 843us/step - loss: 0.7405\n",
      "Epoch 66/100\n",
      "32/32 - 0s - 923us/step - loss: 0.7360\n",
      "Epoch 67/100\n",
      "32/32 - 0s - 809us/step - loss: 0.7382\n",
      "Epoch 68/100\n",
      "32/32 - 0s - 849us/step - loss: 0.7376\n",
      "Epoch 69/100\n",
      "32/32 - 0s - 917us/step - loss: 0.7367\n",
      "Epoch 70/100\n",
      "32/32 - 0s - 827us/step - loss: 0.7300\n",
      "Epoch 71/100\n",
      "32/32 - 0s - 838us/step - loss: 0.7317\n",
      "Epoch 72/100\n",
      "32/32 - 0s - 815us/step - loss: 0.7299\n",
      "Epoch 73/100\n",
      "32/32 - 0s - 849us/step - loss: 0.7297\n",
      "Epoch 74/100\n",
      "32/32 - 0s - 809us/step - loss: 0.7340\n",
      "Epoch 75/100\n",
      "32/32 - 0s - 843us/step - loss: 0.7332\n",
      "Epoch 76/100\n",
      "32/32 - 0s - 904us/step - loss: 0.7315\n",
      "Epoch 77/100\n",
      "32/32 - 0s - 826us/step - loss: 0.7288\n",
      "Epoch 78/100\n",
      "32/32 - 0s - 820us/step - loss: 0.7249\n",
      "Epoch 79/100\n",
      "32/32 - 0s - 924us/step - loss: 0.7313\n",
      "Epoch 80/100\n",
      "32/32 - 0s - 938us/step - loss: 0.7268\n",
      "Epoch 81/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7256\n",
      "Epoch 82/100\n",
      "32/32 - 0s - 887us/step - loss: 0.7274\n",
      "Epoch 83/100\n",
      "32/32 - 0s - 837us/step - loss: 0.7274\n",
      "Epoch 84/100\n",
      "32/32 - 0s - 889us/step - loss: 0.7287\n",
      "Epoch 85/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7268\n",
      "Epoch 86/100\n",
      "32/32 - 0s - 870us/step - loss: 0.7240\n",
      "Epoch 87/100\n",
      "32/32 - 0s - 887us/step - loss: 0.7205\n",
      "Epoch 88/100\n",
      "32/32 - 0s - 894us/step - loss: 0.7261\n",
      "Epoch 89/100\n",
      "32/32 - 0s - 840us/step - loss: 0.7230\n",
      "Epoch 90/100\n",
      "32/32 - 0s - 824us/step - loss: 0.7214\n",
      "Epoch 91/100\n",
      "32/32 - 0s - 995us/step - loss: 0.7246\n",
      "Epoch 92/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7228\n",
      "Epoch 93/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7265\n",
      "Epoch 94/100\n",
      "32/32 - 0s - 915us/step - loss: 0.7226\n",
      "Epoch 95/100\n",
      "32/32 - 0s - 953us/step - loss: 0.7228\n",
      "Epoch 96/100\n",
      "32/32 - 0s - 858us/step - loss: 0.7210\n",
      "Epoch 97/100\n",
      "32/32 - 0s - 912us/step - loss: 0.7226\n",
      "Epoch 98/100\n",
      "32/32 - 0s - 943us/step - loss: 0.7184\n",
      "Epoch 99/100\n",
      "32/32 - 0s - 882us/step - loss: 0.7201\n",
      "Epoch 100/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7151\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Testing with layers=[64, 32], encoding_dim=12, batch_size=64, epochs=50, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "16/16 - 1s - 81ms/step - loss: 1.2326\n",
      "Epoch 2/50\n",
      "16/16 - 0s - 3ms/step - loss: 1.1419\n",
      "Epoch 3/50\n",
      "16/16 - 0s - 2ms/step - loss: 1.0766\n",
      "Epoch 4/50\n",
      "16/16 - 0s - 2ms/step - loss: 1.0249\n",
      "Epoch 5/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.9850\n",
      "Epoch 6/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.9595\n",
      "Epoch 7/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.9328\n",
      "Epoch 8/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.9124\n",
      "Epoch 9/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8946\n",
      "Epoch 10/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8817\n",
      "Epoch 11/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8676\n",
      "Epoch 12/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8539\n",
      "Epoch 13/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8442\n",
      "Epoch 14/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8374\n",
      "Epoch 15/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8297\n",
      "Epoch 16/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8212\n",
      "Epoch 17/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8154\n",
      "Epoch 18/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8075\n",
      "Epoch 19/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8039\n",
      "Epoch 20/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7978\n",
      "Epoch 21/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7922\n",
      "Epoch 22/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7859\n",
      "Epoch 23/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7820\n",
      "Epoch 24/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7734\n",
      "Epoch 25/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7728\n",
      "Epoch 26/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7701\n",
      "Epoch 27/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7616\n",
      "Epoch 28/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7590\n",
      "Epoch 29/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7556\n",
      "Epoch 30/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7532\n",
      "Epoch 31/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7506\n",
      "Epoch 32/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7453\n",
      "Epoch 33/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7446\n",
      "Epoch 34/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7405\n",
      "Epoch 35/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7393\n",
      "Epoch 36/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7375\n",
      "Epoch 37/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7339\n",
      "Epoch 38/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7293\n",
      "Epoch 39/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7285\n",
      "Epoch 40/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7278\n",
      "Epoch 41/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7244\n",
      "Epoch 42/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7224\n",
      "Epoch 43/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7240\n",
      "Epoch 44/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7199\n",
      "Epoch 45/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7194\n",
      "Epoch 46/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7169\n",
      "Epoch 47/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7174\n",
      "Epoch 48/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7129\n",
      "Epoch 49/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7130\n",
      "Epoch 50/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7114\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Testing with layers=[64, 32], encoding_dim=12, batch_size=64, epochs=50, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "16/16 - 1s - 68ms/step - loss: 1.2426\n",
      "Epoch 2/50\n",
      "16/16 - 0s - 2ms/step - loss: 1.1660\n",
      "Epoch 3/50\n",
      "16/16 - 0s - 2ms/step - loss: 1.0979\n",
      "Epoch 4/50\n",
      "16/16 - 0s - 2ms/step - loss: 1.0530\n",
      "Epoch 5/50\n",
      "16/16 - 0s - 2ms/step - loss: 1.0177\n",
      "Epoch 6/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.9882\n",
      "Epoch 7/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.9645\n",
      "Epoch 8/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.9481\n",
      "Epoch 9/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.9306\n",
      "Epoch 10/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.9174\n",
      "Epoch 11/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.9071\n",
      "Epoch 12/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8949\n",
      "Epoch 13/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8885\n",
      "Epoch 14/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8805\n",
      "Epoch 15/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8775\n",
      "Epoch 16/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8659\n",
      "Epoch 17/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8631\n",
      "Epoch 18/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8623\n",
      "Epoch 19/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8582\n",
      "Epoch 20/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8507\n",
      "Epoch 21/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8459\n",
      "Epoch 22/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8385\n",
      "Epoch 23/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8354\n",
      "Epoch 24/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8332\n",
      "Epoch 25/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8308\n",
      "Epoch 26/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8220\n",
      "Epoch 27/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8235\n",
      "Epoch 28/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8207\n",
      "Epoch 29/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8161\n",
      "Epoch 30/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8110\n",
      "Epoch 31/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8122\n",
      "Epoch 32/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8125\n",
      "Epoch 33/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8065\n",
      "Epoch 34/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8070\n",
      "Epoch 35/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8025\n",
      "Epoch 36/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7990\n",
      "Epoch 37/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7974\n",
      "Epoch 38/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7931\n",
      "Epoch 39/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7927\n",
      "Epoch 40/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7901\n",
      "Epoch 41/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7878\n",
      "Epoch 42/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7861\n",
      "Epoch 43/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7826\n",
      "Epoch 44/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7818\n",
      "Epoch 45/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7832\n",
      "Epoch 46/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7796\n",
      "Epoch 47/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7817\n",
      "Epoch 48/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7754\n",
      "Epoch 49/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7751\n",
      "Epoch 50/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7717\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Testing with layers=[64, 32], encoding_dim=12, batch_size=64, epochs=100, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "16/16 - 1s - 62ms/step - loss: 1.2558\n",
      "Epoch 2/100\n",
      "16/16 - 0s - 1ms/step - loss: 1.1486\n",
      "Epoch 3/100\n",
      "16/16 - 0s - 1ms/step - loss: 1.0771\n",
      "Epoch 4/100\n",
      "16/16 - 0s - 1ms/step - loss: 1.0297\n",
      "Epoch 5/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.9895\n",
      "Epoch 6/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.9580\n",
      "Epoch 7/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.9376\n",
      "Epoch 8/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.9190\n",
      "Epoch 9/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.9039\n",
      "Epoch 10/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8905\n",
      "Epoch 11/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8776\n",
      "Epoch 12/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8679\n",
      "Epoch 13/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8557\n",
      "Epoch 14/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8473\n",
      "Epoch 15/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8393\n",
      "Epoch 16/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8278\n",
      "Epoch 17/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8260\n",
      "Epoch 18/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8147\n",
      "Epoch 19/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8120\n",
      "Epoch 20/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8035\n",
      "Epoch 21/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7974\n",
      "Epoch 22/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7913\n",
      "Epoch 23/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7825\n",
      "Epoch 24/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7779\n",
      "Epoch 25/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7749\n",
      "Epoch 26/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7705\n",
      "Epoch 27/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7654\n",
      "Epoch 28/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7596\n",
      "Epoch 29/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7588\n",
      "Epoch 30/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7547\n",
      "Epoch 31/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7502\n",
      "Epoch 32/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7496\n",
      "Epoch 33/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7453\n",
      "Epoch 34/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7446\n",
      "Epoch 35/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7401\n",
      "Epoch 36/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7389\n",
      "Epoch 37/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7346\n",
      "Epoch 38/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7332\n",
      "Epoch 39/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7309\n",
      "Epoch 40/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7296\n",
      "Epoch 41/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7275\n",
      "Epoch 42/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7230\n",
      "Epoch 43/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7253\n",
      "Epoch 44/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7217\n",
      "Epoch 45/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7182\n",
      "Epoch 46/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7186\n",
      "Epoch 47/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7141\n",
      "Epoch 48/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7162\n",
      "Epoch 49/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7107\n",
      "Epoch 50/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7113\n",
      "Epoch 51/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7096\n",
      "Epoch 52/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7075\n",
      "Epoch 53/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7075\n",
      "Epoch 54/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7068\n",
      "Epoch 55/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7034\n",
      "Epoch 56/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7018\n",
      "Epoch 57/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7047\n",
      "Epoch 58/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6971\n",
      "Epoch 59/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7009\n",
      "Epoch 60/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7062\n",
      "Epoch 61/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7004\n",
      "Epoch 62/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6984\n",
      "Epoch 63/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6980\n",
      "Epoch 64/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6968\n",
      "Epoch 65/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6984\n",
      "Epoch 66/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6966\n",
      "Epoch 67/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6968\n",
      "Epoch 68/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6956\n",
      "Epoch 69/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6942\n",
      "Epoch 70/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6926\n",
      "Epoch 71/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6903\n",
      "Epoch 72/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6918\n",
      "Epoch 73/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6913\n",
      "Epoch 74/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6880\n",
      "Epoch 75/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6914\n",
      "Epoch 76/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6892\n",
      "Epoch 77/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6903\n",
      "Epoch 78/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6854\n",
      "Epoch 79/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6855\n",
      "Epoch 80/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6854\n",
      "Epoch 81/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6864\n",
      "Epoch 82/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6846\n",
      "Epoch 83/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6861\n",
      "Epoch 84/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6877\n",
      "Epoch 85/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6809\n",
      "Epoch 86/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6855\n",
      "Epoch 87/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6855\n",
      "Epoch 88/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6816\n",
      "Epoch 89/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6799\n",
      "Epoch 90/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6789\n",
      "Epoch 91/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6823\n",
      "Epoch 92/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6826\n",
      "Epoch 93/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6779\n",
      "Epoch 94/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6789\n",
      "Epoch 95/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6782\n",
      "Epoch 96/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6759\n",
      "Epoch 97/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6785\n",
      "Epoch 98/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6777\n",
      "Epoch 99/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6754\n",
      "Epoch 100/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6789\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step\n",
      "Testing with layers=[64, 32], encoding_dim=12, batch_size=64, epochs=100, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "16/16 - 1s - 68ms/step - loss: 1.2358\n",
      "Epoch 2/100\n",
      "16/16 - 0s - 1ms/step - loss: 1.1632\n",
      "Epoch 3/100\n",
      "16/16 - 0s - 2ms/step - loss: 1.1096\n",
      "Epoch 4/100\n",
      "16/16 - 0s - 2ms/step - loss: 1.0541\n",
      "Epoch 5/100\n",
      "16/16 - 0s - 1ms/step - loss: 1.0244\n",
      "Epoch 6/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.9936\n",
      "Epoch 7/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.9693\n",
      "Epoch 8/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.9518\n",
      "Epoch 9/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.9328\n",
      "Epoch 10/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.9237\n",
      "Epoch 11/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.9143\n",
      "Epoch 12/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8994\n",
      "Epoch 13/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.8893\n",
      "Epoch 14/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8829\n",
      "Epoch 15/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8765\n",
      "Epoch 16/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8690\n",
      "Epoch 17/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8616\n",
      "Epoch 18/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8543\n",
      "Epoch 19/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8491\n",
      "Epoch 20/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8475\n",
      "Epoch 21/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8424\n",
      "Epoch 22/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.8341\n",
      "Epoch 23/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.8341\n",
      "Epoch 24/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8282\n",
      "Epoch 25/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8217\n",
      "Epoch 26/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8224\n",
      "Epoch 27/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8149\n",
      "Epoch 28/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8118\n",
      "Epoch 29/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8076\n",
      "Epoch 30/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8032\n",
      "Epoch 31/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8032\n",
      "Epoch 32/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7963\n",
      "Epoch 33/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7973\n",
      "Epoch 34/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7932\n",
      "Epoch 35/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7893\n",
      "Epoch 36/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7871\n",
      "Epoch 37/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7854\n",
      "Epoch 38/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7865\n",
      "Epoch 39/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7791\n",
      "Epoch 40/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7793\n",
      "Epoch 41/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7757\n",
      "Epoch 42/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7775\n",
      "Epoch 43/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7761\n",
      "Epoch 44/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7734\n",
      "Epoch 45/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7697\n",
      "Epoch 46/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7709\n",
      "Epoch 47/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7675\n",
      "Epoch 48/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7661\n",
      "Epoch 49/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7663\n",
      "Epoch 50/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7618\n",
      "Epoch 51/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7609\n",
      "Epoch 52/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7605\n",
      "Epoch 53/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7632\n",
      "Epoch 54/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7566\n",
      "Epoch 55/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7591\n",
      "Epoch 56/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7559\n",
      "Epoch 57/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7540\n",
      "Epoch 58/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7549\n",
      "Epoch 59/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7552\n",
      "Epoch 60/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7486\n",
      "Epoch 61/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7517\n",
      "Epoch 62/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7483\n",
      "Epoch 63/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7507\n",
      "Epoch 64/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7445\n",
      "Epoch 65/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7467\n",
      "Epoch 66/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7451\n",
      "Epoch 67/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7457\n",
      "Epoch 68/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7435\n",
      "Epoch 69/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7400\n",
      "Epoch 70/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7417\n",
      "Epoch 71/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7385\n",
      "Epoch 72/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7398\n",
      "Epoch 73/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7351\n",
      "Epoch 74/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7378\n",
      "Epoch 75/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7354\n",
      "Epoch 76/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7352\n",
      "Epoch 77/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7321\n",
      "Epoch 78/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7329\n",
      "Epoch 79/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7334\n",
      "Epoch 80/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7305\n",
      "Epoch 81/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7328\n",
      "Epoch 82/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7347\n",
      "Epoch 83/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7326\n",
      "Epoch 84/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7287\n",
      "Epoch 85/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7288\n",
      "Epoch 86/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7306\n",
      "Epoch 87/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7300\n",
      "Epoch 88/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7309\n",
      "Epoch 89/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7279\n",
      "Epoch 90/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7247\n",
      "Epoch 91/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7257\n",
      "Epoch 92/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7287\n",
      "Epoch 93/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7265\n",
      "Epoch 94/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7286\n",
      "Epoch 95/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7244\n",
      "Epoch 96/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7209\n",
      "Epoch 97/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7237\n",
      "Epoch 98/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7224\n",
      "Epoch 99/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7193\n",
      "Epoch 100/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7267\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Testing with layers=[64, 32], encoding_dim=12, batch_size=128, epochs=50, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "8/8 - 1s - 123ms/step - loss: 1.2539\n",
      "Epoch 2/50\n",
      "8/8 - 0s - 2ms/step - loss: 1.1907\n",
      "Epoch 3/50\n",
      "8/8 - 0s - 2ms/step - loss: 1.1416\n",
      "Epoch 4/50\n",
      "8/8 - 0s - 3ms/step - loss: 1.0975\n",
      "Epoch 5/50\n",
      "8/8 - 0s - 2ms/step - loss: 1.0613\n",
      "Epoch 6/50\n",
      "8/8 - 0s - 2ms/step - loss: 1.0331\n",
      "Epoch 7/50\n",
      "8/8 - 0s - 2ms/step - loss: 1.0105\n",
      "Epoch 8/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.9884\n",
      "Epoch 9/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.9665\n",
      "Epoch 10/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.9498\n",
      "Epoch 11/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.9325\n",
      "Epoch 12/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.9189\n",
      "Epoch 13/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.9125\n",
      "Epoch 14/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.9020\n",
      "Epoch 15/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8890\n",
      "Epoch 16/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8792\n",
      "Epoch 17/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8694\n",
      "Epoch 18/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8653\n",
      "Epoch 19/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8566\n",
      "Epoch 20/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8469\n",
      "Epoch 21/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8474\n",
      "Epoch 22/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8396\n",
      "Epoch 23/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8299\n",
      "Epoch 24/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8303\n",
      "Epoch 25/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8225\n",
      "Epoch 26/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8164\n",
      "Epoch 27/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8121\n",
      "Epoch 28/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8087\n",
      "Epoch 29/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8051\n",
      "Epoch 30/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8010\n",
      "Epoch 31/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7916\n",
      "Epoch 32/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7886\n",
      "Epoch 33/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7857\n",
      "Epoch 34/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7814\n",
      "Epoch 35/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7783\n",
      "Epoch 36/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7769\n",
      "Epoch 37/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7740\n",
      "Epoch 38/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7705\n",
      "Epoch 39/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7674\n",
      "Epoch 40/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7636\n",
      "Epoch 41/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7618\n",
      "Epoch 42/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7559\n",
      "Epoch 43/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7537\n",
      "Epoch 44/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7530\n",
      "Epoch 45/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7491\n",
      "Epoch 46/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7476\n",
      "Epoch 47/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7467\n",
      "Epoch 48/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7495\n",
      "Epoch 49/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7435\n",
      "Epoch 50/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7365\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Testing with layers=[64, 32], encoding_dim=12, batch_size=128, epochs=50, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "8/8 - 1s - 151ms/step - loss: 1.2936\n",
      "Epoch 2/50\n",
      "8/8 - 0s - 3ms/step - loss: 1.2381\n",
      "Epoch 3/50\n",
      "8/8 - 0s - 2ms/step - loss: 1.1960\n",
      "Epoch 4/50\n",
      "8/8 - 0s - 3ms/step - loss: 1.1527\n",
      "Epoch 5/50\n",
      "8/8 - 0s - 2ms/step - loss: 1.1209\n",
      "Epoch 6/50\n",
      "8/8 - 0s - 2ms/step - loss: 1.0922\n",
      "Epoch 7/50\n",
      "8/8 - 0s - 2ms/step - loss: 1.0651\n",
      "Epoch 8/50\n",
      "8/8 - 0s - 3ms/step - loss: 1.0412\n",
      "Epoch 9/50\n",
      "8/8 - 0s - 2ms/step - loss: 1.0165\n",
      "Epoch 10/50\n",
      "8/8 - 0s - 2ms/step - loss: 1.0009\n",
      "Epoch 11/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.9860\n",
      "Epoch 12/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.9735\n",
      "Epoch 13/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.9565\n",
      "Epoch 14/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.9476\n",
      "Epoch 15/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.9360\n",
      "Epoch 16/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.9228\n",
      "Epoch 17/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.9187\n",
      "Epoch 18/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.9120\n",
      "Epoch 19/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.9011\n",
      "Epoch 20/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8965\n",
      "Epoch 21/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8903\n",
      "Epoch 22/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8885\n",
      "Epoch 23/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8788\n",
      "Epoch 24/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8760\n",
      "Epoch 25/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8692\n",
      "Epoch 26/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8686\n",
      "Epoch 27/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8648\n",
      "Epoch 28/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8573\n",
      "Epoch 29/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8555\n",
      "Epoch 30/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8506\n",
      "Epoch 31/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8472\n",
      "Epoch 32/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8459\n",
      "Epoch 33/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8413\n",
      "Epoch 34/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8373\n",
      "Epoch 35/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8341\n",
      "Epoch 36/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8332\n",
      "Epoch 37/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8273\n",
      "Epoch 38/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8264\n",
      "Epoch 39/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8222\n",
      "Epoch 40/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8165\n",
      "Epoch 41/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8140\n",
      "Epoch 42/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8139\n",
      "Epoch 43/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8126\n",
      "Epoch 44/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8119\n",
      "Epoch 45/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8037\n",
      "Epoch 46/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8069\n",
      "Epoch 47/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8025\n",
      "Epoch 48/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8029\n",
      "Epoch 49/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7982\n",
      "Epoch 50/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7924\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Testing with layers=[64, 32], encoding_dim=12, batch_size=128, epochs=100, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "8/8 - 2s - 216ms/step - loss: 1.2305\n",
      "Epoch 2/100\n",
      "8/8 - 0s - 3ms/step - loss: 1.1662\n",
      "Epoch 3/100\n",
      "8/8 - 0s - 2ms/step - loss: 1.1190\n",
      "Epoch 4/100\n",
      "8/8 - 0s - 2ms/step - loss: 1.0798\n",
      "Epoch 5/100\n",
      "8/8 - 0s - 3ms/step - loss: 1.0478\n",
      "Epoch 6/100\n",
      "8/8 - 0s - 2ms/step - loss: 1.0206\n",
      "Epoch 7/100\n",
      "8/8 - 0s - 3ms/step - loss: 1.0006\n",
      "Epoch 8/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.9810\n",
      "Epoch 9/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.9677\n",
      "Epoch 10/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.9520\n",
      "Epoch 11/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.9329\n",
      "Epoch 12/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.9222\n",
      "Epoch 13/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.9138\n",
      "Epoch 14/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.9072\n",
      "Epoch 15/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8980\n",
      "Epoch 16/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8837\n",
      "Epoch 17/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8779\n",
      "Epoch 18/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8706\n",
      "Epoch 19/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8630\n",
      "Epoch 20/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8554\n",
      "Epoch 21/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8481\n",
      "Epoch 22/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8434\n",
      "Epoch 23/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8368\n",
      "Epoch 24/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8334\n",
      "Epoch 25/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8270\n",
      "Epoch 26/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8202\n",
      "Epoch 27/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8219\n",
      "Epoch 28/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8135\n",
      "Epoch 29/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8103\n",
      "Epoch 30/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8091\n",
      "Epoch 31/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8015\n",
      "Epoch 32/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7991\n",
      "Epoch 33/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7979\n",
      "Epoch 34/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7938\n",
      "Epoch 35/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7897\n",
      "Epoch 36/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7847\n",
      "Epoch 37/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7844\n",
      "Epoch 38/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7821\n",
      "Epoch 39/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7799\n",
      "Epoch 40/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7752\n",
      "Epoch 41/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7746\n",
      "Epoch 42/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7707\n",
      "Epoch 43/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7691\n",
      "Epoch 44/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7658\n",
      "Epoch 45/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7655\n",
      "Epoch 46/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7618\n",
      "Epoch 47/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7593\n",
      "Epoch 48/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7566\n",
      "Epoch 49/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7566\n",
      "Epoch 50/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7541\n",
      "Epoch 51/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7503\n",
      "Epoch 52/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7501\n",
      "Epoch 53/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7501\n",
      "Epoch 54/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7494\n",
      "Epoch 55/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7462\n",
      "Epoch 56/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.7467\n",
      "Epoch 57/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7402\n",
      "Epoch 58/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7430\n",
      "Epoch 59/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7389\n",
      "Epoch 60/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7382\n",
      "Epoch 61/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7397\n",
      "Epoch 62/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7357\n",
      "Epoch 63/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7318\n",
      "Epoch 64/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7348\n",
      "Epoch 65/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7309\n",
      "Epoch 66/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7332\n",
      "Epoch 67/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7291\n",
      "Epoch 68/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7284\n",
      "Epoch 69/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7266\n",
      "Epoch 70/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7255\n",
      "Epoch 71/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7248\n",
      "Epoch 72/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7260\n",
      "Epoch 73/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7248\n",
      "Epoch 74/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7258\n",
      "Epoch 75/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7225\n",
      "Epoch 76/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7199\n",
      "Epoch 77/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7194\n",
      "Epoch 78/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7175\n",
      "Epoch 79/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7195\n",
      "Epoch 80/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7173\n",
      "Epoch 81/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7176\n",
      "Epoch 82/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7160\n",
      "Epoch 83/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7145\n",
      "Epoch 84/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7147\n",
      "Epoch 85/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7111\n",
      "Epoch 86/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7125\n",
      "Epoch 87/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7129\n",
      "Epoch 88/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7082\n",
      "Epoch 89/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7076\n",
      "Epoch 90/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7085\n",
      "Epoch 91/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7077\n",
      "Epoch 92/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7073\n",
      "Epoch 93/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7040\n",
      "Epoch 94/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7057\n",
      "Epoch 95/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7046\n",
      "Epoch 96/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7030\n",
      "Epoch 97/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7015\n",
      "Epoch 98/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7015\n",
      "Epoch 99/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7046\n",
      "Epoch 100/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7007\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Testing with layers=[64, 32], encoding_dim=12, batch_size=128, epochs=100, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "8/8 - 2s - 222ms/step - loss: 1.2823\n",
      "Epoch 2/100\n",
      "8/8 - 0s - 5ms/step - loss: 1.2385\n",
      "Epoch 3/100\n",
      "8/8 - 0s - 5ms/step - loss: 1.1938\n",
      "Epoch 4/100\n",
      "8/8 - 0s - 4ms/step - loss: 1.1491\n",
      "Epoch 5/100\n",
      "8/8 - 0s - 4ms/step - loss: 1.1141\n",
      "Epoch 6/100\n",
      "8/8 - 0s - 4ms/step - loss: 1.0860\n",
      "Epoch 7/100\n",
      "8/8 - 0s - 3ms/step - loss: 1.0591\n",
      "Epoch 8/100\n",
      "8/8 - 0s - 2ms/step - loss: 1.0399\n",
      "Epoch 9/100\n",
      "8/8 - 0s - 3ms/step - loss: 1.0153\n",
      "Epoch 10/100\n",
      "8/8 - 0s - 3ms/step - loss: 1.0037\n",
      "Epoch 11/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.9823\n",
      "Epoch 12/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.9636\n",
      "Epoch 13/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.9571\n",
      "Epoch 14/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.9440\n",
      "Epoch 15/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.9334\n",
      "Epoch 16/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.9249\n",
      "Epoch 17/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.9145\n",
      "Epoch 18/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.9088\n",
      "Epoch 19/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8976\n",
      "Epoch 20/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8957\n",
      "Epoch 21/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8886\n",
      "Epoch 22/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8829\n",
      "Epoch 23/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8763\n",
      "Epoch 24/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8687\n",
      "Epoch 25/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8669\n",
      "Epoch 26/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8646\n",
      "Epoch 27/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8573\n",
      "Epoch 28/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8503\n",
      "Epoch 29/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8502\n",
      "Epoch 30/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8520\n",
      "Epoch 31/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8398\n",
      "Epoch 32/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8387\n",
      "Epoch 33/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8357\n",
      "Epoch 34/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8323\n",
      "Epoch 35/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8288\n",
      "Epoch 36/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8258\n",
      "Epoch 37/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8248\n",
      "Epoch 38/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8214\n",
      "Epoch 39/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8214\n",
      "Epoch 40/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8160\n",
      "Epoch 41/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8118\n",
      "Epoch 42/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8086\n",
      "Epoch 43/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8091\n",
      "Epoch 44/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8086\n",
      "Epoch 45/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8092\n",
      "Epoch 46/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8001\n",
      "Epoch 47/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8012\n",
      "Epoch 48/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7979\n",
      "Epoch 49/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7965\n",
      "Epoch 50/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7927\n",
      "Epoch 51/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7911\n",
      "Epoch 52/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7910\n",
      "Epoch 53/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7930\n",
      "Epoch 54/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7898\n",
      "Epoch 55/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7891\n",
      "Epoch 56/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7865\n",
      "Epoch 57/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7803\n",
      "Epoch 58/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7795\n",
      "Epoch 59/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7802\n",
      "Epoch 60/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7768\n",
      "Epoch 61/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7748\n",
      "Epoch 62/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7768\n",
      "Epoch 63/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7723\n",
      "Epoch 64/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7733\n",
      "Epoch 65/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7715\n",
      "Epoch 66/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7735\n",
      "Epoch 67/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7683\n",
      "Epoch 68/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7679\n",
      "Epoch 69/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7635\n",
      "Epoch 70/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7642\n",
      "Epoch 71/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7680\n",
      "Epoch 72/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7624\n",
      "Epoch 73/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7606\n",
      "Epoch 74/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7594\n",
      "Epoch 75/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7576\n",
      "Epoch 76/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7579\n",
      "Epoch 77/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7559\n",
      "Epoch 78/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7535\n",
      "Epoch 79/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7550\n",
      "Epoch 80/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7565\n",
      "Epoch 81/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7507\n",
      "Epoch 82/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7529\n",
      "Epoch 83/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7509\n",
      "Epoch 84/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7519\n",
      "Epoch 85/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7530\n",
      "Epoch 86/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7495\n",
      "Epoch 87/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7467\n",
      "Epoch 88/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7473\n",
      "Epoch 89/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7448\n",
      "Epoch 90/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7443\n",
      "Epoch 91/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7441\n",
      "Epoch 92/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7447\n",
      "Epoch 93/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7395\n",
      "Epoch 94/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7411\n",
      "Epoch 95/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7424\n",
      "Epoch 96/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7387\n",
      "Epoch 97/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7412\n",
      "Epoch 98/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7383\n",
      "Epoch 99/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7377\n",
      "Epoch 100/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7364\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Testing with layers=[128, 64, 32], encoding_dim=8, batch_size=32, epochs=50, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "32/32 - 2s - 53ms/step - loss: 1.1571\n",
      "Epoch 2/50\n",
      "32/32 - 0s - 2ms/step - loss: 1.0132\n",
      "Epoch 3/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.9520\n",
      "Epoch 4/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.9129\n",
      "Epoch 5/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.8953\n",
      "Epoch 6/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.8747\n",
      "Epoch 7/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8644\n",
      "Epoch 8/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8515\n",
      "Epoch 9/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8398\n",
      "Epoch 10/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8329\n",
      "Epoch 11/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8280\n",
      "Epoch 12/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8187\n",
      "Epoch 13/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8133\n",
      "Epoch 14/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8087\n",
      "Epoch 15/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8040\n",
      "Epoch 16/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8020\n",
      "Epoch 17/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7944\n",
      "Epoch 18/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7919\n",
      "Epoch 19/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7882\n",
      "Epoch 20/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7835\n",
      "Epoch 21/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7848\n",
      "Epoch 22/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7779\n",
      "Epoch 23/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7786\n",
      "Epoch 24/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7745\n",
      "Epoch 25/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7692\n",
      "Epoch 26/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7738\n",
      "Epoch 27/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7669\n",
      "Epoch 28/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7694\n",
      "Epoch 29/50\n",
      "32/32 - 0s - 998us/step - loss: 0.7688\n",
      "Epoch 30/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7662\n",
      "Epoch 31/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7598\n",
      "Epoch 32/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7605\n",
      "Epoch 33/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7577\n",
      "Epoch 34/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7559\n",
      "Epoch 35/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7563\n",
      "Epoch 36/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7571\n",
      "Epoch 37/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7570\n",
      "Epoch 38/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7502\n",
      "Epoch 39/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7503\n",
      "Epoch 40/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7513\n",
      "Epoch 41/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7475\n",
      "Epoch 42/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7469\n",
      "Epoch 43/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7466\n",
      "Epoch 44/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7462\n",
      "Epoch 45/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7461\n",
      "Epoch 46/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7420\n",
      "Epoch 47/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7407\n",
      "Epoch 48/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7430\n",
      "Epoch 49/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7419\n",
      "Epoch 50/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7369\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "New best score: 0.303783655166626 with params: {'layer_sizes': [128, 64, 32], 'encoding_dim': 8, 'batch_size': 32, 'epochs': 50, 'dropout_rate': 0.2}\n",
      "Testing with layers=[128, 64, 32], encoding_dim=8, batch_size=32, epochs=50, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "32/32 - 1s - 39ms/step - loss: 1.1789\n",
      "Epoch 2/50\n",
      "32/32 - 0s - 1ms/step - loss: 1.0414\n",
      "Epoch 3/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.9798\n",
      "Epoch 4/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.9490\n",
      "Epoch 5/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.9209\n",
      "Epoch 6/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.9068\n",
      "Epoch 7/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8978\n",
      "Epoch 8/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8837\n",
      "Epoch 9/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8740\n",
      "Epoch 10/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8714\n",
      "Epoch 11/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8602\n",
      "Epoch 12/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8547\n",
      "Epoch 13/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8480\n",
      "Epoch 14/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8452\n",
      "Epoch 15/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8399\n",
      "Epoch 16/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8350\n",
      "Epoch 17/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8327\n",
      "Epoch 18/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8271\n",
      "Epoch 19/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8255\n",
      "Epoch 20/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8234\n",
      "Epoch 21/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8220\n",
      "Epoch 22/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8172\n",
      "Epoch 23/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8149\n",
      "Epoch 24/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8155\n",
      "Epoch 25/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8118\n",
      "Epoch 26/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8136\n",
      "Epoch 27/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8087\n",
      "Epoch 28/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8038\n",
      "Epoch 29/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8039\n",
      "Epoch 30/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8042\n",
      "Epoch 31/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8011\n",
      "Epoch 32/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8005\n",
      "Epoch 33/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7963\n",
      "Epoch 34/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7983\n",
      "Epoch 35/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7987\n",
      "Epoch 36/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7938\n",
      "Epoch 37/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7920\n",
      "Epoch 38/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7907\n",
      "Epoch 39/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7899\n",
      "Epoch 40/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7911\n",
      "Epoch 41/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7891\n",
      "Epoch 42/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7876\n",
      "Epoch 43/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7875\n",
      "Epoch 44/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7853\n",
      "Epoch 45/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7846\n",
      "Epoch 46/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7853\n",
      "Epoch 47/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7847\n",
      "Epoch 48/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7804\n",
      "Epoch 49/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7845\n",
      "Epoch 50/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7785\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Testing with layers=[128, 64, 32], encoding_dim=8, batch_size=32, epochs=100, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "32/32 - 30s - 936ms/step - loss: 1.1483\n",
      "Epoch 2/100\n",
      "32/32 - 0s - 1ms/step - loss: 1.0149\n",
      "Epoch 3/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.9546\n",
      "Epoch 4/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.9198\n",
      "Epoch 5/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8968\n",
      "Epoch 6/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8817\n",
      "Epoch 7/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8724\n",
      "Epoch 8/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8589\n",
      "Epoch 9/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8503\n",
      "Epoch 10/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8418\n",
      "Epoch 11/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8304\n",
      "Epoch 12/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8258\n",
      "Epoch 13/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8190\n",
      "Epoch 14/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8151\n",
      "Epoch 15/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.8069\n",
      "Epoch 16/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8010\n",
      "Epoch 17/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8000\n",
      "Epoch 18/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7974\n",
      "Epoch 19/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7902\n",
      "Epoch 20/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7935\n",
      "Epoch 21/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7853\n",
      "Epoch 22/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7835\n",
      "Epoch 23/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7800\n",
      "Epoch 24/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7775\n",
      "Epoch 25/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7734\n",
      "Epoch 26/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7775\n",
      "Epoch 27/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7725\n",
      "Epoch 28/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7696\n",
      "Epoch 29/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7681\n",
      "Epoch 30/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7670\n",
      "Epoch 31/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7612\n",
      "Epoch 32/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7589\n",
      "Epoch 33/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7583\n",
      "Epoch 34/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7588\n",
      "Epoch 35/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7578\n",
      "Epoch 36/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7541\n",
      "Epoch 37/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7547\n",
      "Epoch 38/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7536\n",
      "Epoch 39/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7505\n",
      "Epoch 40/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7512\n",
      "Epoch 41/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7491\n",
      "Epoch 42/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7490\n",
      "Epoch 43/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7449\n",
      "Epoch 44/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7467\n",
      "Epoch 45/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7459\n",
      "Epoch 46/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7417\n",
      "Epoch 47/100\n",
      "32/32 - 0s - 990us/step - loss: 0.7413\n",
      "Epoch 48/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7384\n",
      "Epoch 49/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7421\n",
      "Epoch 50/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7410\n",
      "Epoch 51/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7366\n",
      "Epoch 52/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7400\n",
      "Epoch 53/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7327\n",
      "Epoch 54/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7357\n",
      "Epoch 55/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7360\n",
      "Epoch 56/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7368\n",
      "Epoch 57/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7352\n",
      "Epoch 58/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7305\n",
      "Epoch 59/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7311\n",
      "Epoch 60/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7280\n",
      "Epoch 61/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7327\n",
      "Epoch 62/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7332\n",
      "Epoch 63/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7314\n",
      "Epoch 64/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7278\n",
      "Epoch 65/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7285\n",
      "Epoch 66/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7298\n",
      "Epoch 67/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.7266\n",
      "Epoch 68/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7250\n",
      "Epoch 69/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7282\n",
      "Epoch 70/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7247\n",
      "Epoch 71/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7240\n",
      "Epoch 72/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7208\n",
      "Epoch 73/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7206\n",
      "Epoch 74/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7235\n",
      "Epoch 75/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7233\n",
      "Epoch 76/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7222\n",
      "Epoch 77/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7217\n",
      "Epoch 78/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7213\n",
      "Epoch 79/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7202\n",
      "Epoch 80/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7172\n",
      "Epoch 81/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7193\n",
      "Epoch 82/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7188\n",
      "Epoch 83/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7185\n",
      "Epoch 84/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7142\n",
      "Epoch 85/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7163\n",
      "Epoch 86/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7163\n",
      "Epoch 87/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7194\n",
      "Epoch 88/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7169\n",
      "Epoch 89/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7184\n",
      "Epoch 90/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7165\n",
      "Epoch 91/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7149\n",
      "Epoch 92/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7176\n",
      "Epoch 93/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7138\n",
      "Epoch 94/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7158\n",
      "Epoch 95/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7129\n",
      "Epoch 96/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7128\n",
      "Epoch 97/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7100\n",
      "Epoch 98/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7113\n",
      "Epoch 99/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7144\n",
      "Epoch 100/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7099\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "Testing with layers=[128, 64, 32], encoding_dim=8, batch_size=32, epochs=100, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "32/32 - 2s - 51ms/step - loss: 1.1880\n",
      "Epoch 2/100\n",
      "32/32 - 0s - 1ms/step - loss: 1.0638\n",
      "Epoch 3/100\n",
      "32/32 - 0s - 1ms/step - loss: 1.0034\n",
      "Epoch 4/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.9681\n",
      "Epoch 5/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.9479\n",
      "Epoch 6/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.9307\n",
      "Epoch 7/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.9173\n",
      "Epoch 8/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.9074\n",
      "Epoch 9/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8968\n",
      "Epoch 10/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8862\n",
      "Epoch 11/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8780\n",
      "Epoch 12/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8712\n",
      "Epoch 13/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8618\n",
      "Epoch 14/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8541\n",
      "Epoch 15/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8470\n",
      "Epoch 16/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8449\n",
      "Epoch 17/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8360\n",
      "Epoch 18/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8383\n",
      "Epoch 19/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8308\n",
      "Epoch 20/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8281\n",
      "Epoch 21/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8249\n",
      "Epoch 22/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8200\n",
      "Epoch 23/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8178\n",
      "Epoch 24/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.8160\n",
      "Epoch 25/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.8151\n",
      "Epoch 26/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.8138\n",
      "Epoch 27/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.8096\n",
      "Epoch 28/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.8088\n",
      "Epoch 29/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8090\n",
      "Epoch 30/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.8017\n",
      "Epoch 31/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.8046\n",
      "Epoch 32/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7997\n",
      "Epoch 33/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7993\n",
      "Epoch 34/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7969\n",
      "Epoch 35/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7966\n",
      "Epoch 36/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7960\n",
      "Epoch 37/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7942\n",
      "Epoch 38/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7944\n",
      "Epoch 39/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7909\n",
      "Epoch 40/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7882\n",
      "Epoch 41/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7890\n",
      "Epoch 42/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7883\n",
      "Epoch 43/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7839\n",
      "Epoch 44/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7855\n",
      "Epoch 45/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7845\n",
      "Epoch 46/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7839\n",
      "Epoch 47/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7843\n",
      "Epoch 48/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7847\n",
      "Epoch 49/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7792\n",
      "Epoch 50/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7798\n",
      "Epoch 51/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7798\n",
      "Epoch 52/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7798\n",
      "Epoch 53/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7783\n",
      "Epoch 54/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7783\n",
      "Epoch 55/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7799\n",
      "Epoch 56/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7772\n",
      "Epoch 57/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7733\n",
      "Epoch 58/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7693\n",
      "Epoch 59/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7750\n",
      "Epoch 60/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7717\n",
      "Epoch 61/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7753\n",
      "Epoch 62/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7710\n",
      "Epoch 63/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7711\n",
      "Epoch 64/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7697\n",
      "Epoch 65/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7701\n",
      "Epoch 66/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7655\n",
      "Epoch 67/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7650\n",
      "Epoch 68/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7678\n",
      "Epoch 69/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7637\n",
      "Epoch 70/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7620\n",
      "Epoch 71/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7655\n",
      "Epoch 72/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7603\n",
      "Epoch 73/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7661\n",
      "Epoch 74/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7613\n",
      "Epoch 75/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7606\n",
      "Epoch 76/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7601\n",
      "Epoch 77/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7593\n",
      "Epoch 78/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7604\n",
      "Epoch 79/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7602\n",
      "Epoch 80/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7554\n",
      "Epoch 81/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7593\n",
      "Epoch 82/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7604\n",
      "Epoch 83/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7571\n",
      "Epoch 84/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7576\n",
      "Epoch 85/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7584\n",
      "Epoch 86/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7568\n",
      "Epoch 87/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7595\n",
      "Epoch 88/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7538\n",
      "Epoch 89/100\n",
      "32/32 - 0s - 991us/step - loss: 0.7526\n",
      "Epoch 90/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7552\n",
      "Epoch 91/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7547\n",
      "Epoch 92/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7517\n",
      "Epoch 93/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7538\n",
      "Epoch 94/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7519\n",
      "Epoch 95/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7494\n",
      "Epoch 96/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7499\n",
      "Epoch 97/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7525\n",
      "Epoch 98/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7502\n",
      "Epoch 99/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7504\n",
      "Epoch 100/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7482\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Testing with layers=[128, 64, 32], encoding_dim=8, batch_size=64, epochs=50, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "16/16 - 2s - 94ms/step - loss: 1.2166\n",
      "Epoch 2/50\n",
      "16/16 - 0s - 2ms/step - loss: 1.0899\n",
      "Epoch 3/50\n",
      "16/16 - 0s - 2ms/step - loss: 1.0225\n",
      "Epoch 4/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.9742\n",
      "Epoch 5/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.9435\n",
      "Epoch 6/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.9248\n",
      "Epoch 7/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.9067\n",
      "Epoch 8/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8894\n",
      "Epoch 9/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8785\n",
      "Epoch 10/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8660\n",
      "Epoch 11/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8599\n",
      "Epoch 12/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8512\n",
      "Epoch 13/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8423\n",
      "Epoch 14/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8352\n",
      "Epoch 15/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8263\n",
      "Epoch 16/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8247\n",
      "Epoch 17/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8205\n",
      "Epoch 18/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8140\n",
      "Epoch 19/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.8102\n",
      "Epoch 20/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.8056\n",
      "Epoch 21/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.8022\n",
      "Epoch 22/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7969\n",
      "Epoch 23/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7954\n",
      "Epoch 24/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7940\n",
      "Epoch 25/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7907\n",
      "Epoch 26/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7880\n",
      "Epoch 27/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7848\n",
      "Epoch 28/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7806\n",
      "Epoch 29/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7797\n",
      "Epoch 30/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7799\n",
      "Epoch 31/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7743\n",
      "Epoch 32/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7731\n",
      "Epoch 33/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7736\n",
      "Epoch 34/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7712\n",
      "Epoch 35/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7709\n",
      "Epoch 36/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7668\n",
      "Epoch 37/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7641\n",
      "Epoch 38/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7627\n",
      "Epoch 39/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7622\n",
      "Epoch 40/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7587\n",
      "Epoch 41/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7634\n",
      "Epoch 42/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7587\n",
      "Epoch 43/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7585\n",
      "Epoch 44/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7534\n",
      "Epoch 45/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7562\n",
      "Epoch 46/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7546\n",
      "Epoch 47/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7522\n",
      "Epoch 48/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7514\n",
      "Epoch 49/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7512\n",
      "Epoch 50/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7523\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "Testing with layers=[128, 64, 32], encoding_dim=8, batch_size=64, epochs=50, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "16/16 - 2s - 109ms/step - loss: 1.2439\n",
      "Epoch 2/50\n",
      "16/16 - 0s - 2ms/step - loss: 1.1275\n",
      "Epoch 3/50\n",
      "16/16 - 0s - 2ms/step - loss: 1.0584\n",
      "Epoch 4/50\n",
      "16/16 - 0s - 2ms/step - loss: 1.0084\n",
      "Epoch 5/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.9762\n",
      "Epoch 6/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.9536\n",
      "Epoch 7/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.9397\n",
      "Epoch 8/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.9241\n",
      "Epoch 9/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.9145\n",
      "Epoch 10/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.9033\n",
      "Epoch 11/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8926\n",
      "Epoch 12/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8889\n",
      "Epoch 13/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8822\n",
      "Epoch 14/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8770\n",
      "Epoch 15/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8722\n",
      "Epoch 16/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8653\n",
      "Epoch 17/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8599\n",
      "Epoch 18/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8543\n",
      "Epoch 19/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8543\n",
      "Epoch 20/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8511\n",
      "Epoch 21/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8476\n",
      "Epoch 22/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8406\n",
      "Epoch 23/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8368\n",
      "Epoch 24/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8367\n",
      "Epoch 25/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8345\n",
      "Epoch 26/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8275\n",
      "Epoch 27/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8267\n",
      "Epoch 28/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8257\n",
      "Epoch 29/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8217\n",
      "Epoch 30/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8186\n",
      "Epoch 31/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8146\n",
      "Epoch 32/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8188\n",
      "Epoch 33/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8145\n",
      "Epoch 34/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8148\n",
      "Epoch 35/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8142\n",
      "Epoch 36/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8094\n",
      "Epoch 37/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8097\n",
      "Epoch 38/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8079\n",
      "Epoch 39/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8042\n",
      "Epoch 40/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8068\n",
      "Epoch 41/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8046\n",
      "Epoch 42/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8002\n",
      "Epoch 43/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7974\n",
      "Epoch 44/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8014\n",
      "Epoch 45/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7944\n",
      "Epoch 46/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7981\n",
      "Epoch 47/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7946\n",
      "Epoch 48/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7943\n",
      "Epoch 49/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7953\n",
      "Epoch 50/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7931\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Testing with layers=[128, 64, 32], encoding_dim=8, batch_size=64, epochs=100, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "16/16 - 2s - 138ms/step - loss: 1.2272\n",
      "Epoch 2/100\n",
      "16/16 - 0s - 2ms/step - loss: 1.1037\n",
      "Epoch 3/100\n",
      "16/16 - 0s - 2ms/step - loss: 1.0277\n",
      "Epoch 4/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.9789\n",
      "Epoch 5/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.9470\n",
      "Epoch 6/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.9221\n",
      "Epoch 7/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.9056\n",
      "Epoch 8/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8879\n",
      "Epoch 9/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8729\n",
      "Epoch 10/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8633\n",
      "Epoch 11/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8548\n",
      "Epoch 12/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8461\n",
      "Epoch 13/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8347\n",
      "Epoch 14/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8285\n",
      "Epoch 15/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8270\n",
      "Epoch 16/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8188\n",
      "Epoch 17/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8107\n",
      "Epoch 18/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8047\n",
      "Epoch 19/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8051\n",
      "Epoch 20/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8040\n",
      "Epoch 21/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7973\n",
      "Epoch 22/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7964\n",
      "Epoch 23/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7934\n",
      "Epoch 24/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7908\n",
      "Epoch 25/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7892\n",
      "Epoch 26/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7880\n",
      "Epoch 27/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7836\n",
      "Epoch 28/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7827\n",
      "Epoch 29/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7809\n",
      "Epoch 30/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7769\n",
      "Epoch 31/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7769\n",
      "Epoch 32/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7770\n",
      "Epoch 33/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7738\n",
      "Epoch 34/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7728\n",
      "Epoch 35/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7732\n",
      "Epoch 36/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7695\n",
      "Epoch 37/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7663\n",
      "Epoch 38/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7682\n",
      "Epoch 39/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7669\n",
      "Epoch 40/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7643\n",
      "Epoch 41/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7662\n",
      "Epoch 42/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7645\n",
      "Epoch 43/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7620\n",
      "Epoch 44/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7598\n",
      "Epoch 45/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7610\n",
      "Epoch 46/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7586\n",
      "Epoch 47/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7609\n",
      "Epoch 48/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7573\n",
      "Epoch 49/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7577\n",
      "Epoch 50/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7547\n",
      "Epoch 51/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7524\n",
      "Epoch 52/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7522\n",
      "Epoch 53/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7497\n",
      "Epoch 54/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7489\n",
      "Epoch 55/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7502\n",
      "Epoch 56/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7483\n",
      "Epoch 57/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7487\n",
      "Epoch 58/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7472\n",
      "Epoch 59/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7419\n",
      "Epoch 60/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7450\n",
      "Epoch 61/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7405\n",
      "Epoch 62/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7489\n",
      "Epoch 63/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7408\n",
      "Epoch 64/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7420\n",
      "Epoch 65/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7386\n",
      "Epoch 66/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7418\n",
      "Epoch 67/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7402\n",
      "Epoch 68/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7354\n",
      "Epoch 69/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7377\n",
      "Epoch 70/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7399\n",
      "Epoch 71/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7369\n",
      "Epoch 72/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7347\n",
      "Epoch 73/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7313\n",
      "Epoch 74/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7353\n",
      "Epoch 75/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7315\n",
      "Epoch 76/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7331\n",
      "Epoch 77/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7334\n",
      "Epoch 78/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7334\n",
      "Epoch 79/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7284\n",
      "Epoch 80/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7276\n",
      "Epoch 81/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7276\n",
      "Epoch 82/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7285\n",
      "Epoch 83/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7302\n",
      "Epoch 84/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7279\n",
      "Epoch 85/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7267\n",
      "Epoch 86/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7241\n",
      "Epoch 87/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7246\n",
      "Epoch 88/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7269\n",
      "Epoch 89/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7231\n",
      "Epoch 90/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7252\n",
      "Epoch 91/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7240\n",
      "Epoch 92/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7240\n",
      "Epoch 93/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7255\n",
      "Epoch 94/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7186\n",
      "Epoch 95/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7221\n",
      "Epoch 96/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7205\n",
      "Epoch 97/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7245\n",
      "Epoch 98/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7224\n",
      "Epoch 99/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7209\n",
      "Epoch 100/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7169\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Testing with layers=[128, 64, 32], encoding_dim=8, batch_size=64, epochs=100, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "16/16 - 1s - 93ms/step - loss: 1.2126\n",
      "Epoch 2/100\n",
      "16/16 - 0s - 2ms/step - loss: 1.1029\n",
      "Epoch 3/100\n",
      "16/16 - 0s - 2ms/step - loss: 1.0393\n",
      "Epoch 4/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.9989\n",
      "Epoch 5/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.9689\n",
      "Epoch 6/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.9490\n",
      "Epoch 7/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.9340\n",
      "Epoch 8/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.9218\n",
      "Epoch 9/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.9084\n",
      "Epoch 10/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8979\n",
      "Epoch 11/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.8852\n",
      "Epoch 12/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.8793\n",
      "Epoch 13/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.8728\n",
      "Epoch 14/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.8711\n",
      "Epoch 15/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8622\n",
      "Epoch 16/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8558\n",
      "Epoch 17/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.8523\n",
      "Epoch 18/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.8477\n",
      "Epoch 19/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8456\n",
      "Epoch 20/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.8389\n",
      "Epoch 21/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8364\n",
      "Epoch 22/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8329\n",
      "Epoch 23/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8266\n",
      "Epoch 24/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8276\n",
      "Epoch 25/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.8272\n",
      "Epoch 26/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.8194\n",
      "Epoch 27/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.8171\n",
      "Epoch 28/100\n",
      "16/16 - 0s - 10ms/step - loss: 0.8157\n",
      "Epoch 29/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.8136\n",
      "Epoch 30/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.8114\n",
      "Epoch 31/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.8116\n",
      "Epoch 32/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.8098\n",
      "Epoch 33/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.8061\n",
      "Epoch 34/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.8032\n",
      "Epoch 35/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.8056\n",
      "Epoch 36/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.8028\n",
      "Epoch 37/100\n",
      "16/16 - 0s - 7ms/step - loss: 0.8048\n",
      "Epoch 38/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7999\n",
      "Epoch 39/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.8006\n",
      "Epoch 40/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7985\n",
      "Epoch 41/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7977\n",
      "Epoch 42/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7984\n",
      "Epoch 43/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7923\n",
      "Epoch 44/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7888\n",
      "Epoch 45/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7915\n",
      "Epoch 46/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7922\n",
      "Epoch 47/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7916\n",
      "Epoch 48/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7924\n",
      "Epoch 49/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7880\n",
      "Epoch 50/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7844\n",
      "Epoch 51/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7846\n",
      "Epoch 52/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7865\n",
      "Epoch 53/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7854\n",
      "Epoch 54/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7875\n",
      "Epoch 55/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7811\n",
      "Epoch 56/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7839\n",
      "Epoch 57/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7799\n",
      "Epoch 58/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7839\n",
      "Epoch 59/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7820\n",
      "Epoch 60/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7815\n",
      "Epoch 61/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7775\n",
      "Epoch 62/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7787\n",
      "Epoch 63/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7775\n",
      "Epoch 64/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7737\n",
      "Epoch 65/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7768\n",
      "Epoch 66/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7699\n",
      "Epoch 67/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7733\n",
      "Epoch 68/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7724\n",
      "Epoch 69/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7729\n",
      "Epoch 70/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7729\n",
      "Epoch 71/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7733\n",
      "Epoch 72/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7741\n",
      "Epoch 73/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7694\n",
      "Epoch 74/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7695\n",
      "Epoch 75/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7738\n",
      "Epoch 76/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7711\n",
      "Epoch 77/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7677\n",
      "Epoch 78/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7701\n",
      "Epoch 79/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7687\n",
      "Epoch 80/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7668\n",
      "Epoch 81/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7675\n",
      "Epoch 82/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7687\n",
      "Epoch 83/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7661\n",
      "Epoch 84/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7682\n",
      "Epoch 85/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7656\n",
      "Epoch 86/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7696\n",
      "Epoch 87/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7670\n",
      "Epoch 88/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7628\n",
      "Epoch 89/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7676\n",
      "Epoch 90/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7640\n",
      "Epoch 91/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7662\n",
      "Epoch 92/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7629\n",
      "Epoch 93/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7646\n",
      "Epoch 94/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7633\n",
      "Epoch 95/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7616\n",
      "Epoch 96/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7633\n",
      "Epoch 97/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7614\n",
      "Epoch 98/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7609\n",
      "Epoch 99/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7589\n",
      "Epoch 100/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7591\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Testing with layers=[128, 64, 32], encoding_dim=8, batch_size=128, epochs=50, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "8/8 - 1s - 184ms/step - loss: 1.2454\n",
      "Epoch 2/50\n",
      "8/8 - 0s - 3ms/step - loss: 1.1543\n",
      "Epoch 3/50\n",
      "8/8 - 0s - 3ms/step - loss: 1.0902\n",
      "Epoch 4/50\n",
      "8/8 - 0s - 3ms/step - loss: 1.0432\n",
      "Epoch 5/50\n",
      "8/8 - 0s - 3ms/step - loss: 1.0050\n",
      "Epoch 6/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.9757\n",
      "Epoch 7/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.9554\n",
      "Epoch 8/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.9344\n",
      "Epoch 9/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.9186\n",
      "Epoch 10/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.9059\n",
      "Epoch 11/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8979\n",
      "Epoch 12/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8839\n",
      "Epoch 13/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8785\n",
      "Epoch 14/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8705\n",
      "Epoch 15/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8649\n",
      "Epoch 16/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8580\n",
      "Epoch 17/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8490\n",
      "Epoch 18/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8457\n",
      "Epoch 19/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8383\n",
      "Epoch 20/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8321\n",
      "Epoch 21/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8328\n",
      "Epoch 22/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8273\n",
      "Epoch 23/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8262\n",
      "Epoch 24/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8208\n",
      "Epoch 25/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.8181\n",
      "Epoch 26/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.8163\n",
      "Epoch 27/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.8114\n",
      "Epoch 28/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.8080\n",
      "Epoch 29/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.8080\n",
      "Epoch 30/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.8041\n",
      "Epoch 31/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8031\n",
      "Epoch 32/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8036\n",
      "Epoch 33/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7973\n",
      "Epoch 34/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7954\n",
      "Epoch 35/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7937\n",
      "Epoch 36/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7934\n",
      "Epoch 37/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7921\n",
      "Epoch 38/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7893\n",
      "Epoch 39/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7866\n",
      "Epoch 40/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7849\n",
      "Epoch 41/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7830\n",
      "Epoch 42/50\n",
      "8/8 - 0s - 9ms/step - loss: 0.7848\n",
      "Epoch 43/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.7770\n",
      "Epoch 44/50\n",
      "8/8 - 0s - 9ms/step - loss: 0.7803\n",
      "Epoch 45/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.7775\n",
      "Epoch 46/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7753\n",
      "Epoch 47/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7772\n",
      "Epoch 48/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7754\n",
      "Epoch 49/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.7723\n",
      "Epoch 50/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.7690\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Testing with layers=[128, 64, 32], encoding_dim=8, batch_size=128, epochs=50, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "8/8 - 1s - 181ms/step - loss: 1.2664\n",
      "Epoch 2/50\n",
      "8/8 - 0s - 3ms/step - loss: 1.1856\n",
      "Epoch 3/50\n",
      "8/8 - 0s - 3ms/step - loss: 1.1247\n",
      "Epoch 4/50\n",
      "8/8 - 0s - 3ms/step - loss: 1.0781\n",
      "Epoch 5/50\n",
      "8/8 - 0s - 3ms/step - loss: 1.0414\n",
      "Epoch 6/50\n",
      "8/8 - 0s - 3ms/step - loss: 1.0126\n",
      "Epoch 7/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.9928\n",
      "Epoch 8/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.9748\n",
      "Epoch 9/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.9617\n",
      "Epoch 10/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.9525\n",
      "Epoch 11/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.9370\n",
      "Epoch 12/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.9318\n",
      "Epoch 13/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.9216\n",
      "Epoch 14/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.9164\n",
      "Epoch 15/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.9110\n",
      "Epoch 16/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.9051\n",
      "Epoch 17/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8987\n",
      "Epoch 18/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8926\n",
      "Epoch 19/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8884\n",
      "Epoch 20/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8831\n",
      "Epoch 21/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8801\n",
      "Epoch 22/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8739\n",
      "Epoch 23/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8711\n",
      "Epoch 24/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8694\n",
      "Epoch 25/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8644\n",
      "Epoch 26/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8632\n",
      "Epoch 27/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8611\n",
      "Epoch 28/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8583\n",
      "Epoch 29/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.8524\n",
      "Epoch 30/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8521\n",
      "Epoch 31/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.8473\n",
      "Epoch 32/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8468\n",
      "Epoch 33/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8433\n",
      "Epoch 34/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8379\n",
      "Epoch 35/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8396\n",
      "Epoch 36/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.8355\n",
      "Epoch 37/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8332\n",
      "Epoch 38/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8306\n",
      "Epoch 39/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8281\n",
      "Epoch 40/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8263\n",
      "Epoch 41/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8272\n",
      "Epoch 42/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8240\n",
      "Epoch 43/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8214\n",
      "Epoch 44/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8198\n",
      "Epoch 45/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8195\n",
      "Epoch 46/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8202\n",
      "Epoch 47/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8173\n",
      "Epoch 48/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8145\n",
      "Epoch 49/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8104\n",
      "Epoch 50/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8126\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Testing with layers=[128, 64, 32], encoding_dim=8, batch_size=128, epochs=100, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "8/8 - 2s - 209ms/step - loss: 1.2271\n",
      "Epoch 2/100\n",
      "8/8 - 0s - 3ms/step - loss: 1.1366\n",
      "Epoch 3/100\n",
      "8/8 - 0s - 3ms/step - loss: 1.0794\n",
      "Epoch 4/100\n",
      "8/8 - 0s - 3ms/step - loss: 1.0340\n",
      "Epoch 5/100\n",
      "8/8 - 0s - 3ms/step - loss: 1.0013\n",
      "Epoch 6/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.9736\n",
      "Epoch 7/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.9583\n",
      "Epoch 8/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.9418\n",
      "Epoch 9/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.9256\n",
      "Epoch 10/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.9150\n",
      "Epoch 11/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.9039\n",
      "Epoch 12/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8945\n",
      "Epoch 13/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8857\n",
      "Epoch 14/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8780\n",
      "Epoch 15/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8699\n",
      "Epoch 16/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8660\n",
      "Epoch 17/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8601\n",
      "Epoch 18/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8573\n",
      "Epoch 19/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8485\n",
      "Epoch 20/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8447\n",
      "Epoch 21/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8391\n",
      "Epoch 22/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8361\n",
      "Epoch 23/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8337\n",
      "Epoch 24/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8302\n",
      "Epoch 25/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8246\n",
      "Epoch 26/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8251\n",
      "Epoch 27/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8208\n",
      "Epoch 28/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8162\n",
      "Epoch 29/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8143\n",
      "Epoch 30/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8085\n",
      "Epoch 31/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8064\n",
      "Epoch 32/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8027\n",
      "Epoch 33/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8024\n",
      "Epoch 34/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8018\n",
      "Epoch 35/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7992\n",
      "Epoch 36/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7980\n",
      "Epoch 37/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7946\n",
      "Epoch 38/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7899\n",
      "Epoch 39/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7906\n",
      "Epoch 40/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7888\n",
      "Epoch 41/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7852\n",
      "Epoch 42/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7833\n",
      "Epoch 43/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7820\n",
      "Epoch 44/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7810\n",
      "Epoch 45/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7796\n",
      "Epoch 46/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7761\n",
      "Epoch 47/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7736\n",
      "Epoch 48/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7768\n",
      "Epoch 49/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7737\n",
      "Epoch 50/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7720\n",
      "Epoch 51/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7703\n",
      "Epoch 52/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7689\n",
      "Epoch 53/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7656\n",
      "Epoch 54/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7687\n",
      "Epoch 55/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7678\n",
      "Epoch 56/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7688\n",
      "Epoch 57/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7617\n",
      "Epoch 58/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7616\n",
      "Epoch 59/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7634\n",
      "Epoch 60/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7622\n",
      "Epoch 61/100\n",
      "8/8 - 0s - 10ms/step - loss: 0.7594\n",
      "Epoch 62/100\n",
      "8/8 - 0s - 10ms/step - loss: 0.7588\n",
      "Epoch 63/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7576\n",
      "Epoch 64/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7575\n",
      "Epoch 65/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7551\n",
      "Epoch 66/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7529\n",
      "Epoch 67/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7529\n",
      "Epoch 68/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7534\n",
      "Epoch 69/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7534\n",
      "Epoch 70/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7482\n",
      "Epoch 71/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7490\n",
      "Epoch 72/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7503\n",
      "Epoch 73/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7503\n",
      "Epoch 74/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7468\n",
      "Epoch 75/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7472\n",
      "Epoch 76/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7450\n",
      "Epoch 77/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7446\n",
      "Epoch 78/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7441\n",
      "Epoch 79/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7458\n",
      "Epoch 80/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7428\n",
      "Epoch 81/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7423\n",
      "Epoch 82/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7394\n",
      "Epoch 83/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7448\n",
      "Epoch 84/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7411\n",
      "Epoch 85/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7365\n",
      "Epoch 86/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7401\n",
      "Epoch 87/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7371\n",
      "Epoch 88/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7343\n",
      "Epoch 89/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7346\n",
      "Epoch 90/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7349\n",
      "Epoch 91/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7359\n",
      "Epoch 92/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7348\n",
      "Epoch 93/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7335\n",
      "Epoch 94/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7387\n",
      "Epoch 95/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7322\n",
      "Epoch 96/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7338\n",
      "Epoch 97/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7341\n",
      "Epoch 98/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7298\n",
      "Epoch 99/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7301\n",
      "Epoch 100/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7315\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "Testing with layers=[128, 64, 32], encoding_dim=8, batch_size=128, epochs=100, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "8/8 - 2s - 237ms/step - loss: 1.2794\n",
      "Epoch 2/100\n",
      "8/8 - 0s - 3ms/step - loss: 1.1994\n",
      "Epoch 3/100\n",
      "8/8 - 0s - 12ms/step - loss: 1.1401\n",
      "Epoch 4/100\n",
      "8/8 - 0s - 4ms/step - loss: 1.0903\n",
      "Epoch 5/100\n",
      "8/8 - 0s - 5ms/step - loss: 1.0543\n",
      "Epoch 6/100\n",
      "8/8 - 0s - 4ms/step - loss: 1.0268\n",
      "Epoch 7/100\n",
      "8/8 - 0s - 4ms/step - loss: 1.0022\n",
      "Epoch 8/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.9906\n",
      "Epoch 9/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.9719\n",
      "Epoch 10/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.9593\n",
      "Epoch 11/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.9520\n",
      "Epoch 12/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.9387\n",
      "Epoch 13/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.9309\n",
      "Epoch 14/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.9240\n",
      "Epoch 15/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.9178\n",
      "Epoch 16/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.9112\n",
      "Epoch 17/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.9049\n",
      "Epoch 18/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8993\n",
      "Epoch 19/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8940\n",
      "Epoch 20/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8903\n",
      "Epoch 21/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.8839\n",
      "Epoch 22/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8802\n",
      "Epoch 23/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8763\n",
      "Epoch 24/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8724\n",
      "Epoch 25/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8684\n",
      "Epoch 26/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8666\n",
      "Epoch 27/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8631\n",
      "Epoch 28/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8608\n",
      "Epoch 29/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8551\n",
      "Epoch 30/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8541\n",
      "Epoch 31/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8523\n",
      "Epoch 32/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8475\n",
      "Epoch 33/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8455\n",
      "Epoch 34/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8405\n",
      "Epoch 35/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8408\n",
      "Epoch 36/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8390\n",
      "Epoch 37/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8341\n",
      "Epoch 38/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8342\n",
      "Epoch 39/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8281\n",
      "Epoch 40/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8286\n",
      "Epoch 41/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8263\n",
      "Epoch 42/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8207\n",
      "Epoch 43/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8231\n",
      "Epoch 44/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8229\n",
      "Epoch 45/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8182\n",
      "Epoch 46/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8205\n",
      "Epoch 47/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8163\n",
      "Epoch 48/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8193\n",
      "Epoch 49/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8154\n",
      "Epoch 50/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8153\n",
      "Epoch 51/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8127\n",
      "Epoch 52/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8113\n",
      "Epoch 53/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8110\n",
      "Epoch 54/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8078\n",
      "Epoch 55/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8085\n",
      "Epoch 56/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8062\n",
      "Epoch 57/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8036\n",
      "Epoch 58/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8053\n",
      "Epoch 59/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8089\n",
      "Epoch 60/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8063\n",
      "Epoch 61/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8003\n",
      "Epoch 62/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7986\n",
      "Epoch 63/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7986\n",
      "Epoch 64/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.8013\n",
      "Epoch 65/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7988\n",
      "Epoch 66/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7981\n",
      "Epoch 67/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7974\n",
      "Epoch 68/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7968\n",
      "Epoch 69/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7953\n",
      "Epoch 70/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7947\n",
      "Epoch 71/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7915\n",
      "Epoch 72/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7938\n",
      "Epoch 73/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7902\n",
      "Epoch 74/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7867\n",
      "Epoch 75/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7886\n",
      "Epoch 76/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7887\n",
      "Epoch 77/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7917\n",
      "Epoch 78/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7913\n",
      "Epoch 79/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7910\n",
      "Epoch 80/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7864\n",
      "Epoch 81/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7864\n",
      "Epoch 82/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7855\n",
      "Epoch 83/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7836\n",
      "Epoch 84/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7795\n",
      "Epoch 85/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7860\n",
      "Epoch 86/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7802\n",
      "Epoch 87/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7850\n",
      "Epoch 88/100\n",
      "8/8 - 0s - 9ms/step - loss: 0.7774\n",
      "Epoch 89/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7793\n",
      "Epoch 90/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7797\n",
      "Epoch 91/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7807\n",
      "Epoch 92/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7782\n",
      "Epoch 93/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7767\n",
      "Epoch 94/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7777\n",
      "Epoch 95/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7772\n",
      "Epoch 96/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7753\n",
      "Epoch 97/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7761\n",
      "Epoch 98/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7725\n",
      "Epoch 99/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7766\n",
      "Epoch 100/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7748\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "Testing with layers=[128, 64, 32], encoding_dim=10, batch_size=32, epochs=50, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "32/32 - 1s - 45ms/step - loss: 1.1563\n",
      "Epoch 2/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.9973\n",
      "Epoch 3/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.9372\n",
      "Epoch 4/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.9026\n",
      "Epoch 5/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8820\n",
      "Epoch 6/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8670\n",
      "Epoch 7/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8472\n",
      "Epoch 8/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8367\n",
      "Epoch 9/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8265\n",
      "Epoch 10/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8212\n",
      "Epoch 11/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8111\n",
      "Epoch 12/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8048\n",
      "Epoch 13/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8005\n",
      "Epoch 14/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7931\n",
      "Epoch 15/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7855\n",
      "Epoch 16/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7837\n",
      "Epoch 17/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7797\n",
      "Epoch 18/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7753\n",
      "Epoch 19/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7726\n",
      "Epoch 20/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7656\n",
      "Epoch 21/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7649\n",
      "Epoch 22/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7626\n",
      "Epoch 23/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7573\n",
      "Epoch 24/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7555\n",
      "Epoch 25/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7545\n",
      "Epoch 26/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7504\n",
      "Epoch 27/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7531\n",
      "Epoch 28/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7461\n",
      "Epoch 29/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7406\n",
      "Epoch 30/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7401\n",
      "Epoch 31/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7428\n",
      "Epoch 32/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7377\n",
      "Epoch 33/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7376\n",
      "Epoch 34/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7353\n",
      "Epoch 35/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7341\n",
      "Epoch 36/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7368\n",
      "Epoch 37/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7288\n",
      "Epoch 38/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7300\n",
      "Epoch 39/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7281\n",
      "Epoch 40/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7298\n",
      "Epoch 41/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7233\n",
      "Epoch 42/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7211\n",
      "Epoch 43/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7184\n",
      "Epoch 44/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7210\n",
      "Epoch 45/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7193\n",
      "Epoch 46/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7176\n",
      "Epoch 47/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7203\n",
      "Epoch 48/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7161\n",
      "Epoch 49/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7158\n",
      "Epoch 50/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7139\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n",
      "Testing with layers=[128, 64, 32], encoding_dim=10, batch_size=32, epochs=50, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "32/32 - 1s - 45ms/step - loss: 1.2097\n",
      "Epoch 2/50\n",
      "32/32 - 0s - 1ms/step - loss: 1.0524\n",
      "Epoch 3/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.9856\n",
      "Epoch 4/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.9496\n",
      "Epoch 5/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.9251\n",
      "Epoch 6/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.9088\n",
      "Epoch 7/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8883\n",
      "Epoch 8/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8807\n",
      "Epoch 9/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8661\n",
      "Epoch 10/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8594\n",
      "Epoch 11/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8508\n",
      "Epoch 12/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8464\n",
      "Epoch 13/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8395\n",
      "Epoch 14/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8325\n",
      "Epoch 15/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8237\n",
      "Epoch 16/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8198\n",
      "Epoch 17/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8144\n",
      "Epoch 18/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8123\n",
      "Epoch 19/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8099\n",
      "Epoch 20/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7996\n",
      "Epoch 21/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8007\n",
      "Epoch 22/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7975\n",
      "Epoch 23/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7947\n",
      "Epoch 24/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7927\n",
      "Epoch 25/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7892\n",
      "Epoch 26/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7876\n",
      "Epoch 27/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7841\n",
      "Epoch 28/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7831\n",
      "Epoch 29/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7810\n",
      "Epoch 30/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7818\n",
      "Epoch 31/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7758\n",
      "Epoch 32/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7720\n",
      "Epoch 33/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7722\n",
      "Epoch 34/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7708\n",
      "Epoch 35/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7714\n",
      "Epoch 36/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7728\n",
      "Epoch 37/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7660\n",
      "Epoch 38/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7639\n",
      "Epoch 39/50\n",
      "32/32 - 0s - 4ms/step - loss: 0.7644\n",
      "Epoch 40/50\n",
      "32/32 - 0s - 5ms/step - loss: 0.7658\n",
      "Epoch 41/50\n",
      "32/32 - 0s - 7ms/step - loss: 0.7636\n",
      "Epoch 42/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7629\n",
      "Epoch 43/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7614\n",
      "Epoch 44/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7586\n",
      "Epoch 45/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7598\n",
      "Epoch 46/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7555\n",
      "Epoch 47/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7539\n",
      "Epoch 48/50\n",
      "32/32 - 0s - 5ms/step - loss: 0.7594\n",
      "Epoch 49/50\n",
      "32/32 - 0s - 5ms/step - loss: 0.7542\n",
      "Epoch 50/50\n",
      "32/32 - 0s - 4ms/step - loss: 0.7499\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Testing with layers=[128, 64, 32], encoding_dim=10, batch_size=32, epochs=100, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "32/32 - 2s - 50ms/step - loss: 1.1846\n",
      "Epoch 2/100\n",
      "32/32 - 0s - 1ms/step - loss: 1.0233\n",
      "Epoch 3/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.9508\n",
      "Epoch 4/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.9123\n",
      "Epoch 5/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8859\n",
      "Epoch 6/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8640\n",
      "Epoch 7/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8521\n",
      "Epoch 8/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8359\n",
      "Epoch 9/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8245\n",
      "Epoch 10/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8135\n",
      "Epoch 11/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8066\n",
      "Epoch 12/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7998\n",
      "Epoch 13/100\n",
      "32/32 - 0s - 981us/step - loss: 0.7917\n",
      "Epoch 14/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7883\n",
      "Epoch 15/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7836\n",
      "Epoch 16/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7805\n",
      "Epoch 17/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7731\n",
      "Epoch 18/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7731\n",
      "Epoch 19/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7680\n",
      "Epoch 20/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7643\n",
      "Epoch 21/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7590\n",
      "Epoch 22/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7585\n",
      "Epoch 23/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7548\n",
      "Epoch 24/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7515\n",
      "Epoch 25/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7515\n",
      "Epoch 26/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7474\n",
      "Epoch 27/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7471\n",
      "Epoch 28/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7470\n",
      "Epoch 29/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7428\n",
      "Epoch 30/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7436\n",
      "Epoch 31/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7387\n",
      "Epoch 32/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7405\n",
      "Epoch 33/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7385\n",
      "Epoch 34/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7361\n",
      "Epoch 35/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7349\n",
      "Epoch 36/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7325\n",
      "Epoch 37/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7310\n",
      "Epoch 38/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7279\n",
      "Epoch 39/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7301\n",
      "Epoch 40/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7268\n",
      "Epoch 41/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7318\n",
      "Epoch 42/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7258\n",
      "Epoch 43/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7268\n",
      "Epoch 44/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7244\n",
      "Epoch 45/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7214\n",
      "Epoch 46/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7166\n",
      "Epoch 47/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7207\n",
      "Epoch 48/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7191\n",
      "Epoch 49/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7168\n",
      "Epoch 50/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7174\n",
      "Epoch 51/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7140\n",
      "Epoch 52/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7126\n",
      "Epoch 53/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7161\n",
      "Epoch 54/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7138\n",
      "Epoch 55/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7109\n",
      "Epoch 56/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7106\n",
      "Epoch 57/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7087\n",
      "Epoch 58/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7109\n",
      "Epoch 59/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7108\n",
      "Epoch 60/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7063\n",
      "Epoch 61/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7072\n",
      "Epoch 62/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7063\n",
      "Epoch 63/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7043\n",
      "Epoch 64/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7017\n",
      "Epoch 65/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7019\n",
      "Epoch 66/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7039\n",
      "Epoch 67/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6998\n",
      "Epoch 68/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6975\n",
      "Epoch 69/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6967\n",
      "Epoch 70/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7009\n",
      "Epoch 71/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6963\n",
      "Epoch 72/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6966\n",
      "Epoch 73/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6982\n",
      "Epoch 74/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6941\n",
      "Epoch 75/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6970\n",
      "Epoch 76/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6952\n",
      "Epoch 77/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6922\n",
      "Epoch 78/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6945\n",
      "Epoch 79/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6915\n",
      "Epoch 80/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6931\n",
      "Epoch 81/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6910\n",
      "Epoch 82/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6917\n",
      "Epoch 83/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6887\n",
      "Epoch 84/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6880\n",
      "Epoch 85/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6903\n",
      "Epoch 86/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6899\n",
      "Epoch 87/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6895\n",
      "Epoch 88/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6840\n",
      "Epoch 89/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6816\n",
      "Epoch 90/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6862\n",
      "Epoch 91/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6879\n",
      "Epoch 92/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6893\n",
      "Epoch 93/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6885\n",
      "Epoch 94/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6833\n",
      "Epoch 95/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6805\n",
      "Epoch 96/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6836\n",
      "Epoch 97/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6871\n",
      "Epoch 98/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6846\n",
      "Epoch 99/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6820\n",
      "Epoch 100/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6828\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Testing with layers=[128, 64, 32], encoding_dim=10, batch_size=32, epochs=100, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "32/32 - 1s - 47ms/step - loss: 1.1609\n",
      "Epoch 2/100\n",
      "32/32 - 0s - 1ms/step - loss: 1.0269\n",
      "Epoch 3/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.9754\n",
      "Epoch 4/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.9385\n",
      "Epoch 5/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.9249\n",
      "Epoch 6/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.9047\n",
      "Epoch 7/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8882\n",
      "Epoch 8/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8831\n",
      "Epoch 9/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8656\n",
      "Epoch 10/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8588\n",
      "Epoch 11/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8524\n",
      "Epoch 12/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8401\n",
      "Epoch 13/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8380\n",
      "Epoch 14/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8286\n",
      "Epoch 15/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8247\n",
      "Epoch 16/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8157\n",
      "Epoch 17/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8159\n",
      "Epoch 18/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8091\n",
      "Epoch 19/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8033\n",
      "Epoch 20/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7991\n",
      "Epoch 21/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7959\n",
      "Epoch 22/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7928\n",
      "Epoch 23/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7871\n",
      "Epoch 24/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7899\n",
      "Epoch 25/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7851\n",
      "Epoch 26/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7858\n",
      "Epoch 27/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7817\n",
      "Epoch 28/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7798\n",
      "Epoch 29/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7770\n",
      "Epoch 30/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7778\n",
      "Epoch 31/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7736\n",
      "Epoch 32/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7732\n",
      "Epoch 33/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7731\n",
      "Epoch 34/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7665\n",
      "Epoch 35/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7667\n",
      "Epoch 36/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7670\n",
      "Epoch 37/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7630\n",
      "Epoch 38/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7651\n",
      "Epoch 39/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7662\n",
      "Epoch 40/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7625\n",
      "Epoch 41/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7657\n",
      "Epoch 42/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7607\n",
      "Epoch 43/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7614\n",
      "Epoch 44/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.7608\n",
      "Epoch 45/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7609\n",
      "Epoch 46/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7565\n",
      "Epoch 47/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7547\n",
      "Epoch 48/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7571\n",
      "Epoch 49/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.7542\n",
      "Epoch 50/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.7549\n",
      "Epoch 51/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7556\n",
      "Epoch 52/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7552\n",
      "Epoch 53/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7528\n",
      "Epoch 54/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7525\n",
      "Epoch 55/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7515\n",
      "Epoch 56/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7487\n",
      "Epoch 57/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7524\n",
      "Epoch 58/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7484\n",
      "Epoch 59/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7480\n",
      "Epoch 60/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7508\n",
      "Epoch 61/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7476\n",
      "Epoch 62/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.7542\n",
      "Epoch 63/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.7447\n",
      "Epoch 64/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7445\n",
      "Epoch 65/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7472\n",
      "Epoch 66/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7476\n",
      "Epoch 67/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7476\n",
      "Epoch 68/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7443\n",
      "Epoch 69/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7382\n",
      "Epoch 70/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7436\n",
      "Epoch 71/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7445\n",
      "Epoch 72/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7418\n",
      "Epoch 73/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7403\n",
      "Epoch 74/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7410\n",
      "Epoch 75/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7399\n",
      "Epoch 76/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7391\n",
      "Epoch 77/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7364\n",
      "Epoch 78/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7414\n",
      "Epoch 79/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7365\n",
      "Epoch 80/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7375\n",
      "Epoch 81/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7393\n",
      "Epoch 82/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7355\n",
      "Epoch 83/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7392\n",
      "Epoch 84/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7379\n",
      "Epoch 85/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7373\n",
      "Epoch 86/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7389\n",
      "Epoch 87/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7348\n",
      "Epoch 88/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7326\n",
      "Epoch 89/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7333\n",
      "Epoch 90/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7344\n",
      "Epoch 91/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7369\n",
      "Epoch 92/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7353\n",
      "Epoch 93/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7338\n",
      "Epoch 94/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7334\n",
      "Epoch 95/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7358\n",
      "Epoch 96/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7283\n",
      "Epoch 97/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7302\n",
      "Epoch 98/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7320\n",
      "Epoch 99/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7368\n",
      "Epoch 100/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7335\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Testing with layers=[128, 64, 32], encoding_dim=10, batch_size=64, epochs=50, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "16/16 - 1s - 81ms/step - loss: 1.2454\n",
      "Epoch 2/50\n",
      "16/16 - 0s - 2ms/step - loss: 1.1012\n",
      "Epoch 3/50\n",
      "16/16 - 0s - 2ms/step - loss: 1.0238\n",
      "Epoch 4/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.9701\n",
      "Epoch 5/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.9366\n",
      "Epoch 6/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.9147\n",
      "Epoch 7/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8951\n",
      "Epoch 8/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8812\n",
      "Epoch 9/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8695\n",
      "Epoch 10/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8548\n",
      "Epoch 11/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8449\n",
      "Epoch 12/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8363\n",
      "Epoch 13/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8308\n",
      "Epoch 14/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8245\n",
      "Epoch 15/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8148\n",
      "Epoch 16/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8076\n",
      "Epoch 17/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8028\n",
      "Epoch 18/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8001\n",
      "Epoch 19/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7917\n",
      "Epoch 20/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7889\n",
      "Epoch 21/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7878\n",
      "Epoch 22/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7790\n",
      "Epoch 23/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7744\n",
      "Epoch 24/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7733\n",
      "Epoch 25/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7692\n",
      "Epoch 26/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7652\n",
      "Epoch 27/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7621\n",
      "Epoch 28/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7559\n",
      "Epoch 29/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7600\n",
      "Epoch 30/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7555\n",
      "Epoch 31/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7510\n",
      "Epoch 32/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7480\n",
      "Epoch 33/50\n",
      "16/16 - 0s - 23ms/step - loss: 0.7453\n",
      "Epoch 34/50\n",
      "16/16 - 0s - 5ms/step - loss: 0.7412\n",
      "Epoch 35/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7422\n",
      "Epoch 36/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7383\n",
      "Epoch 37/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7396\n",
      "Epoch 38/50\n",
      "16/16 - 0s - 5ms/step - loss: 0.7339\n",
      "Epoch 39/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7343\n",
      "Epoch 40/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7320\n",
      "Epoch 41/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7307\n",
      "Epoch 42/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7328\n",
      "Epoch 43/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7310\n",
      "Epoch 44/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7252\n",
      "Epoch 45/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7245\n",
      "Epoch 46/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7255\n",
      "Epoch 47/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7215\n",
      "Epoch 48/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7221\n",
      "Epoch 49/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7196\n",
      "Epoch 50/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7183\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Testing with layers=[128, 64, 32], encoding_dim=10, batch_size=64, epochs=50, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "16/16 - 2s - 103ms/step - loss: 1.2190\n",
      "Epoch 2/50\n",
      "16/16 - 0s - 2ms/step - loss: 1.1079\n",
      "Epoch 3/50\n",
      "16/16 - 0s - 2ms/step - loss: 1.0391\n",
      "Epoch 4/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.9948\n",
      "Epoch 5/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.9640\n",
      "Epoch 6/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.9414\n",
      "Epoch 7/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.9252\n",
      "Epoch 8/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.9094\n",
      "Epoch 9/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8914\n",
      "Epoch 10/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8877\n",
      "Epoch 11/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8798\n",
      "Epoch 12/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8691\n",
      "Epoch 13/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8612\n",
      "Epoch 14/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8588\n",
      "Epoch 15/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8519\n",
      "Epoch 16/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8469\n",
      "Epoch 17/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8395\n",
      "Epoch 18/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8362\n",
      "Epoch 19/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8330\n",
      "Epoch 20/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8279\n",
      "Epoch 21/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8218\n",
      "Epoch 22/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8181\n",
      "Epoch 23/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8175\n",
      "Epoch 24/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.8132\n",
      "Epoch 25/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.8063\n",
      "Epoch 26/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8032\n",
      "Epoch 27/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8018\n",
      "Epoch 28/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8035\n",
      "Epoch 29/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7960\n",
      "Epoch 30/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7960\n",
      "Epoch 31/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7927\n",
      "Epoch 32/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7910\n",
      "Epoch 33/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7874\n",
      "Epoch 34/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7866\n",
      "Epoch 35/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7869\n",
      "Epoch 36/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7823\n",
      "Epoch 37/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7848\n",
      "Epoch 38/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7775\n",
      "Epoch 39/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7765\n",
      "Epoch 40/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7752\n",
      "Epoch 41/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7746\n",
      "Epoch 42/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7756\n",
      "Epoch 43/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7703\n",
      "Epoch 44/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7684\n",
      "Epoch 45/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7719\n",
      "Epoch 46/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7699\n",
      "Epoch 47/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7673\n",
      "Epoch 48/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7675\n",
      "Epoch 49/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7663\n",
      "Epoch 50/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7658\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Testing with layers=[128, 64, 32], encoding_dim=10, batch_size=64, epochs=100, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "16/16 - 1s - 80ms/step - loss: 1.2242\n",
      "Epoch 2/100\n",
      "16/16 - 0s - 2ms/step - loss: 1.0928\n",
      "Epoch 3/100\n",
      "16/16 - 0s - 2ms/step - loss: 1.0214\n",
      "Epoch 4/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.9696\n",
      "Epoch 5/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.9359\n",
      "Epoch 6/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.9093\n",
      "Epoch 7/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8942\n",
      "Epoch 8/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8772\n",
      "Epoch 9/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8658\n",
      "Epoch 10/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8544\n",
      "Epoch 11/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8452\n",
      "Epoch 12/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8358\n",
      "Epoch 13/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8275\n",
      "Epoch 14/100\n",
      "16/16 - 0s - 10ms/step - loss: 0.8215\n",
      "Epoch 15/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8160\n",
      "Epoch 16/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8107\n",
      "Epoch 17/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8011\n",
      "Epoch 18/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8007\n",
      "Epoch 19/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7940\n",
      "Epoch 20/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7895\n",
      "Epoch 21/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7827\n",
      "Epoch 22/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7801\n",
      "Epoch 23/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7768\n",
      "Epoch 24/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7788\n",
      "Epoch 25/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7736\n",
      "Epoch 26/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7681\n",
      "Epoch 27/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7694\n",
      "Epoch 28/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7642\n",
      "Epoch 29/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7586\n",
      "Epoch 30/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7602\n",
      "Epoch 31/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7544\n",
      "Epoch 32/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7561\n",
      "Epoch 33/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7506\n",
      "Epoch 34/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7508\n",
      "Epoch 35/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7459\n",
      "Epoch 36/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7466\n",
      "Epoch 37/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7465\n",
      "Epoch 38/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7413\n",
      "Epoch 39/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7389\n",
      "Epoch 40/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7394\n",
      "Epoch 41/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7345\n",
      "Epoch 42/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7354\n",
      "Epoch 43/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7342\n",
      "Epoch 44/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7290\n",
      "Epoch 45/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7280\n",
      "Epoch 46/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7287\n",
      "Epoch 47/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7287\n",
      "Epoch 48/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7253\n",
      "Epoch 49/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7247\n",
      "Epoch 50/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7217\n",
      "Epoch 51/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7236\n",
      "Epoch 52/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7221\n",
      "Epoch 53/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7200\n",
      "Epoch 54/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7183\n",
      "Epoch 55/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7201\n",
      "Epoch 56/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7176\n",
      "Epoch 57/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7154\n",
      "Epoch 58/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7148\n",
      "Epoch 59/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7128\n",
      "Epoch 60/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7102\n",
      "Epoch 61/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7117\n",
      "Epoch 62/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7120\n",
      "Epoch 63/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7100\n",
      "Epoch 64/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7071\n",
      "Epoch 65/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7087\n",
      "Epoch 66/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7074\n",
      "Epoch 67/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7058\n",
      "Epoch 68/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7063\n",
      "Epoch 69/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7026\n",
      "Epoch 70/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7018\n",
      "Epoch 71/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7039\n",
      "Epoch 72/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7044\n",
      "Epoch 73/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6986\n",
      "Epoch 74/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7000\n",
      "Epoch 75/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6983\n",
      "Epoch 76/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7042\n",
      "Epoch 77/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6988\n",
      "Epoch 78/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6955\n",
      "Epoch 79/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6960\n",
      "Epoch 80/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6989\n",
      "Epoch 81/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6947\n",
      "Epoch 82/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6938\n",
      "Epoch 83/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6950\n",
      "Epoch 84/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6926\n",
      "Epoch 85/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6925\n",
      "Epoch 86/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6921\n",
      "Epoch 87/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6914\n",
      "Epoch 88/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6903\n",
      "Epoch 89/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6885\n",
      "Epoch 90/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6944\n",
      "Epoch 91/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6899\n",
      "Epoch 92/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6887\n",
      "Epoch 93/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6890\n",
      "Epoch 94/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6898\n",
      "Epoch 95/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6873\n",
      "Epoch 96/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6853\n",
      "Epoch 97/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6837\n",
      "Epoch 98/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6869\n",
      "Epoch 99/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6821\n",
      "Epoch 100/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6834\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n",
      "Testing with layers=[128, 64, 32], encoding_dim=10, batch_size=64, epochs=100, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "16/16 - 1s - 79ms/step - loss: 1.2552\n",
      "Epoch 2/100\n",
      "16/16 - 0s - 2ms/step - loss: 1.1318\n",
      "Epoch 3/100\n",
      "16/16 - 0s - 2ms/step - loss: 1.0559\n",
      "Epoch 4/100\n",
      "16/16 - 0s - 2ms/step - loss: 1.0114\n",
      "Epoch 5/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.9782\n",
      "Epoch 6/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.9540\n",
      "Epoch 7/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.9330\n",
      "Epoch 8/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.9153\n",
      "Epoch 9/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.9098\n",
      "Epoch 10/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8964\n",
      "Epoch 11/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8875\n",
      "Epoch 12/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8802\n",
      "Epoch 13/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8746\n",
      "Epoch 14/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8667\n",
      "Epoch 15/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8630\n",
      "Epoch 16/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8531\n",
      "Epoch 17/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8488\n",
      "Epoch 18/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8454\n",
      "Epoch 19/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8420\n",
      "Epoch 20/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8387\n",
      "Epoch 21/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8322\n",
      "Epoch 22/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8270\n",
      "Epoch 23/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8247\n",
      "Epoch 24/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8229\n",
      "Epoch 25/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8215\n",
      "Epoch 26/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8212\n",
      "Epoch 27/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8162\n",
      "Epoch 28/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8146\n",
      "Epoch 29/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8106\n",
      "Epoch 30/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8092\n",
      "Epoch 31/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8068\n",
      "Epoch 32/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8076\n",
      "Epoch 33/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8050\n",
      "Epoch 34/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8050\n",
      "Epoch 35/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7979\n",
      "Epoch 36/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7950\n",
      "Epoch 37/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7942\n",
      "Epoch 38/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7962\n",
      "Epoch 39/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7967\n",
      "Epoch 40/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7911\n",
      "Epoch 41/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7888\n",
      "Epoch 42/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7901\n",
      "Epoch 43/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7872\n",
      "Epoch 44/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7842\n",
      "Epoch 45/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7834\n",
      "Epoch 46/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7833\n",
      "Epoch 47/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7857\n",
      "Epoch 48/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7793\n",
      "Epoch 49/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7776\n",
      "Epoch 50/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7768\n",
      "Epoch 51/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7773\n",
      "Epoch 52/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7737\n",
      "Epoch 53/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7777\n",
      "Epoch 54/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7733\n",
      "Epoch 55/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7705\n",
      "Epoch 56/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7641\n",
      "Epoch 57/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7704\n",
      "Epoch 58/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7659\n",
      "Epoch 59/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7658\n",
      "Epoch 60/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7618\n",
      "Epoch 61/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7653\n",
      "Epoch 62/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7642\n",
      "Epoch 63/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7617\n",
      "Epoch 64/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7551\n",
      "Epoch 65/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7581\n",
      "Epoch 66/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7562\n",
      "Epoch 67/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7562\n",
      "Epoch 68/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7546\n",
      "Epoch 69/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7542\n",
      "Epoch 70/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7560\n",
      "Epoch 71/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7560\n",
      "Epoch 72/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7513\n",
      "Epoch 73/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7531\n",
      "Epoch 74/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7528\n",
      "Epoch 75/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7510\n",
      "Epoch 76/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7479\n",
      "Epoch 77/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7492\n",
      "Epoch 78/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7486\n",
      "Epoch 79/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7449\n",
      "Epoch 80/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7480\n",
      "Epoch 81/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7470\n",
      "Epoch 82/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7463\n",
      "Epoch 83/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7451\n",
      "Epoch 84/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7440\n",
      "Epoch 85/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7397\n",
      "Epoch 86/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7430\n",
      "Epoch 87/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7398\n",
      "Epoch 88/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7417\n",
      "Epoch 89/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7388\n",
      "Epoch 90/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7366\n",
      "Epoch 91/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7381\n",
      "Epoch 92/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7389\n",
      "Epoch 93/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7393\n",
      "Epoch 94/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7385\n",
      "Epoch 95/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7357\n",
      "Epoch 96/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7376\n",
      "Epoch 97/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7377\n",
      "Epoch 98/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7330\n",
      "Epoch 99/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7358\n",
      "Epoch 100/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7324\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n",
      "Testing with layers=[128, 64, 32], encoding_dim=10, batch_size=128, epochs=50, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "8/8 - 1s - 149ms/step - loss: 1.2383\n",
      "Epoch 2/50\n",
      "8/8 - 0s - 3ms/step - loss: 1.1365\n",
      "Epoch 3/50\n",
      "8/8 - 0s - 3ms/step - loss: 1.0714\n",
      "Epoch 4/50\n",
      "8/8 - 0s - 3ms/step - loss: 1.0247\n",
      "Epoch 5/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.9947\n",
      "Epoch 6/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.9618\n",
      "Epoch 7/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.9437\n",
      "Epoch 8/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.9276\n",
      "Epoch 9/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.9144\n",
      "Epoch 10/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.9020\n",
      "Epoch 11/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8923\n",
      "Epoch 12/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8811\n",
      "Epoch 13/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8755\n",
      "Epoch 14/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8619\n",
      "Epoch 15/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8559\n",
      "Epoch 16/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8453\n",
      "Epoch 17/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8406\n",
      "Epoch 18/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8338\n",
      "Epoch 19/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8262\n",
      "Epoch 20/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8215\n",
      "Epoch 21/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8155\n",
      "Epoch 22/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8146\n",
      "Epoch 23/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8071\n",
      "Epoch 24/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8044\n",
      "Epoch 25/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7982\n",
      "Epoch 26/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7960\n",
      "Epoch 27/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7921\n",
      "Epoch 28/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7866\n",
      "Epoch 29/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7853\n",
      "Epoch 30/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7796\n",
      "Epoch 31/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7774\n",
      "Epoch 32/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7772\n",
      "Epoch 33/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7720\n",
      "Epoch 34/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7704\n",
      "Epoch 35/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7699\n",
      "Epoch 36/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7641\n",
      "Epoch 37/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7648\n",
      "Epoch 38/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7618\n",
      "Epoch 39/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7581\n",
      "Epoch 40/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7570\n",
      "Epoch 41/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7568\n",
      "Epoch 42/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7561\n",
      "Epoch 43/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7505\n",
      "Epoch 44/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7500\n",
      "Epoch 45/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7503\n",
      "Epoch 46/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7502\n",
      "Epoch 47/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7460\n",
      "Epoch 48/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7481\n",
      "Epoch 49/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7451\n",
      "Epoch 50/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7424\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Testing with layers=[128, 64, 32], encoding_dim=10, batch_size=128, epochs=50, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "8/8 - 1s - 162ms/step - loss: 1.2921\n",
      "Epoch 2/50\n",
      "8/8 - 0s - 3ms/step - loss: 1.2017\n",
      "Epoch 3/50\n",
      "8/8 - 0s - 13ms/step - loss: 1.1430\n",
      "Epoch 4/50\n",
      "8/8 - 0s - 9ms/step - loss: 1.0929\n",
      "Epoch 5/50\n",
      "8/8 - 0s - 4ms/step - loss: 1.0544\n",
      "Epoch 6/50\n",
      "8/8 - 0s - 3ms/step - loss: 1.0231\n",
      "Epoch 7/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.9996\n",
      "Epoch 8/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.9762\n",
      "Epoch 9/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.9638\n",
      "Epoch 10/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.9506\n",
      "Epoch 11/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.9424\n",
      "Epoch 12/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.9280\n",
      "Epoch 13/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.9191\n",
      "Epoch 14/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.9115\n",
      "Epoch 15/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8984\n",
      "Epoch 16/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8955\n",
      "Epoch 17/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8913\n",
      "Epoch 18/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8844\n",
      "Epoch 19/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8791\n",
      "Epoch 20/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8738\n",
      "Epoch 21/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8700\n",
      "Epoch 22/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8635\n",
      "Epoch 23/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8590\n",
      "Epoch 24/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8595\n",
      "Epoch 25/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8560\n",
      "Epoch 26/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8483\n",
      "Epoch 27/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8446\n",
      "Epoch 28/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8430\n",
      "Epoch 29/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8394\n",
      "Epoch 30/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8376\n",
      "Epoch 31/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8339\n",
      "Epoch 32/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8312\n",
      "Epoch 33/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8315\n",
      "Epoch 34/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8254\n",
      "Epoch 35/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8224\n",
      "Epoch 36/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8174\n",
      "Epoch 37/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8178\n",
      "Epoch 38/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8125\n",
      "Epoch 39/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8104\n",
      "Epoch 40/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8085\n",
      "Epoch 41/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8052\n",
      "Epoch 42/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8046\n",
      "Epoch 43/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8028\n",
      "Epoch 44/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8021\n",
      "Epoch 45/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8001\n",
      "Epoch 46/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7962\n",
      "Epoch 47/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7928\n",
      "Epoch 48/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7896\n",
      "Epoch 49/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7943\n",
      "Epoch 50/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7923\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n",
      "Testing with layers=[128, 64, 32], encoding_dim=10, batch_size=128, epochs=100, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "8/8 - 1s - 169ms/step - loss: 1.2598\n",
      "Epoch 2/100\n",
      "8/8 - 0s - 4ms/step - loss: 1.1595\n",
      "Epoch 3/100\n",
      "8/8 - 0s - 10ms/step - loss: 1.0902\n",
      "Epoch 4/100\n",
      "8/8 - 0s - 3ms/step - loss: 1.0353\n",
      "Epoch 5/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.9984\n",
      "Epoch 6/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.9686\n",
      "Epoch 7/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.9442\n",
      "Epoch 8/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.9248\n",
      "Epoch 9/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.9123\n",
      "Epoch 10/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8946\n",
      "Epoch 11/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8835\n",
      "Epoch 12/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8690\n",
      "Epoch 13/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8610\n",
      "Epoch 14/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8557\n",
      "Epoch 15/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8476\n",
      "Epoch 16/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8388\n",
      "Epoch 17/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8344\n",
      "Epoch 18/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8292\n",
      "Epoch 19/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8235\n",
      "Epoch 20/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8150\n",
      "Epoch 21/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8144\n",
      "Epoch 22/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8098\n",
      "Epoch 23/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8016\n",
      "Epoch 24/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8004\n",
      "Epoch 25/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7985\n",
      "Epoch 26/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7914\n",
      "Epoch 27/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7911\n",
      "Epoch 28/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7862\n",
      "Epoch 29/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7837\n",
      "Epoch 30/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7782\n",
      "Epoch 31/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7777\n",
      "Epoch 32/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7734\n",
      "Epoch 33/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7719\n",
      "Epoch 34/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7679\n",
      "Epoch 35/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7661\n",
      "Epoch 36/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7659\n",
      "Epoch 37/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7618\n",
      "Epoch 38/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7587\n",
      "Epoch 39/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7585\n",
      "Epoch 40/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7570\n",
      "Epoch 41/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7530\n",
      "Epoch 42/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7529\n",
      "Epoch 43/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7530\n",
      "Epoch 44/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7503\n",
      "Epoch 45/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7478\n",
      "Epoch 46/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7471\n",
      "Epoch 47/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7457\n",
      "Epoch 48/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7450\n",
      "Epoch 49/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7426\n",
      "Epoch 50/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7433\n",
      "Epoch 51/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7389\n",
      "Epoch 52/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7413\n",
      "Epoch 53/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7363\n",
      "Epoch 54/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7365\n",
      "Epoch 55/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7340\n",
      "Epoch 56/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7383\n",
      "Epoch 57/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7341\n",
      "Epoch 58/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7352\n",
      "Epoch 59/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7322\n",
      "Epoch 60/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7312\n",
      "Epoch 61/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7309\n",
      "Epoch 62/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7316\n",
      "Epoch 63/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7289\n",
      "Epoch 64/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7273\n",
      "Epoch 65/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7280\n",
      "Epoch 66/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7276\n",
      "Epoch 67/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7268\n",
      "Epoch 68/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7243\n",
      "Epoch 69/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7231\n",
      "Epoch 70/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7242\n",
      "Epoch 71/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7254\n",
      "Epoch 72/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7225\n",
      "Epoch 73/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7207\n",
      "Epoch 74/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7216\n",
      "Epoch 75/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7189\n",
      "Epoch 76/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7201\n",
      "Epoch 77/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7193\n",
      "Epoch 78/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7168\n",
      "Epoch 79/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7168\n",
      "Epoch 80/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7149\n",
      "Epoch 81/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7158\n",
      "Epoch 82/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7140\n",
      "Epoch 83/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7150\n",
      "Epoch 84/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7107\n",
      "Epoch 85/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7099\n",
      "Epoch 86/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7140\n",
      "Epoch 87/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7091\n",
      "Epoch 88/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7099\n",
      "Epoch 89/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7101\n",
      "Epoch 90/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.7088\n",
      "Epoch 91/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7072\n",
      "Epoch 92/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7053\n",
      "Epoch 93/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7043\n",
      "Epoch 94/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7071\n",
      "Epoch 95/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7092\n",
      "Epoch 96/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7042\n",
      "Epoch 97/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7076\n",
      "Epoch 98/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7047\n",
      "Epoch 99/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7030\n",
      "Epoch 100/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7067\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Testing with layers=[128, 64, 32], encoding_dim=10, batch_size=128, epochs=100, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "8/8 - 1s - 157ms/step - loss: 1.2338\n",
      "Epoch 2/100\n",
      "8/8 - 0s - 3ms/step - loss: 1.1550\n",
      "Epoch 3/100\n",
      "8/8 - 0s - 3ms/step - loss: 1.0964\n",
      "Epoch 4/100\n",
      "8/8 - 0s - 3ms/step - loss: 1.0552\n",
      "Epoch 5/100\n",
      "8/8 - 0s - 4ms/step - loss: 1.0206\n",
      "Epoch 6/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.9946\n",
      "Epoch 7/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.9757\n",
      "Epoch 8/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.9625\n",
      "Epoch 9/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.9458\n",
      "Epoch 10/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.9342\n",
      "Epoch 11/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.9251\n",
      "Epoch 12/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.9173\n",
      "Epoch 13/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.9062\n",
      "Epoch 14/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8984\n",
      "Epoch 15/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8919\n",
      "Epoch 16/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8844\n",
      "Epoch 17/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8835\n",
      "Epoch 18/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8741\n",
      "Epoch 19/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8727\n",
      "Epoch 20/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.8671\n",
      "Epoch 21/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8616\n",
      "Epoch 22/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8607\n",
      "Epoch 23/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8513\n",
      "Epoch 24/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8497\n",
      "Epoch 25/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8490\n",
      "Epoch 26/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8425\n",
      "Epoch 27/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.8408\n",
      "Epoch 28/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8411\n",
      "Epoch 29/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8302\n",
      "Epoch 30/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8315\n",
      "Epoch 31/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8251\n",
      "Epoch 32/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8243\n",
      "Epoch 33/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8219\n",
      "Epoch 34/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8168\n",
      "Epoch 35/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8170\n",
      "Epoch 36/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8107\n",
      "Epoch 37/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8125\n",
      "Epoch 38/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8108\n",
      "Epoch 39/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8078\n",
      "Epoch 40/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8056\n",
      "Epoch 41/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8026\n",
      "Epoch 42/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8029\n",
      "Epoch 43/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7984\n",
      "Epoch 44/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7996\n",
      "Epoch 45/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7966\n",
      "Epoch 46/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7931\n",
      "Epoch 47/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7923\n",
      "Epoch 48/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7879\n",
      "Epoch 49/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7900\n",
      "Epoch 50/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7892\n",
      "Epoch 51/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7859\n",
      "Epoch 52/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7822\n",
      "Epoch 53/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7801\n",
      "Epoch 54/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7788\n",
      "Epoch 55/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7725\n",
      "Epoch 56/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7749\n",
      "Epoch 57/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7738\n",
      "Epoch 58/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7741\n",
      "Epoch 59/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7674\n",
      "Epoch 60/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7735\n",
      "Epoch 61/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7691\n",
      "Epoch 62/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7692\n",
      "Epoch 63/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7673\n",
      "Epoch 64/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7688\n",
      "Epoch 65/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7655\n",
      "Epoch 66/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7636\n",
      "Epoch 67/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7634\n",
      "Epoch 68/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7616\n",
      "Epoch 69/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7625\n",
      "Epoch 70/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7610\n",
      "Epoch 71/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7609\n",
      "Epoch 72/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7575\n",
      "Epoch 73/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7546\n",
      "Epoch 74/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7577\n",
      "Epoch 75/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7539\n",
      "Epoch 76/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7565\n",
      "Epoch 77/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7550\n",
      "Epoch 78/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7553\n",
      "Epoch 79/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7521\n",
      "Epoch 80/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7520\n",
      "Epoch 81/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7524\n",
      "Epoch 82/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7507\n",
      "Epoch 83/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7482\n",
      "Epoch 84/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7479\n",
      "Epoch 85/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7481\n",
      "Epoch 86/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7461\n",
      "Epoch 87/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7511\n",
      "Epoch 88/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7488\n",
      "Epoch 89/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7477\n",
      "Epoch 90/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7479\n",
      "Epoch 91/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7465\n",
      "Epoch 92/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7456\n",
      "Epoch 93/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7447\n",
      "Epoch 94/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7467\n",
      "Epoch 95/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7433\n",
      "Epoch 96/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7449\n",
      "Epoch 97/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7448\n",
      "Epoch 98/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7453\n",
      "Epoch 99/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7413\n",
      "Epoch 100/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7364\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 16ms/step\n",
      "Testing with layers=[128, 64, 32], encoding_dim=12, batch_size=32, epochs=50, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "32/32 - 2s - 55ms/step - loss: 1.1731\n",
      "Epoch 2/50\n",
      "32/32 - 0s - 1ms/step - loss: 1.0168\n",
      "Epoch 3/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.9410\n",
      "Epoch 4/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.9055\n",
      "Epoch 5/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8801\n",
      "Epoch 6/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8606\n",
      "Epoch 7/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8413\n",
      "Epoch 8/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8265\n",
      "Epoch 9/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8136\n",
      "Epoch 10/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8031\n",
      "Epoch 11/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7968\n",
      "Epoch 12/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7873\n",
      "Epoch 13/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7857\n",
      "Epoch 14/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7803\n",
      "Epoch 15/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7705\n",
      "Epoch 16/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7673\n",
      "Epoch 17/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7576\n",
      "Epoch 18/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7538\n",
      "Epoch 19/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7563\n",
      "Epoch 20/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7531\n",
      "Epoch 21/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7455\n",
      "Epoch 22/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7438\n",
      "Epoch 23/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7401\n",
      "Epoch 24/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7390\n",
      "Epoch 25/50\n",
      "32/32 - 0s - 10ms/step - loss: 0.7345\n",
      "Epoch 26/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7315\n",
      "Epoch 27/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7307\n",
      "Epoch 28/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7245\n",
      "Epoch 29/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7204\n",
      "Epoch 30/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7177\n",
      "Epoch 31/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7182\n",
      "Epoch 32/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7162\n",
      "Epoch 33/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7098\n",
      "Epoch 34/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7096\n",
      "Epoch 35/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7107\n",
      "Epoch 36/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7115\n",
      "Epoch 37/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7079\n",
      "Epoch 38/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7046\n",
      "Epoch 39/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7034\n",
      "Epoch 40/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7037\n",
      "Epoch 41/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7025\n",
      "Epoch 42/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.6996\n",
      "Epoch 43/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.6978\n",
      "Epoch 44/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.6974\n",
      "Epoch 45/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.6996\n",
      "Epoch 46/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.6990\n",
      "Epoch 47/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.6950\n",
      "Epoch 48/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.6961\n",
      "Epoch 49/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.6901\n",
      "Epoch 50/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.6929\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Testing with layers=[128, 64, 32], encoding_dim=12, batch_size=32, epochs=50, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "32/32 - 1s - 44ms/step - loss: 1.1955\n",
      "Epoch 2/50\n",
      "32/32 - 0s - 1ms/step - loss: 1.0378\n",
      "Epoch 3/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.9657\n",
      "Epoch 4/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.9325\n",
      "Epoch 5/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.9127\n",
      "Epoch 6/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8935\n",
      "Epoch 7/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8766\n",
      "Epoch 8/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8650\n",
      "Epoch 9/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8507\n",
      "Epoch 10/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8417\n",
      "Epoch 11/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8390\n",
      "Epoch 12/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8248\n",
      "Epoch 13/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8210\n",
      "Epoch 14/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8130\n",
      "Epoch 15/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8132\n",
      "Epoch 16/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8052\n",
      "Epoch 17/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8002\n",
      "Epoch 18/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7987\n",
      "Epoch 19/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7928\n",
      "Epoch 20/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7851\n",
      "Epoch 21/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7854\n",
      "Epoch 22/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7801\n",
      "Epoch 23/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7812\n",
      "Epoch 24/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7760\n",
      "Epoch 25/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7742\n",
      "Epoch 26/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7706\n",
      "Epoch 27/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7680\n",
      "Epoch 28/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7657\n",
      "Epoch 29/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7618\n",
      "Epoch 30/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7626\n",
      "Epoch 31/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7642\n",
      "Epoch 32/50\n",
      "32/32 - 0s - 4ms/step - loss: 0.7576\n",
      "Epoch 33/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7536\n",
      "Epoch 34/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7534\n",
      "Epoch 35/50\n",
      "32/32 - 0s - 4ms/step - loss: 0.7517\n",
      "Epoch 36/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7522\n",
      "Epoch 37/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7442\n",
      "Epoch 38/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7486\n",
      "Epoch 39/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7462\n",
      "Epoch 40/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7476\n",
      "Epoch 41/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7478\n",
      "Epoch 42/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7420\n",
      "Epoch 43/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7420\n",
      "Epoch 44/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7400\n",
      "Epoch 45/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7403\n",
      "Epoch 46/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7395\n",
      "Epoch 47/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7397\n",
      "Epoch 48/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7391\n",
      "Epoch 49/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7368\n",
      "Epoch 50/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7346\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Testing with layers=[128, 64, 32], encoding_dim=12, batch_size=32, epochs=100, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "32/32 - 1s - 46ms/step - loss: 1.1439\n",
      "Epoch 2/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.9887\n",
      "Epoch 3/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.9279\n",
      "Epoch 4/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8918\n",
      "Epoch 5/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8681\n",
      "Epoch 6/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8473\n",
      "Epoch 7/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.8319\n",
      "Epoch 8/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8169\n",
      "Epoch 9/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8043\n",
      "Epoch 10/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7903\n",
      "Epoch 11/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7851\n",
      "Epoch 12/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7756\n",
      "Epoch 13/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7659\n",
      "Epoch 14/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7573\n",
      "Epoch 15/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7536\n",
      "Epoch 16/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7471\n",
      "Epoch 17/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7446\n",
      "Epoch 18/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7421\n",
      "Epoch 19/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7387\n",
      "Epoch 20/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7338\n",
      "Epoch 21/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7307\n",
      "Epoch 22/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7258\n",
      "Epoch 23/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7263\n",
      "Epoch 24/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7254\n",
      "Epoch 25/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7231\n",
      "Epoch 26/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7203\n",
      "Epoch 27/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7148\n",
      "Epoch 28/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7178\n",
      "Epoch 29/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7128\n",
      "Epoch 30/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7101\n",
      "Epoch 31/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7141\n",
      "Epoch 32/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7123\n",
      "Epoch 33/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7132\n",
      "Epoch 34/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7062\n",
      "Epoch 35/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7057\n",
      "Epoch 36/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7022\n",
      "Epoch 37/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7002\n",
      "Epoch 38/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6990\n",
      "Epoch 39/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7024\n",
      "Epoch 40/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6994\n",
      "Epoch 41/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7024\n",
      "Epoch 42/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6972\n",
      "Epoch 43/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6950\n",
      "Epoch 44/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6956\n",
      "Epoch 45/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6950\n",
      "Epoch 46/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6934\n",
      "Epoch 47/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6946\n",
      "Epoch 48/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6939\n",
      "Epoch 49/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6941\n",
      "Epoch 50/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.6912\n",
      "Epoch 51/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6888\n",
      "Epoch 52/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.6896\n",
      "Epoch 53/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6864\n",
      "Epoch 54/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6854\n",
      "Epoch 55/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6848\n",
      "Epoch 56/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.6852\n",
      "Epoch 57/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6871\n",
      "Epoch 58/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6872\n",
      "Epoch 59/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6811\n",
      "Epoch 60/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6817\n",
      "Epoch 61/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.6850\n",
      "Epoch 62/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6834\n",
      "Epoch 63/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6803\n",
      "Epoch 64/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.6816\n",
      "Epoch 65/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.6810\n",
      "Epoch 66/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6787\n",
      "Epoch 67/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6805\n",
      "Epoch 68/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6780\n",
      "Epoch 69/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6752\n",
      "Epoch 70/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6786\n",
      "Epoch 71/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.6742\n",
      "Epoch 72/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6732\n",
      "Epoch 73/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6749\n",
      "Epoch 74/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6763\n",
      "Epoch 75/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6740\n",
      "Epoch 76/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6704\n",
      "Epoch 77/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.6712\n",
      "Epoch 78/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6739\n",
      "Epoch 79/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6710\n",
      "Epoch 80/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6754\n",
      "Epoch 81/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6723\n",
      "Epoch 82/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6682\n",
      "Epoch 83/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6692\n",
      "Epoch 84/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6691\n",
      "Epoch 85/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6702\n",
      "Epoch 86/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6725\n",
      "Epoch 87/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6668\n",
      "Epoch 88/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6647\n",
      "Epoch 89/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6672\n",
      "Epoch 90/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6657\n",
      "Epoch 91/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6676\n",
      "Epoch 92/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6659\n",
      "Epoch 93/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6657\n",
      "Epoch 94/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6627\n",
      "Epoch 95/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6622\n",
      "Epoch 96/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6631\n",
      "Epoch 97/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6626\n",
      "Epoch 98/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6633\n",
      "Epoch 99/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6616\n",
      "Epoch 100/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6587\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Testing with layers=[128, 64, 32], encoding_dim=12, batch_size=32, epochs=100, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "32/32 - 1s - 42ms/step - loss: 1.1980\n",
      "Epoch 2/100\n",
      "32/32 - 0s - 2ms/step - loss: 1.0515\n",
      "Epoch 3/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.9807\n",
      "Epoch 4/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.9443\n",
      "Epoch 5/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.9264\n",
      "Epoch 6/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.9096\n",
      "Epoch 7/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8943\n",
      "Epoch 8/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8809\n",
      "Epoch 9/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8722\n",
      "Epoch 10/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8612\n",
      "Epoch 11/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8524\n",
      "Epoch 12/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8466\n",
      "Epoch 13/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8362\n",
      "Epoch 14/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8347\n",
      "Epoch 15/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8272\n",
      "Epoch 16/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8231\n",
      "Epoch 17/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8211\n",
      "Epoch 18/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8131\n",
      "Epoch 19/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8081\n",
      "Epoch 20/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8011\n",
      "Epoch 21/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7967\n",
      "Epoch 22/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7910\n",
      "Epoch 23/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7937\n",
      "Epoch 24/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7895\n",
      "Epoch 25/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7818\n",
      "Epoch 26/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7827\n",
      "Epoch 27/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7776\n",
      "Epoch 28/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7733\n",
      "Epoch 29/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7741\n",
      "Epoch 30/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7730\n",
      "Epoch 31/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7693\n",
      "Epoch 32/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7620\n",
      "Epoch 33/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7641\n",
      "Epoch 34/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7599\n",
      "Epoch 35/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7616\n",
      "Epoch 36/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7569\n",
      "Epoch 37/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7588\n",
      "Epoch 38/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7577\n",
      "Epoch 39/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7557\n",
      "Epoch 40/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7524\n",
      "Epoch 41/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7507\n",
      "Epoch 42/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7553\n",
      "Epoch 43/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7443\n",
      "Epoch 44/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7464\n",
      "Epoch 45/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7470\n",
      "Epoch 46/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7471\n",
      "Epoch 47/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7412\n",
      "Epoch 48/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7425\n",
      "Epoch 49/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7431\n",
      "Epoch 50/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7451\n",
      "Epoch 51/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7369\n",
      "Epoch 52/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7315\n",
      "Epoch 53/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7350\n",
      "Epoch 54/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7317\n",
      "Epoch 55/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7334\n",
      "Epoch 56/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7334\n",
      "Epoch 57/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7358\n",
      "Epoch 58/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7299\n",
      "Epoch 59/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7306\n",
      "Epoch 60/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7264\n",
      "Epoch 61/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7312\n",
      "Epoch 62/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7312\n",
      "Epoch 63/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7293\n",
      "Epoch 64/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7283\n",
      "Epoch 65/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7276\n",
      "Epoch 66/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7247\n",
      "Epoch 67/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7270\n",
      "Epoch 68/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7201\n",
      "Epoch 69/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7250\n",
      "Epoch 70/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7266\n",
      "Epoch 71/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7271\n",
      "Epoch 72/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7238\n",
      "Epoch 73/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7211\n",
      "Epoch 74/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7190\n",
      "Epoch 75/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7210\n",
      "Epoch 76/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7179\n",
      "Epoch 77/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7202\n",
      "Epoch 78/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7244\n",
      "Epoch 79/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7197\n",
      "Epoch 80/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7188\n",
      "Epoch 81/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7183\n",
      "Epoch 82/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7183\n",
      "Epoch 83/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7207\n",
      "Epoch 84/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7191\n",
      "Epoch 85/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7186\n",
      "Epoch 86/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7118\n",
      "Epoch 87/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7141\n",
      "Epoch 88/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7155\n",
      "Epoch 89/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7168\n",
      "Epoch 90/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7144\n",
      "Epoch 91/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7134\n",
      "Epoch 92/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7144\n",
      "Epoch 93/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7105\n",
      "Epoch 94/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7141\n",
      "Epoch 95/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7119\n",
      "Epoch 96/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7099\n",
      "Epoch 97/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7127\n",
      "Epoch 98/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7083\n",
      "Epoch 99/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7073\n",
      "Epoch 100/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7089\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Testing with layers=[128, 64, 32], encoding_dim=12, batch_size=64, epochs=50, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "16/16 - 2s - 114ms/step - loss: 1.1782\n",
      "Epoch 2/50\n",
      "16/16 - 0s - 2ms/step - loss: 1.0471\n",
      "Epoch 3/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.9791\n",
      "Epoch 4/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.9344\n",
      "Epoch 5/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.9009\n",
      "Epoch 6/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8836\n",
      "Epoch 7/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8653\n",
      "Epoch 8/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8457\n",
      "Epoch 9/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8381\n",
      "Epoch 10/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8266\n",
      "Epoch 11/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8182\n",
      "Epoch 12/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8057\n",
      "Epoch 13/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7978\n",
      "Epoch 14/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7893\n",
      "Epoch 15/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7827\n",
      "Epoch 16/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7748\n",
      "Epoch 17/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7742\n",
      "Epoch 18/50\n",
      "16/16 - 0s - 8ms/step - loss: 0.7660\n",
      "Epoch 19/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7605\n",
      "Epoch 20/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7574\n",
      "Epoch 21/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7494\n",
      "Epoch 22/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7500\n",
      "Epoch 23/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7462\n",
      "Epoch 24/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7439\n",
      "Epoch 25/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7396\n",
      "Epoch 26/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7339\n",
      "Epoch 27/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7331\n",
      "Epoch 28/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7299\n",
      "Epoch 29/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7298\n",
      "Epoch 30/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7237\n",
      "Epoch 31/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7218\n",
      "Epoch 32/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7227\n",
      "Epoch 33/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7165\n",
      "Epoch 34/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7228\n",
      "Epoch 35/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7149\n",
      "Epoch 36/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7152\n",
      "Epoch 37/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7151\n",
      "Epoch 38/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7101\n",
      "Epoch 39/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7086\n",
      "Epoch 40/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7052\n",
      "Epoch 41/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7088\n",
      "Epoch 42/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7070\n",
      "Epoch 43/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7070\n",
      "Epoch 44/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7023\n",
      "Epoch 45/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7019\n",
      "Epoch 46/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7028\n",
      "Epoch 47/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.6963\n",
      "Epoch 48/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7009\n",
      "Epoch 49/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.6996\n",
      "Epoch 50/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.6976\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Testing with layers=[128, 64, 32], encoding_dim=12, batch_size=64, epochs=50, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "16/16 - 2s - 101ms/step - loss: 1.2307\n",
      "Epoch 2/50\n",
      "16/16 - 0s - 3ms/step - loss: 1.1135\n",
      "Epoch 3/50\n",
      "16/16 - 0s - 4ms/step - loss: 1.0403\n",
      "Epoch 4/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.9922\n",
      "Epoch 5/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.9602\n",
      "Epoch 6/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.9385\n",
      "Epoch 7/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.9251\n",
      "Epoch 8/50\n",
      "16/16 - 0s - 5ms/step - loss: 0.9098\n",
      "Epoch 9/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.8981\n",
      "Epoch 10/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.8891\n",
      "Epoch 11/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8784\n",
      "Epoch 12/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8673\n",
      "Epoch 13/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8611\n",
      "Epoch 14/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8549\n",
      "Epoch 15/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8491\n",
      "Epoch 16/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8417\n",
      "Epoch 17/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8351\n",
      "Epoch 18/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8338\n",
      "Epoch 19/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8292\n",
      "Epoch 20/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8215\n",
      "Epoch 21/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8199\n",
      "Epoch 22/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8167\n",
      "Epoch 23/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8135\n",
      "Epoch 24/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8093\n",
      "Epoch 25/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8072\n",
      "Epoch 26/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8046\n",
      "Epoch 27/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7999\n",
      "Epoch 28/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7949\n",
      "Epoch 29/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7911\n",
      "Epoch 30/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7913\n",
      "Epoch 31/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7867\n",
      "Epoch 32/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7843\n",
      "Epoch 33/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7807\n",
      "Epoch 34/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7799\n",
      "Epoch 35/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7798\n",
      "Epoch 36/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7704\n",
      "Epoch 37/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7700\n",
      "Epoch 38/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7666\n",
      "Epoch 39/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7692\n",
      "Epoch 40/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7642\n",
      "Epoch 41/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7621\n",
      "Epoch 42/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7589\n",
      "Epoch 43/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7574\n",
      "Epoch 44/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7517\n",
      "Epoch 45/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7554\n",
      "Epoch 46/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7537\n",
      "Epoch 47/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7512\n",
      "Epoch 48/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7538\n",
      "Epoch 49/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7476\n",
      "Epoch 50/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7504\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Testing with layers=[128, 64, 32], encoding_dim=12, batch_size=64, epochs=100, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "16/16 - 2s - 104ms/step - loss: 1.2030\n",
      "Epoch 2/100\n",
      "16/16 - 0s - 2ms/step - loss: 1.0746\n",
      "Epoch 3/100\n",
      "16/16 - 0s - 3ms/step - loss: 1.0006\n",
      "Epoch 4/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.9516\n",
      "Epoch 5/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.9196\n",
      "Epoch 6/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8922\n",
      "Epoch 7/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.8744\n",
      "Epoch 8/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.8585\n",
      "Epoch 9/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8424\n",
      "Epoch 10/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8330\n",
      "Epoch 11/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8254\n",
      "Epoch 12/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8131\n",
      "Epoch 13/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8082\n",
      "Epoch 14/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8009\n",
      "Epoch 15/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7910\n",
      "Epoch 16/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7875\n",
      "Epoch 17/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7816\n",
      "Epoch 18/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7750\n",
      "Epoch 19/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7695\n",
      "Epoch 20/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7662\n",
      "Epoch 21/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7622\n",
      "Epoch 22/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7553\n",
      "Epoch 23/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7518\n",
      "Epoch 24/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7492\n",
      "Epoch 25/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7422\n",
      "Epoch 26/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7404\n",
      "Epoch 27/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7366\n",
      "Epoch 28/100\n",
      "16/16 - 0s - 10ms/step - loss: 0.7352\n",
      "Epoch 29/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7296\n",
      "Epoch 30/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7294\n",
      "Epoch 31/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7283\n",
      "Epoch 32/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7264\n",
      "Epoch 33/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7206\n",
      "Epoch 34/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7208\n",
      "Epoch 35/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7200\n",
      "Epoch 36/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7182\n",
      "Epoch 37/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7168\n",
      "Epoch 38/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7102\n",
      "Epoch 39/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7105\n",
      "Epoch 40/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7102\n",
      "Epoch 41/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7067\n",
      "Epoch 42/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7084\n",
      "Epoch 43/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7069\n",
      "Epoch 44/100\n",
      "16/16 - 0s - 11ms/step - loss: 0.7038\n",
      "Epoch 45/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7040\n",
      "Epoch 46/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6989\n",
      "Epoch 47/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7041\n",
      "Epoch 48/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7026\n",
      "Epoch 49/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6936\n",
      "Epoch 50/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6964\n",
      "Epoch 51/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6939\n",
      "Epoch 52/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6956\n",
      "Epoch 53/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6936\n",
      "Epoch 54/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.6934\n",
      "Epoch 55/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6921\n",
      "Epoch 56/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6925\n",
      "Epoch 57/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6917\n",
      "Epoch 58/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6889\n",
      "Epoch 59/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6900\n",
      "Epoch 60/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6860\n",
      "Epoch 61/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6845\n",
      "Epoch 62/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6844\n",
      "Epoch 63/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6833\n",
      "Epoch 64/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6849\n",
      "Epoch 65/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6834\n",
      "Epoch 66/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6850\n",
      "Epoch 67/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6801\n",
      "Epoch 68/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6797\n",
      "Epoch 69/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6788\n",
      "Epoch 70/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6805\n",
      "Epoch 71/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6782\n",
      "Epoch 72/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6766\n",
      "Epoch 73/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6813\n",
      "Epoch 74/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6762\n",
      "Epoch 75/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6762\n",
      "Epoch 76/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6724\n",
      "Epoch 77/100\n",
      "16/16 - 0s - 6ms/step - loss: 0.6734\n",
      "Epoch 78/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6758\n",
      "Epoch 79/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6777\n",
      "Epoch 80/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6756\n",
      "Epoch 81/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6748\n",
      "Epoch 82/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6729\n",
      "Epoch 83/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6736\n",
      "Epoch 84/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6747\n",
      "Epoch 85/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6699\n",
      "Epoch 86/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6692\n",
      "Epoch 87/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6659\n",
      "Epoch 88/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6680\n",
      "Epoch 89/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6706\n",
      "Epoch 90/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.6699\n",
      "Epoch 91/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6640\n",
      "Epoch 92/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6674\n",
      "Epoch 93/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6657\n",
      "Epoch 94/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6701\n",
      "Epoch 95/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6669\n",
      "Epoch 96/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6662\n",
      "Epoch 97/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6674\n",
      "Epoch 98/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6642\n",
      "Epoch 99/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6631\n",
      "Epoch 100/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6646\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "Testing with layers=[128, 64, 32], encoding_dim=12, batch_size=64, epochs=100, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "16/16 - 2s - 117ms/step - loss: 1.2449\n",
      "Epoch 2/100\n",
      "16/16 - 0s - 4ms/step - loss: 1.1220\n",
      "Epoch 3/100\n",
      "16/16 - 0s - 4ms/step - loss: 1.0482\n",
      "Epoch 4/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.9967\n",
      "Epoch 5/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.9651\n",
      "Epoch 6/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.9360\n",
      "Epoch 7/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.9218\n",
      "Epoch 8/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.9040\n",
      "Epoch 9/100\n",
      "16/16 - 0s - 9ms/step - loss: 0.8924\n",
      "Epoch 10/100\n",
      "16/16 - 0s - 8ms/step - loss: 0.8771\n",
      "Epoch 11/100\n",
      "16/16 - 0s - 6ms/step - loss: 0.8751\n",
      "Epoch 12/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.8603\n",
      "Epoch 13/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.8586\n",
      "Epoch 14/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.8490\n",
      "Epoch 15/100\n",
      "16/16 - 0s - 6ms/step - loss: 0.8446\n",
      "Epoch 16/100\n",
      "16/16 - 0s - 6ms/step - loss: 0.8364\n",
      "Epoch 17/100\n",
      "16/16 - 0s - 6ms/step - loss: 0.8364\n",
      "Epoch 18/100\n",
      "16/16 - 0s - 6ms/step - loss: 0.8255\n",
      "Epoch 19/100\n",
      "16/16 - 0s - 6ms/step - loss: 0.8216\n",
      "Epoch 20/100\n",
      "16/16 - 0s - 6ms/step - loss: 0.8207\n",
      "Epoch 21/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.8146\n",
      "Epoch 22/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.8144\n",
      "Epoch 23/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.8064\n",
      "Epoch 24/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.8059\n",
      "Epoch 25/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.8008\n",
      "Epoch 26/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7980\n",
      "Epoch 27/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7945\n",
      "Epoch 28/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7923\n",
      "Epoch 29/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7891\n",
      "Epoch 30/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7863\n",
      "Epoch 31/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7861\n",
      "Epoch 32/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7850\n",
      "Epoch 33/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7837\n",
      "Epoch 34/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7767\n",
      "Epoch 35/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7763\n",
      "Epoch 36/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7720\n",
      "Epoch 37/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7727\n",
      "Epoch 38/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7691\n",
      "Epoch 39/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7684\n",
      "Epoch 40/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7711\n",
      "Epoch 41/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7663\n",
      "Epoch 42/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7662\n",
      "Epoch 43/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7639\n",
      "Epoch 44/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7634\n",
      "Epoch 45/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7628\n",
      "Epoch 46/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7607\n",
      "Epoch 47/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7569\n",
      "Epoch 48/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7533\n",
      "Epoch 49/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7537\n",
      "Epoch 50/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7533\n",
      "Epoch 51/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7537\n",
      "Epoch 52/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7507\n",
      "Epoch 53/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7513\n",
      "Epoch 54/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7513\n",
      "Epoch 55/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7475\n",
      "Epoch 56/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7473\n",
      "Epoch 57/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7431\n",
      "Epoch 58/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7462\n",
      "Epoch 59/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7427\n",
      "Epoch 60/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7402\n",
      "Epoch 61/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7429\n",
      "Epoch 62/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7423\n",
      "Epoch 63/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7414\n",
      "Epoch 64/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7371\n",
      "Epoch 65/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7340\n",
      "Epoch 66/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7378\n",
      "Epoch 67/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7431\n",
      "Epoch 68/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7367\n",
      "Epoch 69/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7334\n",
      "Epoch 70/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7346\n",
      "Epoch 71/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7317\n",
      "Epoch 72/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7349\n",
      "Epoch 73/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7314\n",
      "Epoch 74/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7336\n",
      "Epoch 75/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7309\n",
      "Epoch 76/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7272\n",
      "Epoch 77/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7281\n",
      "Epoch 78/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7238\n",
      "Epoch 79/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7260\n",
      "Epoch 80/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7275\n",
      "Epoch 81/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7287\n",
      "Epoch 82/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7277\n",
      "Epoch 83/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7258\n",
      "Epoch 84/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7244\n",
      "Epoch 85/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7263\n",
      "Epoch 86/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7262\n",
      "Epoch 87/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7258\n",
      "Epoch 88/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7218\n",
      "Epoch 89/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7217\n",
      "Epoch 90/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7170\n",
      "Epoch 91/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7152\n",
      "Epoch 92/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7231\n",
      "Epoch 93/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7202\n",
      "Epoch 94/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7170\n",
      "Epoch 95/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7203\n",
      "Epoch 96/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7180\n",
      "Epoch 97/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7157\n",
      "Epoch 98/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7169\n",
      "Epoch 99/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7163\n",
      "Epoch 100/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7117\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Testing with layers=[128, 64, 32], encoding_dim=12, batch_size=128, epochs=50, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "8/8 - 2s - 279ms/step - loss: 1.2823\n",
      "Epoch 2/50\n",
      "8/8 - 0s - 6ms/step - loss: 1.1747\n",
      "Epoch 3/50\n",
      "8/8 - 0s - 6ms/step - loss: 1.0951\n",
      "Epoch 4/50\n",
      "8/8 - 0s - 5ms/step - loss: 1.0401\n",
      "Epoch 5/50\n",
      "8/8 - 0s - 3ms/step - loss: 1.0009\n",
      "Epoch 6/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.9714\n",
      "Epoch 7/50\n",
      "8/8 - 0s - 12ms/step - loss: 0.9390\n",
      "Epoch 8/50\n",
      "8/8 - 0s - 9ms/step - loss: 0.9206\n",
      "Epoch 9/50\n",
      "8/8 - 0s - 11ms/step - loss: 0.8999\n",
      "Epoch 10/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.8860\n",
      "Epoch 11/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8734\n",
      "Epoch 12/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8654\n",
      "Epoch 13/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8541\n",
      "Epoch 14/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8432\n",
      "Epoch 15/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8373\n",
      "Epoch 16/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.8280\n",
      "Epoch 17/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8231\n",
      "Epoch 18/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.8149\n",
      "Epoch 19/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.8137\n",
      "Epoch 20/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8058\n",
      "Epoch 21/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8018\n",
      "Epoch 22/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.7966\n",
      "Epoch 23/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7941\n",
      "Epoch 24/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.7875\n",
      "Epoch 25/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.7872\n",
      "Epoch 26/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7787\n",
      "Epoch 27/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.7781\n",
      "Epoch 28/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.7753\n",
      "Epoch 29/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.7713\n",
      "Epoch 30/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.7655\n",
      "Epoch 31/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.7622\n",
      "Epoch 32/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.7656\n",
      "Epoch 33/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.7581\n",
      "Epoch 34/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7577\n",
      "Epoch 35/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7506\n",
      "Epoch 36/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.7529\n",
      "Epoch 37/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.7495\n",
      "Epoch 38/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7455\n",
      "Epoch 39/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7456\n",
      "Epoch 40/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7448\n",
      "Epoch 41/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7421\n",
      "Epoch 42/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7393\n",
      "Epoch 43/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7355\n",
      "Epoch 44/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7383\n",
      "Epoch 45/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7326\n",
      "Epoch 46/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7313\n",
      "Epoch 47/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7303\n",
      "Epoch 48/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7309\n",
      "Epoch 49/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.7263\n",
      "Epoch 50/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7254\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "Testing with layers=[128, 64, 32], encoding_dim=12, batch_size=128, epochs=50, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "8/8 - 2s - 188ms/step - loss: 1.2727\n",
      "Epoch 2/50\n",
      "8/8 - 0s - 6ms/step - loss: 1.1870\n",
      "Epoch 3/50\n",
      "8/8 - 0s - 4ms/step - loss: 1.1188\n",
      "Epoch 4/50\n",
      "8/8 - 0s - 13ms/step - loss: 1.0664\n",
      "Epoch 5/50\n",
      "8/8 - 0s - 8ms/step - loss: 1.0293\n",
      "Epoch 6/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.9973\n",
      "Epoch 7/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.9764\n",
      "Epoch 8/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.9565\n",
      "Epoch 9/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.9394\n",
      "Epoch 10/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.9262\n",
      "Epoch 11/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.9157\n",
      "Epoch 12/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.9035\n",
      "Epoch 13/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8968\n",
      "Epoch 14/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.8867\n",
      "Epoch 15/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8805\n",
      "Epoch 16/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8725\n",
      "Epoch 17/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8651\n",
      "Epoch 18/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.8625\n",
      "Epoch 19/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8535\n",
      "Epoch 20/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8479\n",
      "Epoch 21/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.8446\n",
      "Epoch 22/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8368\n",
      "Epoch 23/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8352\n",
      "Epoch 24/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8322\n",
      "Epoch 25/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8273\n",
      "Epoch 26/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8240\n",
      "Epoch 27/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8198\n",
      "Epoch 28/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8135\n",
      "Epoch 29/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8095\n",
      "Epoch 30/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8119\n",
      "Epoch 31/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8099\n",
      "Epoch 32/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8078\n",
      "Epoch 33/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7977\n",
      "Epoch 34/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7994\n",
      "Epoch 35/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7997\n",
      "Epoch 36/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7947\n",
      "Epoch 37/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7936\n",
      "Epoch 38/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7939\n",
      "Epoch 39/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7880\n",
      "Epoch 40/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7877\n",
      "Epoch 41/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7846\n",
      "Epoch 42/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7845\n",
      "Epoch 43/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7794\n",
      "Epoch 44/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7799\n",
      "Epoch 45/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7790\n",
      "Epoch 46/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7775\n",
      "Epoch 47/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7771\n",
      "Epoch 48/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7756\n",
      "Epoch 49/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.7733\n",
      "Epoch 50/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7688\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Testing with layers=[128, 64, 32], encoding_dim=12, batch_size=128, epochs=100, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "8/8 - 2s - 210ms/step - loss: 1.2406\n",
      "Epoch 2/100\n",
      "8/8 - 0s - 4ms/step - loss: 1.1436\n",
      "Epoch 3/100\n",
      "8/8 - 0s - 3ms/step - loss: 1.0774\n",
      "Epoch 4/100\n",
      "8/8 - 0s - 5ms/step - loss: 1.0292\n",
      "Epoch 5/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.9929\n",
      "Epoch 6/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.9640\n",
      "Epoch 7/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.9399\n",
      "Epoch 8/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.9209\n",
      "Epoch 9/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.9057\n",
      "Epoch 10/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.8905\n",
      "Epoch 11/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.8816\n",
      "Epoch 12/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.8669\n",
      "Epoch 13/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.8595\n",
      "Epoch 14/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8501\n",
      "Epoch 15/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.8416\n",
      "Epoch 16/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.8364\n",
      "Epoch 17/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.8256\n",
      "Epoch 18/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.8224\n",
      "Epoch 19/100\n",
      "8/8 - 0s - 12ms/step - loss: 0.8179\n",
      "Epoch 20/100\n",
      "8/8 - 0s - 14ms/step - loss: 0.8114\n",
      "Epoch 21/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.8056\n",
      "Epoch 22/100\n",
      "8/8 - 0s - 9ms/step - loss: 0.8014\n",
      "Epoch 23/100\n",
      "8/8 - 0s - 9ms/step - loss: 0.7941\n",
      "Epoch 24/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.7911\n",
      "Epoch 25/100\n",
      "8/8 - 0s - 9ms/step - loss: 0.7837\n",
      "Epoch 26/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7815\n",
      "Epoch 27/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.7763\n",
      "Epoch 28/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7720\n",
      "Epoch 29/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.7721\n",
      "Epoch 30/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7633\n",
      "Epoch 31/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7607\n",
      "Epoch 32/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7587\n",
      "Epoch 33/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7525\n",
      "Epoch 34/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7554\n",
      "Epoch 35/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7526\n",
      "Epoch 36/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7493\n",
      "Epoch 37/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7459\n",
      "Epoch 38/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7435\n",
      "Epoch 39/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7418\n",
      "Epoch 40/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.7412\n",
      "Epoch 41/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.7377\n",
      "Epoch 42/100\n",
      "8/8 - 0s - 15ms/step - loss: 0.7349\n",
      "Epoch 43/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.7319\n",
      "Epoch 44/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7301\n",
      "Epoch 45/100\n",
      "8/8 - 0s - 16ms/step - loss: 0.7276\n",
      "Epoch 46/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7292\n",
      "Epoch 47/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7236\n",
      "Epoch 48/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7250\n",
      "Epoch 49/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7217\n",
      "Epoch 50/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7209\n",
      "Epoch 51/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7167\n",
      "Epoch 52/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7169\n",
      "Epoch 53/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7169\n",
      "Epoch 54/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7134\n",
      "Epoch 55/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7159\n",
      "Epoch 56/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7101\n",
      "Epoch 57/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7105\n",
      "Epoch 58/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7100\n",
      "Epoch 59/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7115\n",
      "Epoch 60/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7064\n",
      "Epoch 61/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7074\n",
      "Epoch 62/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7054\n",
      "Epoch 63/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7047\n",
      "Epoch 64/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7029\n",
      "Epoch 65/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7035\n",
      "Epoch 66/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7037\n",
      "Epoch 67/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7011\n",
      "Epoch 68/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7012\n",
      "Epoch 69/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7021\n",
      "Epoch 70/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7012\n",
      "Epoch 71/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6992\n",
      "Epoch 72/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6974\n",
      "Epoch 73/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6980\n",
      "Epoch 74/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6941\n",
      "Epoch 75/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6935\n",
      "Epoch 76/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6962\n",
      "Epoch 77/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6926\n",
      "Epoch 78/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6959\n",
      "Epoch 79/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.6959\n",
      "Epoch 80/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.6890\n",
      "Epoch 81/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.6908\n",
      "Epoch 82/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6902\n",
      "Epoch 83/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.6890\n",
      "Epoch 84/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.6864\n",
      "Epoch 85/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.6895\n",
      "Epoch 86/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.6874\n",
      "Epoch 87/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6849\n",
      "Epoch 88/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.6851\n",
      "Epoch 89/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.6864\n",
      "Epoch 90/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6835\n",
      "Epoch 91/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6849\n",
      "Epoch 92/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.6841\n",
      "Epoch 93/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6837\n",
      "Epoch 94/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.6821\n",
      "Epoch 95/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.6847\n",
      "Epoch 96/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.6803\n",
      "Epoch 97/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6796\n",
      "Epoch 98/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.6817\n",
      "Epoch 99/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6806\n",
      "Epoch 100/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6807\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "Testing with layers=[128, 64, 32], encoding_dim=12, batch_size=128, epochs=100, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "8/8 - 2s - 197ms/step - loss: 1.2431\n",
      "Epoch 2/100\n",
      "8/8 - 0s - 5ms/step - loss: 1.1675\n",
      "Epoch 3/100\n",
      "8/8 - 0s - 5ms/step - loss: 1.1061\n",
      "Epoch 4/100\n",
      "8/8 - 0s - 5ms/step - loss: 1.0598\n",
      "Epoch 5/100\n",
      "8/8 - 0s - 5ms/step - loss: 1.0253\n",
      "Epoch 6/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.9979\n",
      "Epoch 7/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.9794\n",
      "Epoch 8/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.9600\n",
      "Epoch 9/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.9416\n",
      "Epoch 10/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.9326\n",
      "Epoch 11/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.9280\n",
      "Epoch 12/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.9172\n",
      "Epoch 13/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.9055\n",
      "Epoch 14/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8978\n",
      "Epoch 15/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8877\n",
      "Epoch 16/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8792\n",
      "Epoch 17/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8746\n",
      "Epoch 18/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8705\n",
      "Epoch 19/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.8607\n",
      "Epoch 20/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8550\n",
      "Epoch 21/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.8514\n",
      "Epoch 22/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8480\n",
      "Epoch 23/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8484\n",
      "Epoch 24/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.8411\n",
      "Epoch 25/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8373\n",
      "Epoch 26/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.8342\n",
      "Epoch 27/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8275\n",
      "Epoch 28/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8255\n",
      "Epoch 29/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.8246\n",
      "Epoch 30/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8215\n",
      "Epoch 31/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8156\n",
      "Epoch 32/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.8110\n",
      "Epoch 33/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.8073\n",
      "Epoch 34/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8042\n",
      "Epoch 35/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8044\n",
      "Epoch 36/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.8011\n",
      "Epoch 37/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7967\n",
      "Epoch 38/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7940\n",
      "Epoch 39/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7892\n",
      "Epoch 40/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7882\n",
      "Epoch 41/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7853\n",
      "Epoch 42/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7829\n",
      "Epoch 43/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7826\n",
      "Epoch 44/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7804\n",
      "Epoch 45/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.7776\n",
      "Epoch 46/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7757\n",
      "Epoch 47/100\n",
      "8/8 - 0s - 9ms/step - loss: 0.7716\n",
      "Epoch 48/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.7709\n",
      "Epoch 49/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7704\n",
      "Epoch 50/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7690\n",
      "Epoch 51/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7668\n",
      "Epoch 52/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.7653\n",
      "Epoch 53/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.7636\n",
      "Epoch 54/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7637\n",
      "Epoch 55/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7608\n",
      "Epoch 56/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7603\n",
      "Epoch 57/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7536\n",
      "Epoch 58/100\n",
      "8/8 - 0s - 9ms/step - loss: 0.7581\n",
      "Epoch 59/100\n",
      "8/8 - 0s - 9ms/step - loss: 0.7542\n",
      "Epoch 60/100\n",
      "8/8 - 0s - 9ms/step - loss: 0.7525\n",
      "Epoch 61/100\n",
      "8/8 - 0s - 9ms/step - loss: 0.7533\n",
      "Epoch 62/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7518\n",
      "Epoch 63/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7484\n",
      "Epoch 64/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7487\n",
      "Epoch 65/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.7516\n",
      "Epoch 66/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7485\n",
      "Epoch 67/100\n",
      "8/8 - 0s - 9ms/step - loss: 0.7484\n",
      "Epoch 68/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7486\n",
      "Epoch 69/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7460\n",
      "Epoch 70/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.7437\n",
      "Epoch 71/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7434\n",
      "Epoch 72/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7389\n",
      "Epoch 73/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7418\n",
      "Epoch 74/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7403\n",
      "Epoch 75/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7373\n",
      "Epoch 76/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7401\n",
      "Epoch 77/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7400\n",
      "Epoch 78/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7417\n",
      "Epoch 79/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7373\n",
      "Epoch 80/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7361\n",
      "Epoch 81/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7375\n",
      "Epoch 82/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7362\n",
      "Epoch 83/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7378\n",
      "Epoch 84/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7316\n",
      "Epoch 85/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7315\n",
      "Epoch 86/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7335\n",
      "Epoch 87/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7327\n",
      "Epoch 88/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7291\n",
      "Epoch 89/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7309\n",
      "Epoch 90/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7261\n",
      "Epoch 91/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7298\n",
      "Epoch 92/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7278\n",
      "Epoch 93/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7275\n",
      "Epoch 94/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7244\n",
      "Epoch 95/100\n",
      "8/8 - 0s - 9ms/step - loss: 0.7243\n",
      "Epoch 96/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7215\n",
      "Epoch 97/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7252\n",
      "Epoch 98/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7250\n",
      "Epoch 99/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7269\n",
      "Epoch 100/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.7232\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "Testing with layers=[256, 128, 64, 32], encoding_dim=8, batch_size=32, epochs=50, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "32/32 - 2s - 62ms/step - loss: 1.1142\n",
      "Epoch 2/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.9576\n",
      "Epoch 3/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.9098\n",
      "Epoch 4/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8772\n",
      "Epoch 5/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8561\n",
      "Epoch 6/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.8426\n",
      "Epoch 7/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8295\n",
      "Epoch 8/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8224\n",
      "Epoch 9/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8140\n",
      "Epoch 10/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8062\n",
      "Epoch 11/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8033\n",
      "Epoch 12/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7970\n",
      "Epoch 13/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7910\n",
      "Epoch 14/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7896\n",
      "Epoch 15/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7872\n",
      "Epoch 16/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7824\n",
      "Epoch 17/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7802\n",
      "Epoch 18/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7787\n",
      "Epoch 19/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7715\n",
      "Epoch 20/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7734\n",
      "Epoch 21/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7665\n",
      "Epoch 22/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7658\n",
      "Epoch 23/50\n",
      "32/32 - 0s - 5ms/step - loss: 0.7646\n",
      "Epoch 24/50\n",
      "32/32 - 0s - 5ms/step - loss: 0.7628\n",
      "Epoch 25/50\n",
      "32/32 - 0s - 4ms/step - loss: 0.7629\n",
      "Epoch 26/50\n",
      "32/32 - 0s - 4ms/step - loss: 0.7621\n",
      "Epoch 27/50\n",
      "32/32 - 0s - 4ms/step - loss: 0.7591\n",
      "Epoch 28/50\n",
      "32/32 - 0s - 4ms/step - loss: 0.7551\n",
      "Epoch 29/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7577\n",
      "Epoch 30/50\n",
      "32/32 - 0s - 5ms/step - loss: 0.7513\n",
      "Epoch 31/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7496\n",
      "Epoch 32/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7522\n",
      "Epoch 33/50\n",
      "32/32 - 0s - 4ms/step - loss: 0.7489\n",
      "Epoch 34/50\n",
      "32/32 - 0s - 5ms/step - loss: 0.7456\n",
      "Epoch 35/50\n",
      "32/32 - 0s - 10ms/step - loss: 0.7479\n",
      "Epoch 36/50\n",
      "32/32 - 0s - 6ms/step - loss: 0.7478\n",
      "Epoch 37/50\n",
      "32/32 - 0s - 5ms/step - loss: 0.7459\n",
      "Epoch 38/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7433\n",
      "Epoch 39/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7425\n",
      "Epoch 40/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7412\n",
      "Epoch 41/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7449\n",
      "Epoch 42/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7387\n",
      "Epoch 43/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7413\n",
      "Epoch 44/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7349\n",
      "Epoch 45/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7418\n",
      "Epoch 46/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7364\n",
      "Epoch 47/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7390\n",
      "Epoch 48/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7369\n",
      "Epoch 49/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7369\n",
      "Epoch 50/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7365\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "Testing with layers=[256, 128, 64, 32], encoding_dim=8, batch_size=32, epochs=50, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "32/32 - 2s - 56ms/step - loss: 1.1478\n",
      "Epoch 2/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.9959\n",
      "Epoch 3/50\n",
      "32/32 - 0s - 4ms/step - loss: 0.9538\n",
      "Epoch 4/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.9285\n",
      "Epoch 5/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.9114\n",
      "Epoch 6/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.8967\n",
      "Epoch 7/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8867\n",
      "Epoch 8/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8770\n",
      "Epoch 9/50\n",
      "32/32 - 0s - 4ms/step - loss: 0.8615\n",
      "Epoch 10/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8548\n",
      "Epoch 11/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8468\n",
      "Epoch 12/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8435\n",
      "Epoch 13/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.8361\n",
      "Epoch 14/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8311\n",
      "Epoch 15/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.8267\n",
      "Epoch 16/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.8254\n",
      "Epoch 17/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.8204\n",
      "Epoch 18/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8191\n",
      "Epoch 19/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8140\n",
      "Epoch 20/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8114\n",
      "Epoch 21/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8097\n",
      "Epoch 22/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.8068\n",
      "Epoch 23/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8033\n",
      "Epoch 24/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7960\n",
      "Epoch 25/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.8001\n",
      "Epoch 26/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7971\n",
      "Epoch 27/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8007\n",
      "Epoch 28/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7953\n",
      "Epoch 29/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7945\n",
      "Epoch 30/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7915\n",
      "Epoch 31/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7885\n",
      "Epoch 32/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7893\n",
      "Epoch 33/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7879\n",
      "Epoch 34/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7908\n",
      "Epoch 35/50\n",
      "32/32 - 0s - 5ms/step - loss: 0.7827\n",
      "Epoch 36/50\n",
      "32/32 - 0s - 4ms/step - loss: 0.7860\n",
      "Epoch 37/50\n",
      "32/32 - 0s - 4ms/step - loss: 0.7831\n",
      "Epoch 38/50\n",
      "32/32 - 0s - 5ms/step - loss: 0.7828\n",
      "Epoch 39/50\n",
      "32/32 - 0s - 9ms/step - loss: 0.7826\n",
      "Epoch 40/50\n",
      "32/32 - 0s - 6ms/step - loss: 0.7816\n",
      "Epoch 41/50\n",
      "32/32 - 0s - 7ms/step - loss: 0.7772\n",
      "Epoch 42/50\n",
      "32/32 - 0s - 6ms/step - loss: 0.7804\n",
      "Epoch 43/50\n",
      "32/32 - 0s - 6ms/step - loss: 0.7792\n",
      "Epoch 44/50\n",
      "32/32 - 0s - 6ms/step - loss: 0.7771\n",
      "Epoch 45/50\n",
      "32/32 - 0s - 6ms/step - loss: 0.7771\n",
      "Epoch 46/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7753\n",
      "Epoch 47/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7733\n",
      "Epoch 48/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7724\n",
      "Epoch 49/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7711\n",
      "Epoch 50/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7698\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "Testing with layers=[256, 128, 64, 32], encoding_dim=8, batch_size=32, epochs=100, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "32/32 - 2s - 71ms/step - loss: 1.1236\n",
      "Epoch 2/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.9570\n",
      "Epoch 3/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.9157\n",
      "Epoch 4/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.8865\n",
      "Epoch 5/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.8683\n",
      "Epoch 6/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.8537\n",
      "Epoch 7/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.8416\n",
      "Epoch 8/100\n",
      "32/32 - 0s - 5ms/step - loss: 0.8312\n",
      "Epoch 9/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.8246\n",
      "Epoch 10/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.8157\n",
      "Epoch 11/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.8116\n",
      "Epoch 12/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.8079\n",
      "Epoch 13/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.8016\n",
      "Epoch 14/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.8004\n",
      "Epoch 15/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7967\n",
      "Epoch 16/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7902\n",
      "Epoch 17/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7867\n",
      "Epoch 18/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7857\n",
      "Epoch 19/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.7824\n",
      "Epoch 20/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7762\n",
      "Epoch 21/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7750\n",
      "Epoch 22/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7696\n",
      "Epoch 23/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7702\n",
      "Epoch 24/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7682\n",
      "Epoch 25/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7627\n",
      "Epoch 26/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7588\n",
      "Epoch 27/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7617\n",
      "Epoch 28/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7558\n",
      "Epoch 29/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.7542\n",
      "Epoch 30/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7506\n",
      "Epoch 31/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7520\n",
      "Epoch 32/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7509\n",
      "Epoch 33/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7460\n",
      "Epoch 34/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7452\n",
      "Epoch 35/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.7478\n",
      "Epoch 36/100\n",
      "32/32 - 0s - 6ms/step - loss: 0.7463\n",
      "Epoch 37/100\n",
      "32/32 - 0s - 5ms/step - loss: 0.7434\n",
      "Epoch 38/100\n",
      "32/32 - 0s - 6ms/step - loss: 0.7405\n",
      "Epoch 39/100\n",
      "32/32 - 0s - 5ms/step - loss: 0.7404\n",
      "Epoch 40/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.7402\n",
      "Epoch 41/100\n",
      "32/32 - 0s - 7ms/step - loss: 0.7369\n",
      "Epoch 42/100\n",
      "32/32 - 0s - 7ms/step - loss: 0.7337\n",
      "Epoch 43/100\n",
      "32/32 - 0s - 6ms/step - loss: 0.7339\n",
      "Epoch 44/100\n",
      "32/32 - 0s - 6ms/step - loss: 0.7318\n",
      "Epoch 45/100\n",
      "32/32 - 0s - 5ms/step - loss: 0.7310\n",
      "Epoch 46/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.7308\n",
      "Epoch 47/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7319\n",
      "Epoch 48/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7267\n",
      "Epoch 49/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7263\n",
      "Epoch 50/100\n",
      "32/32 - 0s - 5ms/step - loss: 0.7263\n",
      "Epoch 51/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.7286\n",
      "Epoch 52/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.7244\n",
      "Epoch 53/100\n",
      "32/32 - 0s - 7ms/step - loss: 0.7232\n",
      "Epoch 54/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7238\n",
      "Epoch 55/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7268\n",
      "Epoch 56/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7217\n",
      "Epoch 57/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7231\n",
      "Epoch 58/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7263\n",
      "Epoch 59/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7211\n",
      "Epoch 60/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7202\n",
      "Epoch 61/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7239\n",
      "Epoch 62/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7187\n",
      "Epoch 63/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7232\n",
      "Epoch 64/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7206\n",
      "Epoch 65/100\n",
      "32/32 - 0s - 5ms/step - loss: 0.7165\n",
      "Epoch 66/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7184\n",
      "Epoch 67/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7145\n",
      "Epoch 68/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7175\n",
      "Epoch 69/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7147\n",
      "Epoch 70/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7172\n",
      "Epoch 71/100\n",
      "32/32 - 0s - 6ms/step - loss: 0.7162\n",
      "Epoch 72/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7161\n",
      "Epoch 73/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7130\n",
      "Epoch 74/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7162\n",
      "Epoch 75/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7138\n",
      "Epoch 76/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7157\n",
      "Epoch 77/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7138\n",
      "Epoch 78/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7118\n",
      "Epoch 79/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7100\n",
      "Epoch 80/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7169\n",
      "Epoch 81/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7124\n",
      "Epoch 82/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7107\n",
      "Epoch 83/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7128\n",
      "Epoch 84/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7133\n",
      "Epoch 85/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7086\n",
      "Epoch 86/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7103\n",
      "Epoch 87/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7127\n",
      "Epoch 88/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7074\n",
      "Epoch 89/100\n",
      "32/32 - 0s - 5ms/step - loss: 0.7067\n",
      "Epoch 90/100\n",
      "32/32 - 0s - 6ms/step - loss: 0.7055\n",
      "Epoch 91/100\n",
      "32/32 - 0s - 6ms/step - loss: 0.7132\n",
      "Epoch 92/100\n",
      "32/32 - 0s - 5ms/step - loss: 0.7109\n",
      "Epoch 93/100\n",
      "32/32 - 0s - 5ms/step - loss: 0.7057\n",
      "Epoch 94/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7100\n",
      "Epoch 95/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.7042\n",
      "Epoch 96/100\n",
      "32/32 - 0s - 5ms/step - loss: 0.7064\n",
      "Epoch 97/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.7084\n",
      "Epoch 98/100\n",
      "32/32 - 0s - 6ms/step - loss: 0.7090\n",
      "Epoch 99/100\n",
      "32/32 - 0s - 5ms/step - loss: 0.7041\n",
      "Epoch 100/100\n",
      "32/32 - 0s - 6ms/step - loss: 0.7047\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step\n",
      "Testing with layers=[256, 128, 64, 32], encoding_dim=8, batch_size=32, epochs=100, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "32/32 - 2s - 65ms/step - loss: 1.1497\n",
      "Epoch 2/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.9951\n",
      "Epoch 3/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.9480\n",
      "Epoch 4/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.9205\n",
      "Epoch 5/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.9043\n",
      "Epoch 6/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.8885\n",
      "Epoch 7/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.8801\n",
      "Epoch 8/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.8697\n",
      "Epoch 9/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.8638\n",
      "Epoch 10/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.8578\n",
      "Epoch 11/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.8531\n",
      "Epoch 12/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.8485\n",
      "Epoch 13/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.8414\n",
      "Epoch 14/100\n",
      "32/32 - 0s - 6ms/step - loss: 0.8448\n",
      "Epoch 15/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.8329\n",
      "Epoch 16/100\n",
      "32/32 - 0s - 5ms/step - loss: 0.8323\n",
      "Epoch 17/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.8339\n",
      "Epoch 18/100\n",
      "32/32 - 0s - 5ms/step - loss: 0.8249\n",
      "Epoch 19/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.8268\n",
      "Epoch 20/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.8201\n",
      "Epoch 21/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.8205\n",
      "Epoch 22/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.8185\n",
      "Epoch 23/100\n",
      "32/32 - 0s - 5ms/step - loss: 0.8158\n",
      "Epoch 24/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.8144\n",
      "Epoch 25/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.8136\n",
      "Epoch 26/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.8078\n",
      "Epoch 27/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.8046\n",
      "Epoch 28/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.8058\n",
      "Epoch 29/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.8028\n",
      "Epoch 30/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.8042\n",
      "Epoch 31/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7993\n",
      "Epoch 32/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7953\n",
      "Epoch 33/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7989\n",
      "Epoch 34/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7927\n",
      "Epoch 35/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7956\n",
      "Epoch 36/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7917\n",
      "Epoch 37/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7919\n",
      "Epoch 38/100\n",
      "32/32 - 0s - 5ms/step - loss: 0.7919\n",
      "Epoch 39/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7864\n",
      "Epoch 40/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7877\n",
      "Epoch 41/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7853\n",
      "Epoch 42/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.7849\n",
      "Epoch 43/100\n",
      "32/32 - 0s - 6ms/step - loss: 0.7785\n",
      "Epoch 44/100\n",
      "32/32 - 0s - 6ms/step - loss: 0.7841\n",
      "Epoch 45/100\n",
      "32/32 - 0s - 6ms/step - loss: 0.7798\n",
      "Epoch 46/100\n",
      "32/32 - 0s - 6ms/step - loss: 0.7798\n",
      "Epoch 47/100\n",
      "32/32 - 0s - 5ms/step - loss: 0.7781\n",
      "Epoch 48/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.7759\n",
      "Epoch 49/100\n",
      "32/32 - 0s - 6ms/step - loss: 0.7732\n",
      "Epoch 50/100\n",
      "32/32 - 0s - 6ms/step - loss: 0.7762\n",
      "Epoch 51/100\n",
      "32/32 - 0s - 6ms/step - loss: 0.7739\n",
      "Epoch 52/100\n",
      "32/32 - 0s - 5ms/step - loss: 0.7717\n",
      "Epoch 53/100\n",
      "32/32 - 0s - 6ms/step - loss: 0.7721\n",
      "Epoch 54/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7707\n",
      "Epoch 55/100\n",
      "32/32 - 0s - 6ms/step - loss: 0.7726\n",
      "Epoch 56/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.7690\n",
      "Epoch 57/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.7691\n",
      "Epoch 58/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.7684\n",
      "Epoch 59/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7651\n",
      "Epoch 60/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.7684\n",
      "Epoch 61/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7670\n",
      "Epoch 62/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7677\n",
      "Epoch 63/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7683\n",
      "Epoch 64/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7673\n",
      "Epoch 65/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7634\n",
      "Epoch 66/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7630\n",
      "Epoch 67/100\n",
      "32/32 - 0s - 7ms/step - loss: 0.7655\n",
      "Epoch 68/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.7628\n",
      "Epoch 69/100\n",
      "32/32 - 0s - 8ms/step - loss: 0.7636\n",
      "Epoch 70/100\n",
      "32/32 - 0s - 5ms/step - loss: 0.7654\n",
      "Epoch 71/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7594\n",
      "Epoch 72/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7622\n",
      "Epoch 73/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7651\n",
      "Epoch 74/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7643\n",
      "Epoch 75/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7621\n",
      "Epoch 76/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7634\n",
      "Epoch 77/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7626\n",
      "Epoch 78/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7624\n",
      "Epoch 79/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7662\n",
      "Epoch 80/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7581\n",
      "Epoch 81/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7611\n",
      "Epoch 82/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7610\n",
      "Epoch 83/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7590\n",
      "Epoch 84/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7582\n",
      "Epoch 85/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7624\n",
      "Epoch 86/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7567\n",
      "Epoch 87/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7548\n",
      "Epoch 88/100\n",
      "32/32 - 0s - 5ms/step - loss: 0.7595\n",
      "Epoch 89/100\n",
      "32/32 - 0s - 5ms/step - loss: 0.7564\n",
      "Epoch 90/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7591\n",
      "Epoch 91/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7550\n",
      "Epoch 92/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.7514\n",
      "Epoch 93/100\n",
      "32/32 - 0s - 6ms/step - loss: 0.7545\n",
      "Epoch 94/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7525\n",
      "Epoch 95/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7532\n",
      "Epoch 96/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7511\n",
      "Epoch 97/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7493\n",
      "Epoch 98/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7564\n",
      "Epoch 99/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7560\n",
      "Epoch 100/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7498\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step\n",
      "Testing with layers=[256, 128, 64, 32], encoding_dim=8, batch_size=64, epochs=50, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "16/16 - 2s - 139ms/step - loss: 1.1753\n",
      "Epoch 2/50\n",
      "16/16 - 0s - 3ms/step - loss: 1.0106\n",
      "Epoch 3/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.9494\n",
      "Epoch 4/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.9155\n",
      "Epoch 5/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.8957\n",
      "Epoch 6/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.8762\n",
      "Epoch 7/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.8652\n",
      "Epoch 8/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.8537\n",
      "Epoch 9/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.8468\n",
      "Epoch 10/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.8388\n",
      "Epoch 11/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8298\n",
      "Epoch 12/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.8253\n",
      "Epoch 13/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.8222\n",
      "Epoch 14/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.8128\n",
      "Epoch 15/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.8092\n",
      "Epoch 16/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.8069\n",
      "Epoch 17/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.8008\n",
      "Epoch 18/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.8014\n",
      "Epoch 19/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7932\n",
      "Epoch 20/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7932\n",
      "Epoch 21/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7915\n",
      "Epoch 22/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7878\n",
      "Epoch 23/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7834\n",
      "Epoch 24/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7791\n",
      "Epoch 25/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7810\n",
      "Epoch 26/50\n",
      "16/16 - 0s - 7ms/step - loss: 0.7730\n",
      "Epoch 27/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7712\n",
      "Epoch 28/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7681\n",
      "Epoch 29/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7692\n",
      "Epoch 30/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7630\n",
      "Epoch 31/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7671\n",
      "Epoch 32/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7659\n",
      "Epoch 33/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7592\n",
      "Epoch 34/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7572\n",
      "Epoch 35/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7589\n",
      "Epoch 36/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7553\n",
      "Epoch 37/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7487\n",
      "Epoch 38/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7526\n",
      "Epoch 39/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7511\n",
      "Epoch 40/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7517\n",
      "Epoch 41/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7505\n",
      "Epoch 42/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7494\n",
      "Epoch 43/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7448\n",
      "Epoch 44/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7453\n",
      "Epoch 45/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7445\n",
      "Epoch 46/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7410\n",
      "Epoch 47/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7444\n",
      "Epoch 48/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7446\n",
      "Epoch 49/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7413\n",
      "Epoch 50/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7366\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step\n",
      "Testing with layers=[256, 128, 64, 32], encoding_dim=8, batch_size=64, epochs=50, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "16/16 - 2s - 99ms/step - loss: 1.1896\n",
      "Epoch 2/50\n",
      "16/16 - 0s - 2ms/step - loss: 1.0379\n",
      "Epoch 3/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.9815\n",
      "Epoch 4/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.9504\n",
      "Epoch 5/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.9304\n",
      "Epoch 6/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.9111\n",
      "Epoch 7/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.8993\n",
      "Epoch 8/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8890\n",
      "Epoch 9/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8786\n",
      "Epoch 10/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8697\n",
      "Epoch 11/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8627\n",
      "Epoch 12/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8594\n",
      "Epoch 13/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8490\n",
      "Epoch 14/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.8450\n",
      "Epoch 15/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8380\n",
      "Epoch 16/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.8384\n",
      "Epoch 17/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8293\n",
      "Epoch 18/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8245\n",
      "Epoch 19/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8247\n",
      "Epoch 20/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8140\n",
      "Epoch 21/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.8158\n",
      "Epoch 22/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8142\n",
      "Epoch 23/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8099\n",
      "Epoch 24/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8090\n",
      "Epoch 25/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.8031\n",
      "Epoch 26/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8044\n",
      "Epoch 27/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.8051\n",
      "Epoch 28/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.8008\n",
      "Epoch 29/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7976\n",
      "Epoch 30/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7979\n",
      "Epoch 31/50\n",
      "16/16 - 0s - 5ms/step - loss: 0.7940\n",
      "Epoch 32/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7966\n",
      "Epoch 33/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7940\n",
      "Epoch 34/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7930\n",
      "Epoch 35/50\n",
      "16/16 - 0s - 7ms/step - loss: 0.7916\n",
      "Epoch 36/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7878\n",
      "Epoch 37/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7885\n",
      "Epoch 38/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7870\n",
      "Epoch 39/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7847\n",
      "Epoch 40/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7862\n",
      "Epoch 41/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7844\n",
      "Epoch 42/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7833\n",
      "Epoch 43/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7837\n",
      "Epoch 44/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7818\n",
      "Epoch 45/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7836\n",
      "Epoch 46/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7825\n",
      "Epoch 47/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7788\n",
      "Epoch 48/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7772\n",
      "Epoch 49/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7784\n",
      "Epoch 50/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7774\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Testing with layers=[256, 128, 64, 32], encoding_dim=8, batch_size=64, epochs=100, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "16/16 - 2s - 95ms/step - loss: 1.1605\n",
      "Epoch 2/100\n",
      "16/16 - 0s - 2ms/step - loss: 1.0055\n",
      "Epoch 3/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.9443\n",
      "Epoch 4/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.9101\n",
      "Epoch 5/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.8873\n",
      "Epoch 6/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8714\n",
      "Epoch 7/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8573\n",
      "Epoch 8/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8462\n",
      "Epoch 9/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8376\n",
      "Epoch 10/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.8305\n",
      "Epoch 11/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.8242\n",
      "Epoch 12/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.8181\n",
      "Epoch 13/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.8129\n",
      "Epoch 14/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.8045\n",
      "Epoch 15/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.8000\n",
      "Epoch 16/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7977\n",
      "Epoch 17/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7923\n",
      "Epoch 18/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7904\n",
      "Epoch 19/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7865\n",
      "Epoch 20/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7818\n",
      "Epoch 21/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7782\n",
      "Epoch 22/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7789\n",
      "Epoch 23/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7723\n",
      "Epoch 24/100\n",
      "16/16 - 0s - 7ms/step - loss: 0.7681\n",
      "Epoch 25/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7708\n",
      "Epoch 26/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7647\n",
      "Epoch 27/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7646\n",
      "Epoch 28/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7649\n",
      "Epoch 29/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7603\n",
      "Epoch 30/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7573\n",
      "Epoch 31/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7555\n",
      "Epoch 32/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7586\n",
      "Epoch 33/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7513\n",
      "Epoch 34/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7556\n",
      "Epoch 35/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7520\n",
      "Epoch 36/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7500\n",
      "Epoch 37/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7492\n",
      "Epoch 38/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7456\n",
      "Epoch 39/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7440\n",
      "Epoch 40/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7461\n",
      "Epoch 41/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7434\n",
      "Epoch 42/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7484\n",
      "Epoch 43/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7408\n",
      "Epoch 44/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7395\n",
      "Epoch 45/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7397\n",
      "Epoch 46/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7363\n",
      "Epoch 47/100\n",
      "16/16 - 0s - 6ms/step - loss: 0.7346\n",
      "Epoch 48/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7346\n",
      "Epoch 49/100\n",
      "16/16 - 0s - 8ms/step - loss: 0.7346\n",
      "Epoch 50/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7300\n",
      "Epoch 51/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7312\n",
      "Epoch 52/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7307\n",
      "Epoch 53/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7313\n",
      "Epoch 54/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7315\n",
      "Epoch 55/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7301\n",
      "Epoch 56/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7291\n",
      "Epoch 57/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7260\n",
      "Epoch 58/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7271\n",
      "Epoch 59/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7276\n",
      "Epoch 60/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7255\n",
      "Epoch 61/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7247\n",
      "Epoch 62/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7225\n",
      "Epoch 63/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7223\n",
      "Epoch 64/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7211\n",
      "Epoch 65/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7192\n",
      "Epoch 66/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7203\n",
      "Epoch 67/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7191\n",
      "Epoch 68/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7184\n",
      "Epoch 69/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7175\n",
      "Epoch 70/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7151\n",
      "Epoch 71/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7151\n",
      "Epoch 72/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7138\n",
      "Epoch 73/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7137\n",
      "Epoch 74/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7140\n",
      "Epoch 75/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7098\n",
      "Epoch 76/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7122\n",
      "Epoch 77/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7112\n",
      "Epoch 78/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7086\n",
      "Epoch 79/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7082\n",
      "Epoch 80/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7068\n",
      "Epoch 81/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7098\n",
      "Epoch 82/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7092\n",
      "Epoch 83/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7082\n",
      "Epoch 84/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7092\n",
      "Epoch 85/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7057\n",
      "Epoch 86/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7029\n",
      "Epoch 87/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7044\n",
      "Epoch 88/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7089\n",
      "Epoch 89/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7051\n",
      "Epoch 90/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7018\n",
      "Epoch 91/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7055\n",
      "Epoch 92/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7029\n",
      "Epoch 93/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7059\n",
      "Epoch 94/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7003\n",
      "Epoch 95/100\n",
      "16/16 - 0s - 6ms/step - loss: 0.7054\n",
      "Epoch 96/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.6995\n",
      "Epoch 97/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7011\n",
      "Epoch 98/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7008\n",
      "Epoch 99/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6990\n",
      "Epoch 100/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7027\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "New best score: 0.31653615832328796 with params: {'layer_sizes': [256, 128, 64, 32], 'encoding_dim': 8, 'batch_size': 64, 'epochs': 100, 'dropout_rate': 0.2}\n",
      "Testing with layers=[256, 128, 64, 32], encoding_dim=8, batch_size=64, epochs=100, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "16/16 - 2s - 99ms/step - loss: 1.1833\n",
      "Epoch 2/100\n",
      "16/16 - 0s - 3ms/step - loss: 1.0356\n",
      "Epoch 3/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.9725\n",
      "Epoch 4/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.9413\n",
      "Epoch 5/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.9174\n",
      "Epoch 6/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.9034\n",
      "Epoch 7/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.8896\n",
      "Epoch 8/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8821\n",
      "Epoch 9/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.8759\n",
      "Epoch 10/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8693\n",
      "Epoch 11/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.8579\n",
      "Epoch 12/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8530\n",
      "Epoch 13/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.8503\n",
      "Epoch 14/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8467\n",
      "Epoch 15/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.8446\n",
      "Epoch 16/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8405\n",
      "Epoch 17/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8378\n",
      "Epoch 18/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8329\n",
      "Epoch 19/100\n",
      "16/16 - 0s - 7ms/step - loss: 0.8326\n",
      "Epoch 20/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.8293\n",
      "Epoch 21/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8257\n",
      "Epoch 22/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8210\n",
      "Epoch 23/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8226\n",
      "Epoch 24/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8210\n",
      "Epoch 25/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8150\n",
      "Epoch 26/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.8152\n",
      "Epoch 27/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8111\n",
      "Epoch 28/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.8123\n",
      "Epoch 29/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8096\n",
      "Epoch 30/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8093\n",
      "Epoch 31/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8056\n",
      "Epoch 32/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8053\n",
      "Epoch 33/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.8067\n",
      "Epoch 34/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.8006\n",
      "Epoch 35/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7964\n",
      "Epoch 36/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8009\n",
      "Epoch 37/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7968\n",
      "Epoch 38/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7972\n",
      "Epoch 39/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7993\n",
      "Epoch 40/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7954\n",
      "Epoch 41/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7952\n",
      "Epoch 42/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7924\n",
      "Epoch 43/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7912\n",
      "Epoch 44/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7855\n",
      "Epoch 45/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7864\n",
      "Epoch 46/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7854\n",
      "Epoch 47/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7831\n",
      "Epoch 48/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7829\n",
      "Epoch 49/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7829\n",
      "Epoch 50/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7819\n",
      "Epoch 51/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7794\n",
      "Epoch 52/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7821\n",
      "Epoch 53/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7777\n",
      "Epoch 54/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7789\n",
      "Epoch 55/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7757\n",
      "Epoch 56/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7775\n",
      "Epoch 57/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7725\n",
      "Epoch 58/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7761\n",
      "Epoch 59/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7742\n",
      "Epoch 60/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7687\n",
      "Epoch 61/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7719\n",
      "Epoch 62/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7715\n",
      "Epoch 63/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7703\n",
      "Epoch 64/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7708\n",
      "Epoch 65/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7740\n",
      "Epoch 66/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7704\n",
      "Epoch 67/100\n",
      "16/16 - 0s - 6ms/step - loss: 0.7647\n",
      "Epoch 68/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7640\n",
      "Epoch 69/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7647\n",
      "Epoch 70/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7638\n",
      "Epoch 71/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7657\n",
      "Epoch 72/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7616\n",
      "Epoch 73/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7662\n",
      "Epoch 74/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7627\n",
      "Epoch 75/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7607\n",
      "Epoch 76/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7608\n",
      "Epoch 77/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7614\n",
      "Epoch 78/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7625\n",
      "Epoch 79/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7616\n",
      "Epoch 80/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7620\n",
      "Epoch 81/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7574\n",
      "Epoch 82/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7592\n",
      "Epoch 83/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7535\n",
      "Epoch 84/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7569\n",
      "Epoch 85/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7564\n",
      "Epoch 86/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7537\n",
      "Epoch 87/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7593\n",
      "Epoch 88/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7540\n",
      "Epoch 89/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7566\n",
      "Epoch 90/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7522\n",
      "Epoch 91/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7520\n",
      "Epoch 92/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7516\n",
      "Epoch 93/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7569\n",
      "Epoch 94/100\n",
      "16/16 - 0s - 8ms/step - loss: 0.7503\n",
      "Epoch 95/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7548\n",
      "Epoch 96/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7546\n",
      "Epoch 97/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7505\n",
      "Epoch 98/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7491\n",
      "Epoch 99/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7540\n",
      "Epoch 100/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7538\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "New best score: 0.3250749409198761 with params: {'layer_sizes': [256, 128, 64, 32], 'encoding_dim': 8, 'batch_size': 64, 'epochs': 100, 'dropout_rate': 0.3}\n",
      "Testing with layers=[256, 128, 64, 32], encoding_dim=8, batch_size=128, epochs=50, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "8/8 - 1s - 184ms/step - loss: 1.1966\n",
      "Epoch 2/50\n",
      "8/8 - 0s - 4ms/step - loss: 1.0655\n",
      "Epoch 3/50\n",
      "8/8 - 0s - 4ms/step - loss: 1.0041\n",
      "Epoch 4/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.9613\n",
      "Epoch 5/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.9323\n",
      "Epoch 6/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.9097\n",
      "Epoch 7/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8909\n",
      "Epoch 8/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8789\n",
      "Epoch 9/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8664\n",
      "Epoch 10/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8593\n",
      "Epoch 11/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8476\n",
      "Epoch 12/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8385\n",
      "Epoch 13/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8334\n",
      "Epoch 14/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8313\n",
      "Epoch 15/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8214\n",
      "Epoch 16/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8177\n",
      "Epoch 17/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8151\n",
      "Epoch 18/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8110\n",
      "Epoch 19/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.8101\n",
      "Epoch 20/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8082\n",
      "Epoch 21/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8039\n",
      "Epoch 22/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7991\n",
      "Epoch 23/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7972\n",
      "Epoch 24/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7938\n",
      "Epoch 25/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.7903\n",
      "Epoch 26/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7875\n",
      "Epoch 27/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7858\n",
      "Epoch 28/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7823\n",
      "Epoch 29/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7808\n",
      "Epoch 30/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7824\n",
      "Epoch 31/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7757\n",
      "Epoch 32/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7757\n",
      "Epoch 33/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7761\n",
      "Epoch 34/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.7749\n",
      "Epoch 35/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.7715\n",
      "Epoch 36/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.7696\n",
      "Epoch 37/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.7675\n",
      "Epoch 38/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.7649\n",
      "Epoch 39/50\n",
      "8/8 - 0s - 9ms/step - loss: 0.7669\n",
      "Epoch 40/50\n",
      "8/8 - 0s - 9ms/step - loss: 0.7656\n",
      "Epoch 41/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.7651\n",
      "Epoch 42/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.7644\n",
      "Epoch 43/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.7629\n",
      "Epoch 44/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.7592\n",
      "Epoch 45/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.7585\n",
      "Epoch 46/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.7596\n",
      "Epoch 47/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.7533\n",
      "Epoch 48/50\n",
      "8/8 - 0s - 8ms/step - loss: 0.7568\n",
      "Epoch 49/50\n",
      "8/8 - 0s - 10ms/step - loss: 0.7547\n",
      "Epoch 50/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.7498\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "Testing with layers=[256, 128, 64, 32], encoding_dim=8, batch_size=128, epochs=50, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "8/8 - 2s - 197ms/step - loss: 1.2196\n",
      "Epoch 2/50\n",
      "8/8 - 0s - 4ms/step - loss: 1.1028\n",
      "Epoch 3/50\n",
      "8/8 - 0s - 5ms/step - loss: 1.0322\n",
      "Epoch 4/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.9934\n",
      "Epoch 5/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.9587\n",
      "Epoch 6/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.9434\n",
      "Epoch 7/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.9261\n",
      "Epoch 8/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.9156\n",
      "Epoch 9/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.9060\n",
      "Epoch 10/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8927\n",
      "Epoch 11/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8873\n",
      "Epoch 12/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8792\n",
      "Epoch 13/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8728\n",
      "Epoch 14/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8624\n",
      "Epoch 15/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8610\n",
      "Epoch 16/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.8617\n",
      "Epoch 17/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.8515\n",
      "Epoch 18/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8493\n",
      "Epoch 19/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8435\n",
      "Epoch 20/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8398\n",
      "Epoch 21/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8390\n",
      "Epoch 22/50\n",
      "8/8 - 0s - 8ms/step - loss: 0.8330\n",
      "Epoch 23/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.8328\n",
      "Epoch 24/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.8276\n",
      "Epoch 25/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.8237\n",
      "Epoch 26/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8217\n",
      "Epoch 27/50\n",
      "8/8 - 0s - 16ms/step - loss: 0.8185\n",
      "Epoch 28/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.8173\n",
      "Epoch 29/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.8113\n",
      "Epoch 30/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.8136\n",
      "Epoch 31/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.8067\n",
      "Epoch 32/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.8060\n",
      "Epoch 33/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8046\n",
      "Epoch 34/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.8057\n",
      "Epoch 35/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8024\n",
      "Epoch 36/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8027\n",
      "Epoch 37/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8003\n",
      "Epoch 38/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7947\n",
      "Epoch 39/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8007\n",
      "Epoch 40/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7946\n",
      "Epoch 41/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7920\n",
      "Epoch 42/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7936\n",
      "Epoch 43/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7928\n",
      "Epoch 44/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.7885\n",
      "Epoch 45/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7896\n",
      "Epoch 46/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7851\n",
      "Epoch 47/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7855\n",
      "Epoch 48/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7828\n",
      "Epoch 49/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7820\n",
      "Epoch 50/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7803\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Testing with layers=[256, 128, 64, 32], encoding_dim=8, batch_size=128, epochs=100, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "8/8 - 2s - 188ms/step - loss: 1.1917\n",
      "Epoch 2/100\n",
      "8/8 - 0s - 4ms/step - loss: 1.0680\n",
      "Epoch 3/100\n",
      "8/8 - 0s - 4ms/step - loss: 1.0048\n",
      "Epoch 4/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.9623\n",
      "Epoch 5/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.9394\n",
      "Epoch 6/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.9179\n",
      "Epoch 7/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.9033\n",
      "Epoch 8/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8887\n",
      "Epoch 9/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8767\n",
      "Epoch 10/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8690\n",
      "Epoch 11/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8583\n",
      "Epoch 12/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.8538\n",
      "Epoch 13/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8449\n",
      "Epoch 14/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8379\n",
      "Epoch 15/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8356\n",
      "Epoch 16/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.8285\n",
      "Epoch 17/100\n",
      "8/8 - 0s - 11ms/step - loss: 0.8255\n",
      "Epoch 18/100\n",
      "8/8 - 0s - 10ms/step - loss: 0.8217\n",
      "Epoch 19/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.8186\n",
      "Epoch 20/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.8111\n",
      "Epoch 21/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.8110\n",
      "Epoch 22/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.8069\n",
      "Epoch 23/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.8068\n",
      "Epoch 24/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.8034\n",
      "Epoch 25/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.8011\n",
      "Epoch 26/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7995\n",
      "Epoch 27/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7919\n",
      "Epoch 28/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7923\n",
      "Epoch 29/100\n",
      "8/8 - 0s - 11ms/step - loss: 0.7949\n",
      "Epoch 30/100\n",
      "8/8 - 0s - 10ms/step - loss: 0.7916\n",
      "Epoch 31/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7909\n",
      "Epoch 32/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7856\n",
      "Epoch 33/100\n",
      "8/8 - 0s - 9ms/step - loss: 0.7841\n",
      "Epoch 34/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.7847\n",
      "Epoch 35/100\n",
      "8/8 - 0s - 9ms/step - loss: 0.7804\n",
      "Epoch 36/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.7828\n",
      "Epoch 37/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.7778\n",
      "Epoch 38/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.7784\n",
      "Epoch 39/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7768\n",
      "Epoch 40/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.7759\n",
      "Epoch 41/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7754\n",
      "Epoch 42/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7749\n",
      "Epoch 43/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7742\n",
      "Epoch 44/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7702\n",
      "Epoch 45/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7706\n",
      "Epoch 46/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7671\n",
      "Epoch 47/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7678\n",
      "Epoch 48/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7673\n",
      "Epoch 49/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7645\n",
      "Epoch 50/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7645\n",
      "Epoch 51/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7640\n",
      "Epoch 52/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7624\n",
      "Epoch 53/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7602\n",
      "Epoch 54/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7614\n",
      "Epoch 55/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7591\n",
      "Epoch 56/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7582\n",
      "Epoch 57/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7565\n",
      "Epoch 58/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7581\n",
      "Epoch 59/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7580\n",
      "Epoch 60/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7569\n",
      "Epoch 61/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7560\n",
      "Epoch 62/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7526\n",
      "Epoch 63/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7547\n",
      "Epoch 64/100\n",
      "8/8 - 0s - 11ms/step - loss: 0.7521\n",
      "Epoch 65/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7488\n",
      "Epoch 66/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7507\n",
      "Epoch 67/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7483\n",
      "Epoch 68/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7476\n",
      "Epoch 69/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7478\n",
      "Epoch 70/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7466\n",
      "Epoch 71/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7452\n",
      "Epoch 72/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7463\n",
      "Epoch 73/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7391\n",
      "Epoch 74/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7426\n",
      "Epoch 75/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7386\n",
      "Epoch 76/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7394\n",
      "Epoch 77/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7432\n",
      "Epoch 78/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7381\n",
      "Epoch 79/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7392\n",
      "Epoch 80/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7372\n",
      "Epoch 81/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7370\n",
      "Epoch 82/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7358\n",
      "Epoch 83/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7329\n",
      "Epoch 84/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7355\n",
      "Epoch 85/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7365\n",
      "Epoch 86/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7309\n",
      "Epoch 87/100\n",
      "8/8 - 0s - 16ms/step - loss: 0.7327\n",
      "Epoch 88/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7298\n",
      "Epoch 89/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7325\n",
      "Epoch 90/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7316\n",
      "Epoch 91/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7292\n",
      "Epoch 92/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7297\n",
      "Epoch 93/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7275\n",
      "Epoch 94/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7268\n",
      "Epoch 95/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7232\n",
      "Epoch 96/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7256\n",
      "Epoch 97/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7234\n",
      "Epoch 98/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7258\n",
      "Epoch 99/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7255\n",
      "Epoch 100/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7253\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Testing with layers=[256, 128, 64, 32], encoding_dim=8, batch_size=128, epochs=100, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "8/8 - 2s - 254ms/step - loss: 1.2052\n",
      "Epoch 2/100\n",
      "8/8 - 0s - 4ms/step - loss: 1.1002\n",
      "Epoch 3/100\n",
      "8/8 - 0s - 5ms/step - loss: 1.0311\n",
      "Epoch 4/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.9868\n",
      "Epoch 5/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.9677\n",
      "Epoch 6/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.9455\n",
      "Epoch 7/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.9296\n",
      "Epoch 8/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.9176\n",
      "Epoch 9/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.9057\n",
      "Epoch 10/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8976\n",
      "Epoch 11/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8889\n",
      "Epoch 12/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8839\n",
      "Epoch 13/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8764\n",
      "Epoch 14/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8699\n",
      "Epoch 15/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8648\n",
      "Epoch 16/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8627\n",
      "Epoch 17/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8566\n",
      "Epoch 18/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8516\n",
      "Epoch 19/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8524\n",
      "Epoch 20/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8489\n",
      "Epoch 21/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8478\n",
      "Epoch 22/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8407\n",
      "Epoch 23/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8392\n",
      "Epoch 24/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8375\n",
      "Epoch 25/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8356\n",
      "Epoch 26/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8310\n",
      "Epoch 27/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8278\n",
      "Epoch 28/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.8274\n",
      "Epoch 29/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.8261\n",
      "Epoch 30/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.8226\n",
      "Epoch 31/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.8204\n",
      "Epoch 32/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.8165\n",
      "Epoch 33/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.8161\n",
      "Epoch 34/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.8149\n",
      "Epoch 35/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.8139\n",
      "Epoch 36/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.8122\n",
      "Epoch 37/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.8091\n",
      "Epoch 38/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.8091\n",
      "Epoch 39/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.8081\n",
      "Epoch 40/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.8060\n",
      "Epoch 41/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.8021\n",
      "Epoch 42/100\n",
      "8/8 - 0s - 9ms/step - loss: 0.8025\n",
      "Epoch 43/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.8026\n",
      "Epoch 44/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7980\n",
      "Epoch 45/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7987\n",
      "Epoch 46/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7994\n",
      "Epoch 47/100\n",
      "8/8 - 0s - 11ms/step - loss: 0.7980\n",
      "Epoch 48/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7925\n",
      "Epoch 49/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7961\n",
      "Epoch 50/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7936\n",
      "Epoch 51/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7941\n",
      "Epoch 52/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7889\n",
      "Epoch 53/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7876\n",
      "Epoch 54/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7888\n",
      "Epoch 55/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7896\n",
      "Epoch 56/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7843\n",
      "Epoch 57/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7858\n",
      "Epoch 58/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7837\n",
      "Epoch 59/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7840\n",
      "Epoch 60/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7832\n",
      "Epoch 61/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7818\n",
      "Epoch 62/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7795\n",
      "Epoch 63/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7819\n",
      "Epoch 64/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7776\n",
      "Epoch 65/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7753\n",
      "Epoch 66/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7822\n",
      "Epoch 67/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7789\n",
      "Epoch 68/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7792\n",
      "Epoch 69/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7752\n",
      "Epoch 70/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7750\n",
      "Epoch 71/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7727\n",
      "Epoch 72/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7725\n",
      "Epoch 73/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7764\n",
      "Epoch 74/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7721\n",
      "Epoch 75/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7700\n",
      "Epoch 76/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7684\n",
      "Epoch 77/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7723\n",
      "Epoch 78/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7691\n",
      "Epoch 79/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7703\n",
      "Epoch 80/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7677\n",
      "Epoch 81/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7677\n",
      "Epoch 82/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7675\n",
      "Epoch 83/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7660\n",
      "Epoch 84/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7658\n",
      "Epoch 85/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7705\n",
      "Epoch 86/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7657\n",
      "Epoch 87/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7660\n",
      "Epoch 88/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7616\n",
      "Epoch 89/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7650\n",
      "Epoch 90/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7600\n",
      "Epoch 91/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7575\n",
      "Epoch 92/100\n",
      "8/8 - 0s - 9ms/step - loss: 0.7622\n",
      "Epoch 93/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7624\n",
      "Epoch 94/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7600\n",
      "Epoch 95/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7581\n",
      "Epoch 96/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7608\n",
      "Epoch 97/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7556\n",
      "Epoch 98/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7579\n",
      "Epoch 99/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7594\n",
      "Epoch 100/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7600\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step\n",
      "Testing with layers=[256, 128, 64, 32], encoding_dim=10, batch_size=32, epochs=50, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "32/32 - 3s - 84ms/step - loss: 1.0881\n",
      "Epoch 2/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.9389\n",
      "Epoch 3/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.8929\n",
      "Epoch 4/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.8629\n",
      "Epoch 5/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.8404\n",
      "Epoch 6/50\n",
      "32/32 - 0s - 5ms/step - loss: 0.8291\n",
      "Epoch 7/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.8171\n",
      "Epoch 8/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.8035\n",
      "Epoch 9/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7956\n",
      "Epoch 10/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7862\n",
      "Epoch 11/50\n",
      "32/32 - 0s - 4ms/step - loss: 0.7821\n",
      "Epoch 12/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7768\n",
      "Epoch 13/50\n",
      "32/32 - 0s - 5ms/step - loss: 0.7677\n",
      "Epoch 14/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7633\n",
      "Epoch 15/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7608\n",
      "Epoch 16/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7537\n",
      "Epoch 17/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7517\n",
      "Epoch 18/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7481\n",
      "Epoch 19/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7417\n",
      "Epoch 20/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7425\n",
      "Epoch 21/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7375\n",
      "Epoch 22/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7378\n",
      "Epoch 23/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7362\n",
      "Epoch 24/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7354\n",
      "Epoch 25/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7339\n",
      "Epoch 26/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7295\n",
      "Epoch 27/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7298\n",
      "Epoch 28/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7274\n",
      "Epoch 29/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7292\n",
      "Epoch 30/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7266\n",
      "Epoch 31/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7251\n",
      "Epoch 32/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7229\n",
      "Epoch 33/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7275\n",
      "Epoch 34/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7227\n",
      "Epoch 35/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7193\n",
      "Epoch 36/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7158\n",
      "Epoch 37/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7168\n",
      "Epoch 38/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7149\n",
      "Epoch 39/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7201\n",
      "Epoch 40/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7200\n",
      "Epoch 41/50\n",
      "32/32 - 0s - 6ms/step - loss: 0.7165\n",
      "Epoch 42/50\n",
      "32/32 - 0s - 6ms/step - loss: 0.7152\n",
      "Epoch 43/50\n",
      "32/32 - 0s - 5ms/step - loss: 0.7148\n",
      "Epoch 44/50\n",
      "32/32 - 0s - 8ms/step - loss: 0.7118\n",
      "Epoch 45/50\n",
      "32/32 - 0s - 7ms/step - loss: 0.7075\n",
      "Epoch 46/50\n",
      "32/32 - 0s - 6ms/step - loss: 0.7116\n",
      "Epoch 47/50\n",
      "32/32 - 0s - 6ms/step - loss: 0.7131\n",
      "Epoch 48/50\n",
      "32/32 - 0s - 6ms/step - loss: 0.7146\n",
      "Epoch 49/50\n",
      "32/32 - 0s - 6ms/step - loss: 0.7097\n",
      "Epoch 50/50\n",
      "32/32 - 0s - 6ms/step - loss: 0.7071\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step\n",
      "Testing with layers=[256, 128, 64, 32], encoding_dim=10, batch_size=32, epochs=50, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "32/32 - 2s - 69ms/step - loss: 1.1491\n",
      "Epoch 2/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.9889\n",
      "Epoch 3/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.9431\n",
      "Epoch 4/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.9135\n",
      "Epoch 5/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.8907\n",
      "Epoch 6/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.8795\n",
      "Epoch 7/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.8673\n",
      "Epoch 8/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.8609\n",
      "Epoch 9/50\n",
      "32/32 - 0s - 4ms/step - loss: 0.8502\n",
      "Epoch 10/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.8433\n",
      "Epoch 11/50\n",
      "32/32 - 0s - 4ms/step - loss: 0.8362\n",
      "Epoch 12/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.8320\n",
      "Epoch 13/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8276\n",
      "Epoch 14/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.8217\n",
      "Epoch 15/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8144\n",
      "Epoch 16/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8108\n",
      "Epoch 17/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8117\n",
      "Epoch 18/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8081\n",
      "Epoch 19/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8055\n",
      "Epoch 20/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8006\n",
      "Epoch 21/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8010\n",
      "Epoch 22/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7983\n",
      "Epoch 23/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7929\n",
      "Epoch 24/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7964\n",
      "Epoch 25/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7907\n",
      "Epoch 26/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7877\n",
      "Epoch 27/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7828\n",
      "Epoch 28/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7812\n",
      "Epoch 29/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7824\n",
      "Epoch 30/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7859\n",
      "Epoch 31/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7790\n",
      "Epoch 32/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7766\n",
      "Epoch 33/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7733\n",
      "Epoch 34/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7746\n",
      "Epoch 35/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7743\n",
      "Epoch 36/50\n",
      "32/32 - 0s - 4ms/step - loss: 0.7697\n",
      "Epoch 37/50\n",
      "32/32 - 0s - 5ms/step - loss: 0.7711\n",
      "Epoch 38/50\n",
      "32/32 - 0s - 4ms/step - loss: 0.7687\n",
      "Epoch 39/50\n",
      "32/32 - 0s - 4ms/step - loss: 0.7688\n",
      "Epoch 40/50\n",
      "32/32 - 0s - 5ms/step - loss: 0.7695\n",
      "Epoch 41/50\n",
      "32/32 - 0s - 5ms/step - loss: 0.7641\n",
      "Epoch 42/50\n",
      "32/32 - 0s - 5ms/step - loss: 0.7622\n",
      "Epoch 43/50\n",
      "32/32 - 0s - 7ms/step - loss: 0.7649\n",
      "Epoch 44/50\n",
      "32/32 - 0s - 8ms/step - loss: 0.7612\n",
      "Epoch 45/50\n",
      "32/32 - 0s - 5ms/step - loss: 0.7599\n",
      "Epoch 46/50\n",
      "32/32 - 0s - 6ms/step - loss: 0.7605\n",
      "Epoch 47/50\n",
      "32/32 - 0s - 5ms/step - loss: 0.7576\n",
      "Epoch 48/50\n",
      "32/32 - 0s - 4ms/step - loss: 0.7578\n",
      "Epoch 49/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7559\n",
      "Epoch 50/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7596\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step\n",
      "Testing with layers=[256, 128, 64, 32], encoding_dim=10, batch_size=32, epochs=100, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "32/32 - 2s - 59ms/step - loss: 1.1174\n",
      "Epoch 2/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.9481\n",
      "Epoch 3/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.9018\n",
      "Epoch 4/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.8724\n",
      "Epoch 5/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.8546\n",
      "Epoch 6/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.8350\n",
      "Epoch 7/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.8259\n",
      "Epoch 8/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.8115\n",
      "Epoch 9/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.8079\n",
      "Epoch 10/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7965\n",
      "Epoch 11/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7855\n",
      "Epoch 12/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7810\n",
      "Epoch 13/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7779\n",
      "Epoch 14/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7732\n",
      "Epoch 15/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7685\n",
      "Epoch 16/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7653\n",
      "Epoch 17/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7618\n",
      "Epoch 18/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7606\n",
      "Epoch 19/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7538\n",
      "Epoch 20/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7556\n",
      "Epoch 21/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7506\n",
      "Epoch 22/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7479\n",
      "Epoch 23/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7456\n",
      "Epoch 24/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7425\n",
      "Epoch 25/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7436\n",
      "Epoch 26/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7374\n",
      "Epoch 27/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7371\n",
      "Epoch 28/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7397\n",
      "Epoch 29/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7338\n",
      "Epoch 30/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7338\n",
      "Epoch 31/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7254\n",
      "Epoch 32/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7287\n",
      "Epoch 33/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7251\n",
      "Epoch 34/100\n",
      "32/32 - 0s - 5ms/step - loss: 0.7245\n",
      "Epoch 35/100\n",
      "32/32 - 0s - 5ms/step - loss: 0.7236\n",
      "Epoch 36/100\n",
      "32/32 - 0s - 6ms/step - loss: 0.7232\n",
      "Epoch 37/100\n",
      "32/32 - 0s - 6ms/step - loss: 0.7215\n",
      "Epoch 38/100\n",
      "32/32 - 0s - 6ms/step - loss: 0.7215\n",
      "Epoch 39/100\n",
      "32/32 - 0s - 5ms/step - loss: 0.7211\n",
      "Epoch 40/100\n",
      "32/32 - 0s - 5ms/step - loss: 0.7184\n",
      "Epoch 41/100\n",
      "32/32 - 0s - 5ms/step - loss: 0.7162\n",
      "Epoch 42/100\n",
      "32/32 - 0s - 6ms/step - loss: 0.7165\n",
      "Epoch 43/100\n",
      "32/32 - 0s - 6ms/step - loss: 0.7155\n",
      "Epoch 44/100\n",
      "32/32 - 0s - 5ms/step - loss: 0.7114\n",
      "Epoch 45/100\n",
      "32/32 - 0s - 6ms/step - loss: 0.7123\n",
      "Epoch 46/100\n",
      "32/32 - 0s - 6ms/step - loss: 0.7108\n",
      "Epoch 47/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7072\n",
      "Epoch 48/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7075\n",
      "Epoch 49/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7058\n",
      "Epoch 50/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7066\n",
      "Epoch 51/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7063\n",
      "Epoch 52/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7038\n",
      "Epoch 53/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7055\n",
      "Epoch 54/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7010\n",
      "Epoch 55/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7050\n",
      "Epoch 56/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.6999\n",
      "Epoch 57/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7047\n",
      "Epoch 58/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.6986\n",
      "Epoch 59/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.7007\n",
      "Epoch 60/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7020\n",
      "Epoch 61/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7033\n",
      "Epoch 62/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6999\n",
      "Epoch 63/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6967\n",
      "Epoch 64/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6971\n",
      "Epoch 65/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.6975\n",
      "Epoch 66/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6988\n",
      "Epoch 67/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.6957\n",
      "Epoch 68/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.6905\n",
      "Epoch 69/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.6925\n",
      "Epoch 70/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.6972\n",
      "Epoch 71/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.6931\n",
      "Epoch 72/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.6940\n",
      "Epoch 73/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.6928\n",
      "Epoch 74/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.6898\n",
      "Epoch 75/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.6913\n",
      "Epoch 76/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.6940\n",
      "Epoch 77/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.6881\n",
      "Epoch 78/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.6901\n",
      "Epoch 79/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.6899\n",
      "Epoch 80/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.6827\n",
      "Epoch 81/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.6893\n",
      "Epoch 82/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.6893\n",
      "Epoch 83/100\n",
      "32/32 - 0s - 6ms/step - loss: 0.6879\n",
      "Epoch 84/100\n",
      "32/32 - 0s - 5ms/step - loss: 0.6867\n",
      "Epoch 85/100\n",
      "32/32 - 0s - 9ms/step - loss: 0.6811\n",
      "Epoch 86/100\n",
      "32/32 - 0s - 6ms/step - loss: 0.6859\n",
      "Epoch 87/100\n",
      "32/32 - 0s - 5ms/step - loss: 0.6881\n",
      "Epoch 88/100\n",
      "32/32 - 0s - 5ms/step - loss: 0.6836\n",
      "Epoch 89/100\n",
      "32/32 - 0s - 7ms/step - loss: 0.6892\n",
      "Epoch 90/100\n",
      "32/32 - 0s - 6ms/step - loss: 0.6861\n",
      "Epoch 91/100\n",
      "32/32 - 0s - 6ms/step - loss: 0.6848\n",
      "Epoch 92/100\n",
      "32/32 - 0s - 5ms/step - loss: 0.6824\n",
      "Epoch 93/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.6852\n",
      "Epoch 94/100\n",
      "32/32 - 0s - 6ms/step - loss: 0.6840\n",
      "Epoch 95/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.6809\n",
      "Epoch 96/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.6847\n",
      "Epoch 97/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6813\n",
      "Epoch 98/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6790\n",
      "Epoch 99/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6832\n",
      "Epoch 100/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6855\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "Testing with layers=[256, 128, 64, 32], encoding_dim=10, batch_size=32, epochs=100, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "32/32 - 2s - 50ms/step - loss: 1.1475\n",
      "Epoch 2/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.9947\n",
      "Epoch 3/100\n",
      "32/32 - 0s - 5ms/step - loss: 0.9434\n",
      "Epoch 4/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.9195\n",
      "Epoch 5/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.9026\n",
      "Epoch 6/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.8836\n",
      "Epoch 7/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.8683\n",
      "Epoch 8/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.8591\n",
      "Epoch 9/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.8439\n",
      "Epoch 10/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.8399\n",
      "Epoch 11/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.8306\n",
      "Epoch 12/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.8287\n",
      "Epoch 13/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.8179\n",
      "Epoch 14/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.8133\n",
      "Epoch 15/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.8105\n",
      "Epoch 16/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.8035\n",
      "Epoch 17/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.8036\n",
      "Epoch 18/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.8016\n",
      "Epoch 19/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7955\n",
      "Epoch 20/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7922\n",
      "Epoch 21/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7920\n",
      "Epoch 22/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7857\n",
      "Epoch 23/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7825\n",
      "Epoch 24/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7831\n",
      "Epoch 25/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7806\n",
      "Epoch 26/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7810\n",
      "Epoch 27/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7766\n",
      "Epoch 28/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7747\n",
      "Epoch 29/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7778\n",
      "Epoch 30/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7698\n",
      "Epoch 31/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7733\n",
      "Epoch 32/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7689\n",
      "Epoch 33/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.7702\n",
      "Epoch 34/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.7684\n",
      "Epoch 35/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.7664\n",
      "Epoch 36/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7660\n",
      "Epoch 37/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7638\n",
      "Epoch 38/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7625\n",
      "Epoch 39/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7610\n",
      "Epoch 40/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.7626\n",
      "Epoch 41/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7591\n",
      "Epoch 42/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.7560\n",
      "Epoch 43/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7574\n",
      "Epoch 44/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7600\n",
      "Epoch 45/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.7537\n",
      "Epoch 46/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7527\n",
      "Epoch 47/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7544\n",
      "Epoch 48/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7517\n",
      "Epoch 49/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7500\n",
      "Epoch 50/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7518\n",
      "Epoch 51/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7478\n",
      "Epoch 52/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7493\n",
      "Epoch 53/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7473\n",
      "Epoch 54/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7495\n",
      "Epoch 55/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7451\n",
      "Epoch 56/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7446\n",
      "Epoch 57/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7440\n",
      "Epoch 58/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7498\n",
      "Epoch 59/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7449\n",
      "Epoch 60/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7436\n",
      "Epoch 61/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.7451\n",
      "Epoch 62/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7445\n",
      "Epoch 63/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7429\n",
      "Epoch 64/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7411\n",
      "Epoch 65/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7395\n",
      "Epoch 66/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7390\n",
      "Epoch 67/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7436\n",
      "Epoch 68/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7347\n",
      "Epoch 69/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7411\n",
      "Epoch 70/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7387\n",
      "Epoch 71/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7413\n",
      "Epoch 72/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7379\n",
      "Epoch 73/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7406\n",
      "Epoch 74/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7355\n",
      "Epoch 75/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7340\n",
      "Epoch 76/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7315\n",
      "Epoch 77/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7348\n",
      "Epoch 78/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7296\n",
      "Epoch 79/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7323\n",
      "Epoch 80/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7362\n",
      "Epoch 81/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7319\n",
      "Epoch 82/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7313\n",
      "Epoch 83/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7299\n",
      "Epoch 84/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7293\n",
      "Epoch 85/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7298\n",
      "Epoch 86/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7285\n",
      "Epoch 87/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7319\n",
      "Epoch 88/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7313\n",
      "Epoch 89/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7339\n",
      "Epoch 90/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7295\n",
      "Epoch 91/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7273\n",
      "Epoch 92/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7308\n",
      "Epoch 93/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7290\n",
      "Epoch 94/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7226\n",
      "Epoch 95/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7251\n",
      "Epoch 96/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7253\n",
      "Epoch 97/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7222\n",
      "Epoch 98/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.7258\n",
      "Epoch 99/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7234\n",
      "Epoch 100/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7233\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "Testing with layers=[256, 128, 64, 32], encoding_dim=10, batch_size=64, epochs=50, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "16/16 - 2s - 97ms/step - loss: 1.1565\n",
      "Epoch 2/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.9984\n",
      "Epoch 3/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.9310\n",
      "Epoch 4/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.8979\n",
      "Epoch 5/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8696\n",
      "Epoch 6/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8565\n",
      "Epoch 7/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8407\n",
      "Epoch 8/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8341\n",
      "Epoch 9/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8225\n",
      "Epoch 10/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.8100\n",
      "Epoch 11/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8034\n",
      "Epoch 12/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7967\n",
      "Epoch 13/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7930\n",
      "Epoch 14/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7884\n",
      "Epoch 15/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7811\n",
      "Epoch 16/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7776\n",
      "Epoch 17/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7752\n",
      "Epoch 18/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7669\n",
      "Epoch 19/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7646\n",
      "Epoch 20/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7599\n",
      "Epoch 21/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7575\n",
      "Epoch 22/50\n",
      "16/16 - 0s - 6ms/step - loss: 0.7554\n",
      "Epoch 23/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7514\n",
      "Epoch 24/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7467\n",
      "Epoch 25/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7487\n",
      "Epoch 26/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7477\n",
      "Epoch 27/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7419\n",
      "Epoch 28/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7412\n",
      "Epoch 29/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7357\n",
      "Epoch 30/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7344\n",
      "Epoch 31/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7323\n",
      "Epoch 32/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7305\n",
      "Epoch 33/50\n",
      "16/16 - 0s - 14ms/step - loss: 0.7257\n",
      "Epoch 34/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7291\n",
      "Epoch 35/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7245\n",
      "Epoch 36/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7224\n",
      "Epoch 37/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7233\n",
      "Epoch 38/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7194\n",
      "Epoch 39/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7208\n",
      "Epoch 40/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7180\n",
      "Epoch 41/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7162\n",
      "Epoch 42/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7139\n",
      "Epoch 43/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7128\n",
      "Epoch 44/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7107\n",
      "Epoch 45/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7067\n",
      "Epoch 46/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7093\n",
      "Epoch 47/50\n",
      "16/16 - 0s - 7ms/step - loss: 0.7100\n",
      "Epoch 48/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7065\n",
      "Epoch 49/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7032\n",
      "Epoch 50/50\n",
      "16/16 - 0s - 6ms/step - loss: 0.7053\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Testing with layers=[256, 128, 64, 32], encoding_dim=10, batch_size=64, epochs=50, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "16/16 - 2s - 126ms/step - loss: 1.2187\n",
      "Epoch 2/50\n",
      "16/16 - 0s - 3ms/step - loss: 1.0418\n",
      "Epoch 3/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.9829\n",
      "Epoch 4/50\n",
      "16/16 - 0s - 8ms/step - loss: 0.9474\n",
      "Epoch 5/50\n",
      "16/16 - 0s - 7ms/step - loss: 0.9214\n",
      "Epoch 6/50\n",
      "16/16 - 0s - 6ms/step - loss: 0.9017\n",
      "Epoch 7/50\n",
      "16/16 - 0s - 5ms/step - loss: 0.8868\n",
      "Epoch 8/50\n",
      "16/16 - 0s - 6ms/step - loss: 0.8786\n",
      "Epoch 9/50\n",
      "16/16 - 0s - 7ms/step - loss: 0.8675\n",
      "Epoch 10/50\n",
      "16/16 - 0s - 6ms/step - loss: 0.8527\n",
      "Epoch 11/50\n",
      "16/16 - 0s - 6ms/step - loss: 0.8504\n",
      "Epoch 12/50\n",
      "16/16 - 0s - 7ms/step - loss: 0.8425\n",
      "Epoch 13/50\n",
      "16/16 - 0s - 5ms/step - loss: 0.8359\n",
      "Epoch 14/50\n",
      "16/16 - 0s - 5ms/step - loss: 0.8284\n",
      "Epoch 15/50\n",
      "16/16 - 0s - 7ms/step - loss: 0.8260\n",
      "Epoch 16/50\n",
      "16/16 - 0s - 7ms/step - loss: 0.8223\n",
      "Epoch 17/50\n",
      "16/16 - 0s - 6ms/step - loss: 0.8172\n",
      "Epoch 18/50\n",
      "16/16 - 0s - 6ms/step - loss: 0.8110\n",
      "Epoch 19/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.8100\n",
      "Epoch 20/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.8057\n",
      "Epoch 21/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.8038\n",
      "Epoch 22/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7989\n",
      "Epoch 23/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7971\n",
      "Epoch 24/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7914\n",
      "Epoch 25/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7901\n",
      "Epoch 26/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7880\n",
      "Epoch 27/50\n",
      "16/16 - 0s - 6ms/step - loss: 0.7871\n",
      "Epoch 28/50\n",
      "16/16 - 0s - 13ms/step - loss: 0.7846\n",
      "Epoch 29/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7889\n",
      "Epoch 30/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7808\n",
      "Epoch 31/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7801\n",
      "Epoch 32/50\n",
      "16/16 - 0s - 5ms/step - loss: 0.7815\n",
      "Epoch 33/50\n",
      "16/16 - 0s - 5ms/step - loss: 0.7780\n",
      "Epoch 34/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7752\n",
      "Epoch 35/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7774\n",
      "Epoch 36/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7741\n",
      "Epoch 37/50\n",
      "16/16 - 0s - 7ms/step - loss: 0.7751\n",
      "Epoch 38/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7694\n",
      "Epoch 39/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7733\n",
      "Epoch 40/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7730\n",
      "Epoch 41/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7667\n",
      "Epoch 42/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7691\n",
      "Epoch 43/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7658\n",
      "Epoch 44/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7644\n",
      "Epoch 45/50\n",
      "16/16 - 0s - 9ms/step - loss: 0.7627\n",
      "Epoch 46/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7627\n",
      "Epoch 47/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7599\n",
      "Epoch 48/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7603\n",
      "Epoch 49/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7607\n",
      "Epoch 50/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7618\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "Testing with layers=[256, 128, 64, 32], encoding_dim=10, batch_size=64, epochs=100, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "16/16 - 2s - 100ms/step - loss: 1.1637\n",
      "Epoch 2/100\n",
      "16/16 - 0s - 3ms/step - loss: 1.0002\n",
      "Epoch 3/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.9381\n",
      "Epoch 4/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.9022\n",
      "Epoch 5/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8797\n",
      "Epoch 6/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.8657\n",
      "Epoch 7/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.8489\n",
      "Epoch 8/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8377\n",
      "Epoch 9/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8322\n",
      "Epoch 10/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8220\n",
      "Epoch 11/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8129\n",
      "Epoch 12/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.8067\n",
      "Epoch 13/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7996\n",
      "Epoch 14/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7933\n",
      "Epoch 15/100\n",
      "16/16 - 0s - 6ms/step - loss: 0.7899\n",
      "Epoch 16/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7834\n",
      "Epoch 17/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7786\n",
      "Epoch 18/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7723\n",
      "Epoch 19/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7712\n",
      "Epoch 20/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7682\n",
      "Epoch 21/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7626\n",
      "Epoch 22/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7637\n",
      "Epoch 23/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7611\n",
      "Epoch 24/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7548\n",
      "Epoch 25/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7547\n",
      "Epoch 26/100\n",
      "16/16 - 0s - 8ms/step - loss: 0.7495\n",
      "Epoch 27/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7495\n",
      "Epoch 28/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7495\n",
      "Epoch 29/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7417\n",
      "Epoch 30/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7437\n",
      "Epoch 31/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7417\n",
      "Epoch 32/100\n",
      "16/16 - 0s - 6ms/step - loss: 0.7379\n",
      "Epoch 33/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7366\n",
      "Epoch 34/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7347\n",
      "Epoch 35/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7344\n",
      "Epoch 36/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7309\n",
      "Epoch 37/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7262\n",
      "Epoch 38/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7313\n",
      "Epoch 39/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7243\n",
      "Epoch 40/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7246\n",
      "Epoch 41/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7219\n",
      "Epoch 42/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7192\n",
      "Epoch 43/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7224\n",
      "Epoch 44/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7201\n",
      "Epoch 45/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7159\n",
      "Epoch 46/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7182\n",
      "Epoch 47/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7106\n",
      "Epoch 48/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7139\n",
      "Epoch 49/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7109\n",
      "Epoch 50/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7117\n",
      "Epoch 51/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7120\n",
      "Epoch 52/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7100\n",
      "Epoch 53/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7123\n",
      "Epoch 54/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7068\n",
      "Epoch 55/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7072\n",
      "Epoch 56/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7064\n",
      "Epoch 57/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7084\n",
      "Epoch 58/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7065\n",
      "Epoch 59/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7041\n",
      "Epoch 60/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7030\n",
      "Epoch 61/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7018\n",
      "Epoch 62/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6994\n",
      "Epoch 63/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7000\n",
      "Epoch 64/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6989\n",
      "Epoch 65/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6983\n",
      "Epoch 66/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6979\n",
      "Epoch 67/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6990\n",
      "Epoch 68/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6982\n",
      "Epoch 69/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6976\n",
      "Epoch 70/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6954\n",
      "Epoch 71/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6951\n",
      "Epoch 72/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6937\n",
      "Epoch 73/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6936\n",
      "Epoch 74/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6946\n",
      "Epoch 75/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6886\n",
      "Epoch 76/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6941\n",
      "Epoch 77/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6897\n",
      "Epoch 78/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6900\n",
      "Epoch 79/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6904\n",
      "Epoch 80/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6885\n",
      "Epoch 81/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6913\n",
      "Epoch 82/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6915\n",
      "Epoch 83/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6867\n",
      "Epoch 84/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6873\n",
      "Epoch 85/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6873\n",
      "Epoch 86/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6862\n",
      "Epoch 87/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6848\n",
      "Epoch 88/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6880\n",
      "Epoch 89/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6872\n",
      "Epoch 90/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6819\n",
      "Epoch 91/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6840\n",
      "Epoch 92/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6861\n",
      "Epoch 93/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.6825\n",
      "Epoch 94/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.6788\n",
      "Epoch 95/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6818\n",
      "Epoch 96/100\n",
      "16/16 - 0s - 6ms/step - loss: 0.6820\n",
      "Epoch 97/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.6791\n",
      "Epoch 98/100\n",
      "16/16 - 0s - 8ms/step - loss: 0.6812\n",
      "Epoch 99/100\n",
      "16/16 - 0s - 8ms/step - loss: 0.6761\n",
      "Epoch 100/100\n",
      "16/16 - 0s - 9ms/step - loss: 0.6815\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step\n",
      "Testing with layers=[256, 128, 64, 32], encoding_dim=10, batch_size=64, epochs=100, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "16/16 - 2s - 140ms/step - loss: 1.1895\n",
      "Epoch 2/100\n",
      "16/16 - 0s - 5ms/step - loss: 1.0467\n",
      "Epoch 3/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.9844\n",
      "Epoch 4/100\n",
      "16/16 - 0s - 7ms/step - loss: 0.9503\n",
      "Epoch 5/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.9310\n",
      "Epoch 6/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.9134\n",
      "Epoch 7/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.9026\n",
      "Epoch 8/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.8893\n",
      "Epoch 9/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.8777\n",
      "Epoch 10/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.8649\n",
      "Epoch 11/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.8566\n",
      "Epoch 12/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.8522\n",
      "Epoch 13/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.8393\n",
      "Epoch 14/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.8340\n",
      "Epoch 15/100\n",
      "16/16 - 0s - 6ms/step - loss: 0.8315\n",
      "Epoch 16/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.8231\n",
      "Epoch 17/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8173\n",
      "Epoch 18/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.8171\n",
      "Epoch 19/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.8092\n",
      "Epoch 20/100\n",
      "16/16 - 0s - 7ms/step - loss: 0.8073\n",
      "Epoch 21/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.8026\n",
      "Epoch 22/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.8016\n",
      "Epoch 23/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7950\n",
      "Epoch 24/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7930\n",
      "Epoch 25/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7933\n",
      "Epoch 26/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7870\n",
      "Epoch 27/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7851\n",
      "Epoch 28/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7858\n",
      "Epoch 29/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7833\n",
      "Epoch 30/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7762\n",
      "Epoch 31/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7770\n",
      "Epoch 32/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7757\n",
      "Epoch 33/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7731\n",
      "Epoch 34/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7709\n",
      "Epoch 35/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7703\n",
      "Epoch 36/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7694\n",
      "Epoch 37/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7696\n",
      "Epoch 38/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7657\n",
      "Epoch 39/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7657\n",
      "Epoch 40/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7645\n",
      "Epoch 41/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7656\n",
      "Epoch 42/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7666\n",
      "Epoch 43/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7608\n",
      "Epoch 44/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7604\n",
      "Epoch 45/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7591\n",
      "Epoch 46/100\n",
      "16/16 - 0s - 6ms/step - loss: 0.7562\n",
      "Epoch 47/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7513\n",
      "Epoch 48/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7572\n",
      "Epoch 49/100\n",
      "16/16 - 0s - 6ms/step - loss: 0.7505\n",
      "Epoch 50/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7568\n",
      "Epoch 51/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7492\n",
      "Epoch 52/100\n",
      "16/16 - 0s - 7ms/step - loss: 0.7489\n",
      "Epoch 53/100\n",
      "16/16 - 0s - 6ms/step - loss: 0.7510\n",
      "Epoch 54/100\n",
      "16/16 - 0s - 7ms/step - loss: 0.7508\n",
      "Epoch 55/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7490\n",
      "Epoch 56/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7434\n",
      "Epoch 57/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7434\n",
      "Epoch 58/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7477\n",
      "Epoch 59/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7425\n",
      "Epoch 60/100\n",
      "16/16 - 0s - 6ms/step - loss: 0.7417\n",
      "Epoch 61/100\n",
      "16/16 - 0s - 11ms/step - loss: 0.7427\n",
      "Epoch 62/100\n",
      "16/16 - 0s - 8ms/step - loss: 0.7447\n",
      "Epoch 63/100\n",
      "16/16 - 0s - 6ms/step - loss: 0.7423\n",
      "Epoch 64/100\n",
      "16/16 - 0s - 8ms/step - loss: 0.7386\n",
      "Epoch 65/100\n",
      "16/16 - 0s - 12ms/step - loss: 0.7379\n",
      "Epoch 66/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7407\n",
      "Epoch 67/100\n",
      "16/16 - 0s - 10ms/step - loss: 0.7391\n",
      "Epoch 68/100\n",
      "16/16 - 0s - 8ms/step - loss: 0.7361\n",
      "Epoch 69/100\n",
      "16/16 - 0s - 7ms/step - loss: 0.7369\n",
      "Epoch 70/100\n",
      "16/16 - 0s - 6ms/step - loss: 0.7350\n",
      "Epoch 71/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7365\n",
      "Epoch 72/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7345\n",
      "Epoch 73/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7353\n",
      "Epoch 74/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7333\n",
      "Epoch 75/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7343\n",
      "Epoch 76/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7323\n",
      "Epoch 77/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7313\n",
      "Epoch 78/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7315\n",
      "Epoch 79/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7278\n",
      "Epoch 80/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7301\n",
      "Epoch 81/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7326\n",
      "Epoch 82/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7288\n",
      "Epoch 83/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7299\n",
      "Epoch 84/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7322\n",
      "Epoch 85/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7268\n",
      "Epoch 86/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7287\n",
      "Epoch 87/100\n",
      "16/16 - 0s - 7ms/step - loss: 0.7290\n",
      "Epoch 88/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7284\n",
      "Epoch 89/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7266\n",
      "Epoch 90/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7278\n",
      "Epoch 91/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7257\n",
      "Epoch 92/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7272\n",
      "Epoch 93/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7204\n",
      "Epoch 94/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7253\n",
      "Epoch 95/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7222\n",
      "Epoch 96/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7204\n",
      "Epoch 97/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7197\n",
      "Epoch 98/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7246\n",
      "Epoch 99/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7217\n",
      "Epoch 100/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7191\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "Testing with layers=[256, 128, 64, 32], encoding_dim=10, batch_size=128, epochs=50, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "8/8 - 36s - 5s/step - loss: 1.1894\n",
      "Epoch 2/50\n",
      "8/8 - 0s - 8ms/step - loss: 1.0541\n",
      "Epoch 3/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.9846\n",
      "Epoch 4/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.9406\n",
      "Epoch 5/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.9164\n",
      "Epoch 6/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.8905\n",
      "Epoch 7/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.8752\n",
      "Epoch 8/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.8595\n",
      "Epoch 9/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.8504\n",
      "Epoch 10/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.8400\n",
      "Epoch 11/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.8305\n",
      "Epoch 12/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.8274\n",
      "Epoch 13/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.8180\n",
      "Epoch 14/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.8133\n",
      "Epoch 15/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.8045\n",
      "Epoch 16/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.8031\n",
      "Epoch 17/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.7931\n",
      "Epoch 18/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.7901\n",
      "Epoch 19/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.7881\n",
      "Epoch 20/50\n",
      "8/8 - 0s - 10ms/step - loss: 0.7827\n",
      "Epoch 21/50\n",
      "8/8 - 0s - 8ms/step - loss: 0.7788\n",
      "Epoch 22/50\n",
      "8/8 - 0s - 8ms/step - loss: 0.7726\n",
      "Epoch 23/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.7708\n",
      "Epoch 24/50\n",
      "8/8 - 0s - 8ms/step - loss: 0.7696\n",
      "Epoch 25/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.7647\n",
      "Epoch 26/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.7624\n",
      "Epoch 27/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.7579\n",
      "Epoch 28/50\n",
      "8/8 - 0s - 9ms/step - loss: 0.7533\n",
      "Epoch 29/50\n",
      "8/8 - 0s - 8ms/step - loss: 0.7558\n",
      "Epoch 30/50\n",
      "8/8 - 0s - 8ms/step - loss: 0.7513\n",
      "Epoch 31/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.7498\n",
      "Epoch 32/50\n",
      "8/8 - 0s - 8ms/step - loss: 0.7485\n",
      "Epoch 33/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.7421\n",
      "Epoch 34/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.7413\n",
      "Epoch 35/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.7425\n",
      "Epoch 36/50\n",
      "8/8 - 0s - 8ms/step - loss: 0.7419\n",
      "Epoch 37/50\n",
      "8/8 - 0s - 9ms/step - loss: 0.7380\n",
      "Epoch 38/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.7372\n",
      "Epoch 39/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.7331\n",
      "Epoch 40/50\n",
      "8/8 - 0s - 10ms/step - loss: 0.7327\n",
      "Epoch 41/50\n",
      "8/8 - 0s - 10ms/step - loss: 0.7292\n",
      "Epoch 42/50\n",
      "8/8 - 0s - 10ms/step - loss: 0.7307\n",
      "Epoch 43/50\n",
      "8/8 - 0s - 10ms/step - loss: 0.7271\n",
      "Epoch 44/50\n",
      "8/8 - 0s - 11ms/step - loss: 0.7278\n",
      "Epoch 45/50\n",
      "8/8 - 0s - 14ms/step - loss: 0.7266\n",
      "Epoch 46/50\n",
      "8/8 - 0s - 11ms/step - loss: 0.7246\n",
      "Epoch 47/50\n",
      "8/8 - 0s - 13ms/step - loss: 0.7217\n",
      "Epoch 48/50\n",
      "8/8 - 0s - 11ms/step - loss: 0.7227\n",
      "Epoch 49/50\n",
      "8/8 - 0s - 13ms/step - loss: 0.7205\n",
      "Epoch 50/50\n",
      "8/8 - 0s - 14ms/step - loss: 0.7198\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 11ms/step\n",
      "Testing with layers=[256, 128, 64, 32], encoding_dim=10, batch_size=128, epochs=50, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "8/8 - 5s - 588ms/step - loss: 1.2461\n",
      "Epoch 2/50\n",
      "8/8 - 0s - 9ms/step - loss: 1.1245\n",
      "Epoch 3/50\n",
      "8/8 - 0s - 8ms/step - loss: 1.0434\n",
      "Epoch 4/50\n",
      "8/8 - 0s - 8ms/step - loss: 1.0018\n",
      "Epoch 5/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.9681\n",
      "Epoch 6/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.9465\n",
      "Epoch 7/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.9266\n",
      "Epoch 8/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.9118\n",
      "Epoch 9/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.8999\n",
      "Epoch 10/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.8885\n",
      "Epoch 11/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.8753\n",
      "Epoch 12/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.8727\n",
      "Epoch 13/50\n",
      "8/8 - 0s - 8ms/step - loss: 0.8633\n",
      "Epoch 14/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.8542\n",
      "Epoch 15/50\n",
      "8/8 - 0s - 8ms/step - loss: 0.8459\n",
      "Epoch 16/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.8444\n",
      "Epoch 17/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.8365\n",
      "Epoch 18/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.8296\n",
      "Epoch 19/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.8258\n",
      "Epoch 20/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.8191\n",
      "Epoch 21/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.8149\n",
      "Epoch 22/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.8127\n",
      "Epoch 23/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.8085\n",
      "Epoch 24/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.8048\n",
      "Epoch 25/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.8015\n",
      "Epoch 26/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.7984\n",
      "Epoch 27/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.7954\n",
      "Epoch 28/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.7952\n",
      "Epoch 29/50\n",
      "8/8 - 0s - 8ms/step - loss: 0.7927\n",
      "Epoch 30/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.7905\n",
      "Epoch 31/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.7883\n",
      "Epoch 32/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.7857\n",
      "Epoch 33/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.7882\n",
      "Epoch 34/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7826\n",
      "Epoch 35/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7826\n",
      "Epoch 36/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7826\n",
      "Epoch 37/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.7803\n",
      "Epoch 38/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.7829\n",
      "Epoch 39/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.7784\n",
      "Epoch 40/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.7791\n",
      "Epoch 41/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.7710\n",
      "Epoch 42/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.7703\n",
      "Epoch 43/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.7748\n",
      "Epoch 44/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.7739\n",
      "Epoch 45/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.7728\n",
      "Epoch 46/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.7753\n",
      "Epoch 47/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.7718\n",
      "Epoch 48/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.7703\n",
      "Epoch 49/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.7673\n",
      "Epoch 50/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.7682\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step\n",
      "Testing with layers=[256, 128, 64, 32], encoding_dim=10, batch_size=128, epochs=100, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "8/8 - 3s - 376ms/step - loss: 1.1863\n",
      "Epoch 2/100\n",
      "8/8 - 0s - 8ms/step - loss: 1.0594\n",
      "Epoch 3/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.9893\n",
      "Epoch 4/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.9500\n",
      "Epoch 5/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.9227\n",
      "Epoch 6/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.9002\n",
      "Epoch 7/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.8855\n",
      "Epoch 8/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8700\n",
      "Epoch 9/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.8631\n",
      "Epoch 10/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.8459\n",
      "Epoch 11/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.8377\n",
      "Epoch 12/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.8291\n",
      "Epoch 13/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.8233\n",
      "Epoch 14/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.8132\n",
      "Epoch 15/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.8072\n",
      "Epoch 16/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7996\n",
      "Epoch 17/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7930\n",
      "Epoch 18/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7852\n",
      "Epoch 19/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7820\n",
      "Epoch 20/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7738\n",
      "Epoch 21/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7749\n",
      "Epoch 22/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7725\n",
      "Epoch 23/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7657\n",
      "Epoch 24/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7599\n",
      "Epoch 25/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7587\n",
      "Epoch 26/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7556\n",
      "Epoch 27/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7542\n",
      "Epoch 28/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7518\n",
      "Epoch 29/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7481\n",
      "Epoch 30/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7475\n",
      "Epoch 31/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7462\n",
      "Epoch 32/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7439\n",
      "Epoch 33/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7440\n",
      "Epoch 34/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7400\n",
      "Epoch 35/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7356\n",
      "Epoch 36/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7354\n",
      "Epoch 37/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7369\n",
      "Epoch 38/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7317\n",
      "Epoch 39/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7331\n",
      "Epoch 40/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7283\n",
      "Epoch 41/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7263\n",
      "Epoch 42/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7275\n",
      "Epoch 43/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7238\n",
      "Epoch 44/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7252\n",
      "Epoch 45/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7241\n",
      "Epoch 46/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7248\n",
      "Epoch 47/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7196\n",
      "Epoch 48/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7220\n",
      "Epoch 49/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7196\n",
      "Epoch 50/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7195\n",
      "Epoch 51/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7175\n",
      "Epoch 52/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.7153\n",
      "Epoch 53/100\n",
      "8/8 - 0s - 10ms/step - loss: 0.7170\n",
      "Epoch 54/100\n",
      "8/8 - 0s - 10ms/step - loss: 0.7147\n",
      "Epoch 55/100\n",
      "8/8 - 0s - 10ms/step - loss: 0.7141\n",
      "Epoch 56/100\n",
      "8/8 - 0s - 12ms/step - loss: 0.7118\n",
      "Epoch 57/100\n",
      "8/8 - 0s - 14ms/step - loss: 0.7100\n",
      "Epoch 58/100\n",
      "8/8 - 0s - 11ms/step - loss: 0.7104\n",
      "Epoch 59/100\n",
      "8/8 - 0s - 14ms/step - loss: 0.7108\n",
      "Epoch 60/100\n",
      "8/8 - 0s - 14ms/step - loss: 0.7095\n",
      "Epoch 61/100\n",
      "8/8 - 0s - 18ms/step - loss: 0.7073\n",
      "Epoch 62/100\n",
      "8/8 - 0s - 25ms/step - loss: 0.7083\n",
      "Epoch 63/100\n",
      "8/8 - 0s - 17ms/step - loss: 0.7061\n",
      "Epoch 64/100\n",
      "8/8 - 0s - 14ms/step - loss: 0.7036\n",
      "Epoch 65/100\n",
      "8/8 - 0s - 12ms/step - loss: 0.7071\n",
      "Epoch 66/100\n",
      "8/8 - 0s - 12ms/step - loss: 0.7027\n",
      "Epoch 67/100\n",
      "8/8 - 0s - 11ms/step - loss: 0.7046\n",
      "Epoch 68/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.7025\n",
      "Epoch 69/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.7022\n",
      "Epoch 70/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7012\n",
      "Epoch 71/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.7008\n",
      "Epoch 72/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.6983\n",
      "Epoch 73/100\n",
      "8/8 - 0s - 9ms/step - loss: 0.6972\n",
      "Epoch 74/100\n",
      "8/8 - 0s - 13ms/step - loss: 0.7004\n",
      "Epoch 75/100\n",
      "8/8 - 0s - 14ms/step - loss: 0.6987\n",
      "Epoch 76/100\n",
      "8/8 - 0s - 11ms/step - loss: 0.6976\n",
      "Epoch 77/100\n",
      "8/8 - 0s - 13ms/step - loss: 0.6964\n",
      "Epoch 78/100\n",
      "8/8 - 0s - 9ms/step - loss: 0.6975\n",
      "Epoch 79/100\n",
      "8/8 - 0s - 11ms/step - loss: 0.6966\n",
      "Epoch 80/100\n",
      "8/8 - 0s - 12ms/step - loss: 0.6971\n",
      "Epoch 81/100\n",
      "8/8 - 0s - 10ms/step - loss: 0.6940\n",
      "Epoch 82/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.6952\n",
      "Epoch 83/100\n",
      "8/8 - 0s - 10ms/step - loss: 0.6944\n",
      "Epoch 84/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.6905\n",
      "Epoch 85/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.6906\n",
      "Epoch 86/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.6914\n",
      "Epoch 87/100\n",
      "8/8 - 0s - 15ms/step - loss: 0.6943\n",
      "Epoch 88/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.6930\n",
      "Epoch 89/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.6925\n",
      "Epoch 90/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.6901\n",
      "Epoch 91/100\n",
      "8/8 - 0s - 18ms/step - loss: 0.6882\n",
      "Epoch 92/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.6925\n",
      "Epoch 93/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.6911\n",
      "Epoch 94/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.6912\n",
      "Epoch 95/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.6881\n",
      "Epoch 96/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.6860\n",
      "Epoch 97/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.6903\n",
      "Epoch 98/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.6878\n",
      "Epoch 99/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.6850\n",
      "Epoch 100/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.6844\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step\n",
      "Testing with layers=[256, 128, 64, 32], encoding_dim=10, batch_size=128, epochs=100, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "8/8 - 2s - 306ms/step - loss: 1.2320\n",
      "Epoch 2/100\n",
      "8/8 - 0s - 5ms/step - loss: 1.1199\n",
      "Epoch 3/100\n",
      "8/8 - 0s - 4ms/step - loss: 1.0448\n",
      "Epoch 4/100\n",
      "8/8 - 0s - 5ms/step - loss: 1.0049\n",
      "Epoch 5/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.9735\n",
      "Epoch 6/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.9578\n",
      "Epoch 7/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.9371\n",
      "Epoch 8/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.9263\n",
      "Epoch 9/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.9136\n",
      "Epoch 10/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.9009\n",
      "Epoch 11/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8926\n",
      "Epoch 12/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8843\n",
      "Epoch 13/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8739\n",
      "Epoch 14/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.8696\n",
      "Epoch 15/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.8614\n",
      "Epoch 16/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.8549\n",
      "Epoch 17/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.8504\n",
      "Epoch 18/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.8458\n",
      "Epoch 19/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8403\n",
      "Epoch 20/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8382\n",
      "Epoch 21/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.8356\n",
      "Epoch 22/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8339\n",
      "Epoch 23/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.8267\n",
      "Epoch 24/100\n",
      "8/8 - 0s - 9ms/step - loss: 0.8233\n",
      "Epoch 25/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.8180\n",
      "Epoch 26/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8180\n",
      "Epoch 27/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.8142\n",
      "Epoch 28/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.8103\n",
      "Epoch 29/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.8093\n",
      "Epoch 30/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.8070\n",
      "Epoch 31/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.8060\n",
      "Epoch 32/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.8028\n",
      "Epoch 33/100\n",
      "8/8 - 0s - 9ms/step - loss: 0.8019\n",
      "Epoch 34/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7989\n",
      "Epoch 35/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.7992\n",
      "Epoch 36/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7952\n",
      "Epoch 37/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7939\n",
      "Epoch 38/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7921\n",
      "Epoch 39/100\n",
      "8/8 - 0s - 10ms/step - loss: 0.7857\n",
      "Epoch 40/100\n",
      "8/8 - 0s - 12ms/step - loss: 0.7885\n",
      "Epoch 41/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.7880\n",
      "Epoch 42/100\n",
      "8/8 - 0s - 14ms/step - loss: 0.7871\n",
      "Epoch 43/100\n",
      "8/8 - 0s - 14ms/step - loss: 0.7868\n",
      "Epoch 44/100\n",
      "8/8 - 0s - 18ms/step - loss: 0.7844\n",
      "Epoch 45/100\n",
      "8/8 - 0s - 16ms/step - loss: 0.7800\n",
      "Epoch 46/100\n",
      "8/8 - 0s - 12ms/step - loss: 0.7809\n",
      "Epoch 47/100\n",
      "8/8 - 0s - 12ms/step - loss: 0.7794\n",
      "Epoch 48/100\n",
      "8/8 - 0s - 13ms/step - loss: 0.7786\n",
      "Epoch 49/100\n",
      "8/8 - 0s - 22ms/step - loss: 0.7766\n",
      "Epoch 50/100\n",
      "8/8 - 0s - 11ms/step - loss: 0.7759\n",
      "Epoch 51/100\n",
      "8/8 - 0s - 9ms/step - loss: 0.7733\n",
      "Epoch 52/100\n",
      "8/8 - 0s - 11ms/step - loss: 0.7731\n",
      "Epoch 53/100\n",
      "8/8 - 0s - 11ms/step - loss: 0.7720\n",
      "Epoch 54/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.7734\n",
      "Epoch 55/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7716\n",
      "Epoch 56/100\n",
      "8/8 - 0s - 10ms/step - loss: 0.7691\n",
      "Epoch 57/100\n",
      "8/8 - 0s - 20ms/step - loss: 0.7687\n",
      "Epoch 58/100\n",
      "8/8 - 0s - 9ms/step - loss: 0.7666\n",
      "Epoch 59/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7663\n",
      "Epoch 60/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7697\n",
      "Epoch 61/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7684\n",
      "Epoch 62/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7642\n",
      "Epoch 63/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7641\n",
      "Epoch 64/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7639\n",
      "Epoch 65/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7615\n",
      "Epoch 66/100\n",
      "8/8 - 0s - 12ms/step - loss: 0.7639\n",
      "Epoch 67/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7577\n",
      "Epoch 68/100\n",
      "8/8 - 0s - 10ms/step - loss: 0.7576\n",
      "Epoch 69/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7575\n",
      "Epoch 70/100\n",
      "8/8 - 0s - 16ms/step - loss: 0.7582\n",
      "Epoch 71/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7566\n",
      "Epoch 72/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.7544\n",
      "Epoch 73/100\n",
      "8/8 - 0s - 10ms/step - loss: 0.7534\n",
      "Epoch 74/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7535\n",
      "Epoch 75/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7562\n",
      "Epoch 76/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7542\n",
      "Epoch 77/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7522\n",
      "Epoch 78/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7512\n",
      "Epoch 79/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7528\n",
      "Epoch 80/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7455\n",
      "Epoch 81/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7478\n",
      "Epoch 82/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7516\n",
      "Epoch 83/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7510\n",
      "Epoch 84/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7512\n",
      "Epoch 85/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7450\n",
      "Epoch 86/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7453\n",
      "Epoch 87/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7425\n",
      "Epoch 88/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7442\n",
      "Epoch 89/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7457\n",
      "Epoch 90/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7426\n",
      "Epoch 91/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7443\n",
      "Epoch 92/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7378\n",
      "Epoch 93/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7361\n",
      "Epoch 94/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7401\n",
      "Epoch 95/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7458\n",
      "Epoch 96/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7427\n",
      "Epoch 97/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7393\n",
      "Epoch 98/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7391\n",
      "Epoch 99/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7417\n",
      "Epoch 100/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7417\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "Testing with layers=[256, 128, 64, 32], encoding_dim=12, batch_size=32, epochs=50, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "32/32 - 4s - 112ms/step - loss: 1.1270\n",
      "Epoch 2/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.9540\n",
      "Epoch 3/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.9008\n",
      "Epoch 4/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.8676\n",
      "Epoch 5/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8513\n",
      "Epoch 6/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8312\n",
      "Epoch 7/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8153\n",
      "Epoch 8/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8049\n",
      "Epoch 9/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7960\n",
      "Epoch 10/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7824\n",
      "Epoch 11/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7795\n",
      "Epoch 12/50\n",
      "32/32 - 0s - 7ms/step - loss: 0.7680\n",
      "Epoch 13/50\n",
      "32/32 - 0s - 4ms/step - loss: 0.7616\n",
      "Epoch 14/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7552\n",
      "Epoch 15/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7560\n",
      "Epoch 16/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7503\n",
      "Epoch 17/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7423\n",
      "Epoch 18/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7433\n",
      "Epoch 19/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7387\n",
      "Epoch 20/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7322\n",
      "Epoch 21/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7338\n",
      "Epoch 22/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7297\n",
      "Epoch 23/50\n",
      "32/32 - 0s - 4ms/step - loss: 0.7259\n",
      "Epoch 24/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7216\n",
      "Epoch 25/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7234\n",
      "Epoch 26/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7146\n",
      "Epoch 27/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7140\n",
      "Epoch 28/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7172\n",
      "Epoch 29/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7126\n",
      "Epoch 30/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7096\n",
      "Epoch 31/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7104\n",
      "Epoch 32/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7054\n",
      "Epoch 33/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7022\n",
      "Epoch 34/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7010\n",
      "Epoch 35/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7008\n",
      "Epoch 36/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7032\n",
      "Epoch 37/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.6960\n",
      "Epoch 38/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.6931\n",
      "Epoch 39/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.6987\n",
      "Epoch 40/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.6975\n",
      "Epoch 41/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.6867\n",
      "Epoch 42/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.6907\n",
      "Epoch 43/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.6882\n",
      "Epoch 44/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.6904\n",
      "Epoch 45/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.6902\n",
      "Epoch 46/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.6884\n",
      "Epoch 47/50\n",
      "32/32 - 0s - 4ms/step - loss: 0.6822\n",
      "Epoch 48/50\n",
      "32/32 - 0s - 6ms/step - loss: 0.6903\n",
      "Epoch 49/50\n",
      "32/32 - 0s - 6ms/step - loss: 0.6818\n",
      "Epoch 50/50\n",
      "32/32 - 0s - 5ms/step - loss: 0.6822\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step\n",
      "Testing with layers=[256, 128, 64, 32], encoding_dim=12, batch_size=32, epochs=50, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "32/32 - 3s - 101ms/step - loss: 1.1442\n",
      "Epoch 2/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.9823\n",
      "Epoch 3/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.9317\n",
      "Epoch 4/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.9052\n",
      "Epoch 5/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8840\n",
      "Epoch 6/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8693\n",
      "Epoch 7/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8542\n",
      "Epoch 8/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8499\n",
      "Epoch 9/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8433\n",
      "Epoch 10/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8345\n",
      "Epoch 11/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8270\n",
      "Epoch 12/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8179\n",
      "Epoch 13/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8163\n",
      "Epoch 14/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8112\n",
      "Epoch 15/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8005\n",
      "Epoch 16/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.8036\n",
      "Epoch 17/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7909\n",
      "Epoch 18/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7958\n",
      "Epoch 19/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7866\n",
      "Epoch 20/50\n",
      "32/32 - 0s - 5ms/step - loss: 0.7843\n",
      "Epoch 21/50\n",
      "32/32 - 0s - 4ms/step - loss: 0.7812\n",
      "Epoch 22/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7831\n",
      "Epoch 23/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7795\n",
      "Epoch 24/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7739\n",
      "Epoch 25/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7721\n",
      "Epoch 26/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7699\n",
      "Epoch 27/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7685\n",
      "Epoch 28/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7600\n",
      "Epoch 29/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7617\n",
      "Epoch 30/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7625\n",
      "Epoch 31/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7591\n",
      "Epoch 32/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7559\n",
      "Epoch 33/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7594\n",
      "Epoch 34/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7506\n",
      "Epoch 35/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7516\n",
      "Epoch 36/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7555\n",
      "Epoch 37/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7559\n",
      "Epoch 38/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7512\n",
      "Epoch 39/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7463\n",
      "Epoch 40/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7468\n",
      "Epoch 41/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7449\n",
      "Epoch 42/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7433\n",
      "Epoch 43/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7409\n",
      "Epoch 44/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7399\n",
      "Epoch 45/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7413\n",
      "Epoch 46/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7511\n",
      "Epoch 47/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7452\n",
      "Epoch 48/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7339\n",
      "Epoch 49/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7391\n",
      "Epoch 50/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7322\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step\n",
      "Testing with layers=[256, 128, 64, 32], encoding_dim=12, batch_size=32, epochs=100, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "32/32 - 3s - 80ms/step - loss: 1.1032\n",
      "Epoch 2/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.9406\n",
      "Epoch 3/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.8918\n",
      "Epoch 4/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.8581\n",
      "Epoch 5/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.8354\n",
      "Epoch 6/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.8137\n",
      "Epoch 7/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.8003\n",
      "Epoch 8/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7924\n",
      "Epoch 9/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7796\n",
      "Epoch 10/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7688\n",
      "Epoch 11/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7638\n",
      "Epoch 12/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7497\n",
      "Epoch 13/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7484\n",
      "Epoch 14/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7434\n",
      "Epoch 15/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7412\n",
      "Epoch 16/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7359\n",
      "Epoch 17/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7300\n",
      "Epoch 18/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7323\n",
      "Epoch 19/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7266\n",
      "Epoch 20/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7234\n",
      "Epoch 21/100\n",
      "32/32 - 0s - 7ms/step - loss: 0.7223\n",
      "Epoch 22/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7211\n",
      "Epoch 23/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.7162\n",
      "Epoch 24/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7138\n",
      "Epoch 25/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7126\n",
      "Epoch 26/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7130\n",
      "Epoch 27/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7081\n",
      "Epoch 28/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7057\n",
      "Epoch 29/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7088\n",
      "Epoch 30/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7046\n",
      "Epoch 31/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7036\n",
      "Epoch 32/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7044\n",
      "Epoch 33/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7028\n",
      "Epoch 34/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6976\n",
      "Epoch 35/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6979\n",
      "Epoch 36/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7003\n",
      "Epoch 37/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6935\n",
      "Epoch 38/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6914\n",
      "Epoch 39/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6912\n",
      "Epoch 40/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6901\n",
      "Epoch 41/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6917\n",
      "Epoch 42/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6879\n",
      "Epoch 43/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6898\n",
      "Epoch 44/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.6875\n",
      "Epoch 45/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.6874\n",
      "Epoch 46/100\n",
      "32/32 - 0s - 5ms/step - loss: 0.6833\n",
      "Epoch 47/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.6859\n",
      "Epoch 48/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.6869\n",
      "Epoch 49/100\n",
      "32/32 - 0s - 5ms/step - loss: 0.6814\n",
      "Epoch 50/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.6802\n",
      "Epoch 51/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.6810\n",
      "Epoch 52/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.6806\n",
      "Epoch 53/100\n",
      "32/32 - 0s - 5ms/step - loss: 0.6809\n",
      "Epoch 54/100\n",
      "32/32 - 0s - 5ms/step - loss: 0.6815\n",
      "Epoch 55/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.6756\n",
      "Epoch 56/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.6794\n",
      "Epoch 57/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.6778\n",
      "Epoch 58/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.6782\n",
      "Epoch 59/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6766\n",
      "Epoch 60/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6753\n",
      "Epoch 61/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6756\n",
      "Epoch 62/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.6774\n",
      "Epoch 63/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6728\n",
      "Epoch 64/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6717\n",
      "Epoch 65/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6716\n",
      "Epoch 66/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6747\n",
      "Epoch 67/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6704\n",
      "Epoch 68/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6732\n",
      "Epoch 69/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6666\n",
      "Epoch 70/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6727\n",
      "Epoch 71/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6715\n",
      "Epoch 72/100\n",
      "32/32 - 0s - 5ms/step - loss: 0.6699\n",
      "Epoch 73/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6684\n",
      "Epoch 74/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6690\n",
      "Epoch 75/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6691\n",
      "Epoch 76/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6718\n",
      "Epoch 77/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6700\n",
      "Epoch 78/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.6684\n",
      "Epoch 79/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6675\n",
      "Epoch 80/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6614\n",
      "Epoch 81/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6635\n",
      "Epoch 82/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6633\n",
      "Epoch 83/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6625\n",
      "Epoch 84/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6666\n",
      "Epoch 85/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6644\n",
      "Epoch 86/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6624\n",
      "Epoch 87/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6585\n",
      "Epoch 88/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6619\n",
      "Epoch 89/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6605\n",
      "Epoch 90/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6626\n",
      "Epoch 91/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6631\n",
      "Epoch 92/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6654\n",
      "Epoch 93/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6599\n",
      "Epoch 94/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6627\n",
      "Epoch 95/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6636\n",
      "Epoch 96/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6614\n",
      "Epoch 97/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6614\n",
      "Epoch 98/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6649\n",
      "Epoch 99/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.6633\n",
      "Epoch 100/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.6610\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "Testing with layers=[256, 128, 64, 32], encoding_dim=12, batch_size=32, epochs=100, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "32/32 - 3s - 78ms/step - loss: 1.1205\n",
      "Epoch 2/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.9775\n",
      "Epoch 3/100\n",
      "32/32 - 0s - 5ms/step - loss: 0.9329\n",
      "Epoch 4/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.9008\n",
      "Epoch 5/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.8835\n",
      "Epoch 6/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.8646\n",
      "Epoch 7/100\n",
      "32/32 - 0s - 5ms/step - loss: 0.8565\n",
      "Epoch 8/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.8466\n",
      "Epoch 9/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.8397\n",
      "Epoch 10/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.8301\n",
      "Epoch 11/100\n",
      "32/32 - 0s - 7ms/step - loss: 0.8228\n",
      "Epoch 12/100\n",
      "32/32 - 0s - 6ms/step - loss: 0.8152\n",
      "Epoch 13/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.8124\n",
      "Epoch 14/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.8061\n",
      "Epoch 15/100\n",
      "32/32 - 0s - 5ms/step - loss: 0.8029\n",
      "Epoch 16/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7986\n",
      "Epoch 17/100\n",
      "32/32 - 0s - 8ms/step - loss: 0.7959\n",
      "Epoch 18/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7961\n",
      "Epoch 19/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7878\n",
      "Epoch 20/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7833\n",
      "Epoch 21/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7805\n",
      "Epoch 22/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7801\n",
      "Epoch 23/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7784\n",
      "Epoch 24/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7788\n",
      "Epoch 25/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7744\n",
      "Epoch 26/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7685\n",
      "Epoch 27/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7693\n",
      "Epoch 28/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7647\n",
      "Epoch 29/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7601\n",
      "Epoch 30/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7581\n",
      "Epoch 31/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7587\n",
      "Epoch 32/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7575\n",
      "Epoch 33/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7525\n",
      "Epoch 34/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7533\n",
      "Epoch 35/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7495\n",
      "Epoch 36/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7485\n",
      "Epoch 37/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7461\n",
      "Epoch 38/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7486\n",
      "Epoch 39/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7493\n",
      "Epoch 40/100\n",
      "32/32 - 0s - 5ms/step - loss: 0.7440\n",
      "Epoch 41/100\n",
      "32/32 - 0s - 5ms/step - loss: 0.7417\n",
      "Epoch 42/100\n",
      "32/32 - 0s - 5ms/step - loss: 0.7428\n",
      "Epoch 43/100\n",
      "32/32 - 0s - 6ms/step - loss: 0.7391\n",
      "Epoch 44/100\n",
      "32/32 - 0s - 6ms/step - loss: 0.7397\n",
      "Epoch 45/100\n",
      "32/32 - 0s - 6ms/step - loss: 0.7392\n",
      "Epoch 46/100\n",
      "32/32 - 0s - 6ms/step - loss: 0.7418\n",
      "Epoch 47/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7393\n",
      "Epoch 48/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.7379\n",
      "Epoch 49/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.7352\n",
      "Epoch 50/100\n",
      "32/32 - 0s - 5ms/step - loss: 0.7352\n",
      "Epoch 51/100\n",
      "32/32 - 0s - 5ms/step - loss: 0.7335\n",
      "Epoch 52/100\n",
      "32/32 - 0s - 5ms/step - loss: 0.7374\n",
      "Epoch 53/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7328\n",
      "Epoch 54/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7308\n",
      "Epoch 55/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7280\n",
      "Epoch 56/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7294\n",
      "Epoch 57/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7287\n",
      "Epoch 58/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7285\n",
      "Epoch 59/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7254\n",
      "Epoch 60/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7280\n",
      "Epoch 61/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.7258\n",
      "Epoch 62/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7324\n",
      "Epoch 63/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7247\n",
      "Epoch 64/100\n",
      "32/32 - 0s - 10ms/step - loss: 0.7206\n",
      "Epoch 65/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7215\n",
      "Epoch 66/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7266\n",
      "Epoch 67/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7225\n",
      "Epoch 68/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.7239\n",
      "Epoch 69/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.7200\n",
      "Epoch 70/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7209\n",
      "Epoch 71/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7214\n",
      "Epoch 72/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7216\n",
      "Epoch 73/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7197\n",
      "Epoch 74/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7167\n",
      "Epoch 75/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7201\n",
      "Epoch 76/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7188\n",
      "Epoch 77/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7160\n",
      "Epoch 78/100\n",
      "32/32 - 0s - 5ms/step - loss: 0.7173\n",
      "Epoch 79/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7208\n",
      "Epoch 80/100\n",
      "32/32 - 0s - 5ms/step - loss: 0.7179\n",
      "Epoch 81/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.7186\n",
      "Epoch 82/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7181\n",
      "Epoch 83/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7154\n",
      "Epoch 84/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7208\n",
      "Epoch 85/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7171\n",
      "Epoch 86/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7195\n",
      "Epoch 87/100\n",
      "32/32 - 0s - 6ms/step - loss: 0.7137\n",
      "Epoch 88/100\n",
      "32/32 - 0s - 6ms/step - loss: 0.7142\n",
      "Epoch 89/100\n",
      "32/32 - 0s - 6ms/step - loss: 0.7165\n",
      "Epoch 90/100\n",
      "32/32 - 0s - 6ms/step - loss: 0.7146\n",
      "Epoch 91/100\n",
      "32/32 - 0s - 6ms/step - loss: 0.7179\n",
      "Epoch 92/100\n",
      "32/32 - 0s - 6ms/step - loss: 0.7147\n",
      "Epoch 93/100\n",
      "32/32 - 0s - 6ms/step - loss: 0.7148\n",
      "Epoch 94/100\n",
      "32/32 - 0s - 5ms/step - loss: 0.7132\n",
      "Epoch 95/100\n",
      "32/32 - 0s - 5ms/step - loss: 0.7087\n",
      "Epoch 96/100\n",
      "32/32 - 0s - 5ms/step - loss: 0.7133\n",
      "Epoch 97/100\n",
      "32/32 - 0s - 11ms/step - loss: 0.7134\n",
      "Epoch 98/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7038\n",
      "Epoch 99/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.7136\n",
      "Epoch 100/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7113\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step\n",
      "Testing with layers=[256, 128, 64, 32], encoding_dim=12, batch_size=64, epochs=50, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "16/16 - 3s - 181ms/step - loss: 1.1711\n",
      "Epoch 2/50\n",
      "16/16 - 0s - 5ms/step - loss: 1.0104\n",
      "Epoch 3/50\n",
      "16/16 - 0s - 5ms/step - loss: 0.9469\n",
      "Epoch 4/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.9110\n",
      "Epoch 5/50\n",
      "16/16 - 0s - 10ms/step - loss: 0.8877\n",
      "Epoch 6/50\n",
      "16/16 - 0s - 6ms/step - loss: 0.8711\n",
      "Epoch 7/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.8554\n",
      "Epoch 8/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.8425\n",
      "Epoch 9/50\n",
      "16/16 - 0s - 5ms/step - loss: 0.8273\n",
      "Epoch 10/50\n",
      "16/16 - 0s - 5ms/step - loss: 0.8184\n",
      "Epoch 11/50\n",
      "16/16 - 0s - 5ms/step - loss: 0.8106\n",
      "Epoch 12/50\n",
      "16/16 - 0s - 5ms/step - loss: 0.8006\n",
      "Epoch 13/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7958\n",
      "Epoch 14/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7853\n",
      "Epoch 15/50\n",
      "16/16 - 0s - 5ms/step - loss: 0.7827\n",
      "Epoch 16/50\n",
      "16/16 - 0s - 7ms/step - loss: 0.7746\n",
      "Epoch 17/50\n",
      "16/16 - 0s - 7ms/step - loss: 0.7674\n",
      "Epoch 18/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7609\n",
      "Epoch 19/50\n",
      "16/16 - 0s - 5ms/step - loss: 0.7581\n",
      "Epoch 20/50\n",
      "16/16 - 0s - 5ms/step - loss: 0.7508\n",
      "Epoch 21/50\n",
      "16/16 - 0s - 5ms/step - loss: 0.7496\n",
      "Epoch 22/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7464\n",
      "Epoch 23/50\n",
      "16/16 - 0s - 5ms/step - loss: 0.7393\n",
      "Epoch 24/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7343\n",
      "Epoch 25/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7326\n",
      "Epoch 26/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7278\n",
      "Epoch 27/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7263\n",
      "Epoch 28/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7227\n",
      "Epoch 29/50\n",
      "16/16 - 0s - 5ms/step - loss: 0.7214\n",
      "Epoch 30/50\n",
      "16/16 - 0s - 6ms/step - loss: 0.7173\n",
      "Epoch 31/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7162\n",
      "Epoch 32/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7156\n",
      "Epoch 33/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7107\n",
      "Epoch 34/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7079\n",
      "Epoch 35/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7090\n",
      "Epoch 36/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7041\n",
      "Epoch 37/50\n",
      "16/16 - 0s - 5ms/step - loss: 0.7014\n",
      "Epoch 38/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7001\n",
      "Epoch 39/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.6993\n",
      "Epoch 40/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7017\n",
      "Epoch 41/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7003\n",
      "Epoch 42/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.6928\n",
      "Epoch 43/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.6963\n",
      "Epoch 44/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.6920\n",
      "Epoch 45/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.6905\n",
      "Epoch 46/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.6910\n",
      "Epoch 47/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.6861\n",
      "Epoch 48/50\n",
      "16/16 - 0s - 6ms/step - loss: 0.6856\n",
      "Epoch 49/50\n",
      "16/16 - 0s - 9ms/step - loss: 0.6897\n",
      "Epoch 50/50\n",
      "16/16 - 0s - 7ms/step - loss: 0.6843\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step\n",
      "Testing with layers=[256, 128, 64, 32], encoding_dim=12, batch_size=64, epochs=50, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "16/16 - 2s - 154ms/step - loss: 1.2062\n",
      "Epoch 2/50\n",
      "16/16 - 0s - 5ms/step - loss: 1.0470\n",
      "Epoch 3/50\n",
      "16/16 - 0s - 5ms/step - loss: 0.9762\n",
      "Epoch 4/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.9427\n",
      "Epoch 5/50\n",
      "16/16 - 0s - 5ms/step - loss: 0.9233\n",
      "Epoch 6/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.9052\n",
      "Epoch 7/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.8915\n",
      "Epoch 8/50\n",
      "16/16 - 0s - 5ms/step - loss: 0.8810\n",
      "Epoch 9/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.8681\n",
      "Epoch 10/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.8544\n",
      "Epoch 11/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.8528\n",
      "Epoch 12/50\n",
      "16/16 - 0s - 5ms/step - loss: 0.8456\n",
      "Epoch 13/50\n",
      "16/16 - 0s - 5ms/step - loss: 0.8423\n",
      "Epoch 14/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.8273\n",
      "Epoch 15/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.8246\n",
      "Epoch 16/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.8173\n",
      "Epoch 17/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.8089\n",
      "Epoch 18/50\n",
      "16/16 - 0s - 5ms/step - loss: 0.8111\n",
      "Epoch 19/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.8069\n",
      "Epoch 20/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.8033\n",
      "Epoch 21/50\n",
      "16/16 - 0s - 9ms/step - loss: 0.8012\n",
      "Epoch 22/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7959\n",
      "Epoch 23/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7921\n",
      "Epoch 24/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7905\n",
      "Epoch 25/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7924\n",
      "Epoch 26/50\n",
      "16/16 - 0s - 6ms/step - loss: 0.7808\n",
      "Epoch 27/50\n",
      "16/16 - 0s - 5ms/step - loss: 0.7831\n",
      "Epoch 28/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7816\n",
      "Epoch 29/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7764\n",
      "Epoch 30/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7710\n",
      "Epoch 31/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7724\n",
      "Epoch 32/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7730\n",
      "Epoch 33/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7668\n",
      "Epoch 34/50\n",
      "16/16 - 0s - 5ms/step - loss: 0.7663\n",
      "Epoch 35/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7612\n",
      "Epoch 36/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7615\n",
      "Epoch 37/50\n",
      "16/16 - 0s - 9ms/step - loss: 0.7659\n",
      "Epoch 38/50\n",
      "16/16 - 0s - 5ms/step - loss: 0.7602\n",
      "Epoch 39/50\n",
      "16/16 - 0s - 5ms/step - loss: 0.7647\n",
      "Epoch 40/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7594\n",
      "Epoch 41/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7541\n",
      "Epoch 42/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7508\n",
      "Epoch 43/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7505\n",
      "Epoch 44/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7572\n",
      "Epoch 45/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7521\n",
      "Epoch 46/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7474\n",
      "Epoch 47/50\n",
      "16/16 - 0s - 5ms/step - loss: 0.7459\n",
      "Epoch 48/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7472\n",
      "Epoch 49/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7470\n",
      "Epoch 50/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7488\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step\n",
      "Testing with layers=[256, 128, 64, 32], encoding_dim=12, batch_size=64, epochs=100, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "16/16 - 4s - 244ms/step - loss: 1.1523\n",
      "Epoch 2/100\n",
      "16/16 - 0s - 30ms/step - loss: 0.9905\n",
      "Epoch 3/100\n",
      "16/16 - 0s - 24ms/step - loss: 0.9235\n",
      "Epoch 4/100\n",
      "16/16 - 0s - 22ms/step - loss: 0.8878\n",
      "Epoch 5/100\n",
      "16/16 - 1s - 31ms/step - loss: 0.8663\n",
      "Epoch 6/100\n",
      "16/16 - 0s - 30ms/step - loss: 0.8520\n",
      "Epoch 7/100\n",
      "16/16 - 1s - 38ms/step - loss: 0.8358\n",
      "Epoch 8/100\n",
      "16/16 - 0s - 22ms/step - loss: 0.8236\n",
      "Epoch 9/100\n",
      "16/16 - 0s - 22ms/step - loss: 0.8131\n",
      "Epoch 10/100\n",
      "16/16 - 1s - 69ms/step - loss: 0.8072\n",
      "Epoch 11/100\n",
      "16/16 - 1s - 34ms/step - loss: 0.7953\n",
      "Epoch 12/100\n",
      "16/16 - 1s - 50ms/step - loss: 0.7844\n",
      "Epoch 13/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7806\n",
      "Epoch 14/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7672\n",
      "Epoch 15/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7660\n",
      "Epoch 16/100\n",
      "16/16 - 0s - 6ms/step - loss: 0.7580\n",
      "Epoch 17/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7552\n",
      "Epoch 18/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7504\n",
      "Epoch 19/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7455\n",
      "Epoch 20/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7429\n",
      "Epoch 21/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7384\n",
      "Epoch 22/100\n",
      "16/16 - 0s - 6ms/step - loss: 0.7348\n",
      "Epoch 23/100\n",
      "16/16 - 0s - 6ms/step - loss: 0.7326\n",
      "Epoch 24/100\n",
      "16/16 - 0s - 6ms/step - loss: 0.7306\n",
      "Epoch 25/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7268\n",
      "Epoch 26/100\n",
      "16/16 - 0s - 9ms/step - loss: 0.7254\n",
      "Epoch 27/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7198\n",
      "Epoch 28/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7177\n",
      "Epoch 29/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7139\n",
      "Epoch 30/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7155\n",
      "Epoch 31/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7146\n",
      "Epoch 32/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7097\n",
      "Epoch 33/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7074\n",
      "Epoch 34/100\n",
      "16/16 - 0s - 7ms/step - loss: 0.7069\n",
      "Epoch 35/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7028\n",
      "Epoch 36/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7063\n",
      "Epoch 37/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7022\n",
      "Epoch 38/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7007\n",
      "Epoch 39/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6992\n",
      "Epoch 40/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.6971\n",
      "Epoch 41/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6950\n",
      "Epoch 42/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.6955\n",
      "Epoch 43/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.6958\n",
      "Epoch 44/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6940\n",
      "Epoch 45/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6913\n",
      "Epoch 46/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6905\n",
      "Epoch 47/100\n",
      "16/16 - 0s - 9ms/step - loss: 0.6920\n",
      "Epoch 48/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.6902\n",
      "Epoch 49/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6913\n",
      "Epoch 50/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6909\n",
      "Epoch 51/100\n",
      "16/16 - 0s - 6ms/step - loss: 0.6845\n",
      "Epoch 52/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.6853\n",
      "Epoch 53/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.6843\n",
      "Epoch 54/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.6828\n",
      "Epoch 55/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6845\n",
      "Epoch 56/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6829\n",
      "Epoch 57/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6789\n",
      "Epoch 58/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6834\n",
      "Epoch 59/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6783\n",
      "Epoch 60/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.6802\n",
      "Epoch 61/100\n",
      "16/16 - 0s - 7ms/step - loss: 0.6794\n",
      "Epoch 62/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.6771\n",
      "Epoch 63/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6776\n",
      "Epoch 64/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6726\n",
      "Epoch 65/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6790\n",
      "Epoch 66/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6775\n",
      "Epoch 67/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6729\n",
      "Epoch 68/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6734\n",
      "Epoch 69/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6729\n",
      "Epoch 70/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6717\n",
      "Epoch 71/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6722\n",
      "Epoch 72/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6694\n",
      "Epoch 73/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6678\n",
      "Epoch 74/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6650\n",
      "Epoch 75/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6645\n",
      "Epoch 76/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6675\n",
      "Epoch 77/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.6672\n",
      "Epoch 78/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.6658\n",
      "Epoch 79/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6645\n",
      "Epoch 80/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6655\n",
      "Epoch 81/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6633\n",
      "Epoch 82/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6651\n",
      "Epoch 83/100\n",
      "16/16 - 0s - 6ms/step - loss: 0.6632\n",
      "Epoch 84/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.6618\n",
      "Epoch 85/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.6664\n",
      "Epoch 86/100\n",
      "16/16 - 0s - 7ms/step - loss: 0.6600\n",
      "Epoch 87/100\n",
      "16/16 - 0s - 7ms/step - loss: 0.6597\n",
      "Epoch 88/100\n",
      "16/16 - 0s - 7ms/step - loss: 0.6632\n",
      "Epoch 89/100\n",
      "16/16 - 0s - 6ms/step - loss: 0.6630\n",
      "Epoch 90/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.6628\n",
      "Epoch 91/100\n",
      "16/16 - 0s - 6ms/step - loss: 0.6591\n",
      "Epoch 92/100\n",
      "16/16 - 0s - 12ms/step - loss: 0.6586\n",
      "Epoch 93/100\n",
      "16/16 - 0s - 8ms/step - loss: 0.6591\n",
      "Epoch 94/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.6600\n",
      "Epoch 95/100\n",
      "16/16 - 0s - 8ms/step - loss: 0.6562\n",
      "Epoch 96/100\n",
      "16/16 - 0s - 7ms/step - loss: 0.6561\n",
      "Epoch 97/100\n",
      "16/16 - 0s - 10ms/step - loss: 0.6587\n",
      "Epoch 98/100\n",
      "16/16 - 0s - 7ms/step - loss: 0.6590\n",
      "Epoch 99/100\n",
      "16/16 - 0s - 6ms/step - loss: 0.6541\n",
      "Epoch 100/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.6565\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 28ms/step\n",
      "Testing with layers=[256, 128, 64, 32], encoding_dim=12, batch_size=64, epochs=100, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "16/16 - 7s - 425ms/step - loss: 1.1757\n",
      "Epoch 2/100\n",
      "16/16 - 0s - 4ms/step - loss: 1.0322\n",
      "Epoch 3/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.9712\n",
      "Epoch 4/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.9441\n",
      "Epoch 5/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.9201\n",
      "Epoch 6/100\n",
      "16/16 - 0s - 6ms/step - loss: 0.9052\n",
      "Epoch 7/100\n",
      "16/16 - 0s - 9ms/step - loss: 0.8933\n",
      "Epoch 8/100\n",
      "16/16 - 0s - 7ms/step - loss: 0.8750\n",
      "Epoch 9/100\n",
      "16/16 - 0s - 8ms/step - loss: 0.8637\n",
      "Epoch 10/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.8570\n",
      "Epoch 11/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.8480\n",
      "Epoch 12/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.8436\n",
      "Epoch 13/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.8293\n",
      "Epoch 14/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.8275\n",
      "Epoch 15/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.8192\n",
      "Epoch 16/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.8162\n",
      "Epoch 17/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.8126\n",
      "Epoch 18/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.8061\n",
      "Epoch 19/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.8044\n",
      "Epoch 20/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7984\n",
      "Epoch 21/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7967\n",
      "Epoch 22/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7941\n",
      "Epoch 23/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7889\n",
      "Epoch 24/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7858\n",
      "Epoch 25/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7861\n",
      "Epoch 26/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7834\n",
      "Epoch 27/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7819\n",
      "Epoch 28/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7784\n",
      "Epoch 29/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7715\n",
      "Epoch 30/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7719\n",
      "Epoch 31/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7734\n",
      "Epoch 32/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7710\n",
      "Epoch 33/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7643\n",
      "Epoch 34/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7601\n",
      "Epoch 35/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7643\n",
      "Epoch 36/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7616\n",
      "Epoch 37/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7587\n",
      "Epoch 38/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7573\n",
      "Epoch 39/100\n",
      "16/16 - 0s - 7ms/step - loss: 0.7569\n",
      "Epoch 40/100\n",
      "16/16 - 0s - 6ms/step - loss: 0.7533\n",
      "Epoch 41/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7530\n",
      "Epoch 42/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7540\n",
      "Epoch 43/100\n",
      "16/16 - 0s - 7ms/step - loss: 0.7515\n",
      "Epoch 44/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7470\n",
      "Epoch 45/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7512\n",
      "Epoch 46/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7492\n",
      "Epoch 47/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7435\n",
      "Epoch 48/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7466\n",
      "Epoch 49/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7427\n",
      "Epoch 50/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7410\n",
      "Epoch 51/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7390\n",
      "Epoch 52/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7397\n",
      "Epoch 53/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7446\n",
      "Epoch 54/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7422\n",
      "Epoch 55/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7380\n",
      "Epoch 56/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7413\n",
      "Epoch 57/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7436\n",
      "Epoch 58/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7343\n",
      "Epoch 59/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7372\n",
      "Epoch 60/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7355\n",
      "Epoch 61/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7350\n",
      "Epoch 62/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7316\n",
      "Epoch 63/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7329\n",
      "Epoch 64/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7369\n",
      "Epoch 65/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7359\n",
      "Epoch 66/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7347\n",
      "Epoch 67/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7287\n",
      "Epoch 68/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7311\n",
      "Epoch 69/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7313\n",
      "Epoch 70/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7319\n",
      "Epoch 71/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7259\n",
      "Epoch 72/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7261\n",
      "Epoch 73/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7290\n",
      "Epoch 74/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7276\n",
      "Epoch 75/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7287\n",
      "Epoch 76/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7257\n",
      "Epoch 77/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7277\n",
      "Epoch 78/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7243\n",
      "Epoch 79/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7229\n",
      "Epoch 80/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7221\n",
      "Epoch 81/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7258\n",
      "Epoch 82/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7195\n",
      "Epoch 83/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7223\n",
      "Epoch 84/100\n",
      "16/16 - 0s - 10ms/step - loss: 0.7230\n",
      "Epoch 85/100\n",
      "16/16 - 0s - 6ms/step - loss: 0.7170\n",
      "Epoch 86/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7217\n",
      "Epoch 87/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7234\n",
      "Epoch 88/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7259\n",
      "Epoch 89/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7219\n",
      "Epoch 90/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7204\n",
      "Epoch 91/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7182\n",
      "Epoch 92/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7183\n",
      "Epoch 93/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7202\n",
      "Epoch 94/100\n",
      "16/16 - 0s - 6ms/step - loss: 0.7177\n",
      "Epoch 95/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7198\n",
      "Epoch 96/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7188\n",
      "Epoch 97/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7149\n",
      "Epoch 98/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7176\n",
      "Epoch 99/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.7155\n",
      "Epoch 100/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7166\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step\n",
      "Testing with layers=[256, 128, 64, 32], encoding_dim=12, batch_size=128, epochs=50, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "8/8 - 4s - 473ms/step - loss: 1.1958\n",
      "Epoch 2/50\n",
      "8/8 - 0s - 6ms/step - loss: 1.0577\n",
      "Epoch 3/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.9776\n",
      "Epoch 4/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.9328\n",
      "Epoch 5/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.9007\n",
      "Epoch 6/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8792\n",
      "Epoch 7/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8673\n",
      "Epoch 8/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8518\n",
      "Epoch 9/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8416\n",
      "Epoch 10/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8326\n",
      "Epoch 11/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8237\n",
      "Epoch 12/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.8153\n",
      "Epoch 13/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8090\n",
      "Epoch 14/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7976\n",
      "Epoch 15/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7947\n",
      "Epoch 16/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7886\n",
      "Epoch 17/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7811\n",
      "Epoch 18/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7767\n",
      "Epoch 19/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7717\n",
      "Epoch 20/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.7666\n",
      "Epoch 21/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.7590\n",
      "Epoch 22/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.7555\n",
      "Epoch 23/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.7539\n",
      "Epoch 24/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.7498\n",
      "Epoch 25/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.7472\n",
      "Epoch 26/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.7454\n",
      "Epoch 27/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.7387\n",
      "Epoch 28/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.7366\n",
      "Epoch 29/50\n",
      "8/8 - 0s - 8ms/step - loss: 0.7305\n",
      "Epoch 30/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.7323\n",
      "Epoch 31/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.7308\n",
      "Epoch 32/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.7240\n",
      "Epoch 33/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.7270\n",
      "Epoch 34/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.7226\n",
      "Epoch 35/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.7238\n",
      "Epoch 36/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.7198\n",
      "Epoch 37/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.7155\n",
      "Epoch 38/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.7171\n",
      "Epoch 39/50\n",
      "8/8 - 0s - 9ms/step - loss: 0.7141\n",
      "Epoch 40/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.7126\n",
      "Epoch 41/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.7136\n",
      "Epoch 42/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.7102\n",
      "Epoch 43/50\n",
      "8/8 - 0s - 8ms/step - loss: 0.7103\n",
      "Epoch 44/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.7043\n",
      "Epoch 45/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.7086\n",
      "Epoch 46/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.7040\n",
      "Epoch 47/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.7029\n",
      "Epoch 48/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.7014\n",
      "Epoch 49/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.7025\n",
      "Epoch 50/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.6989\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "Testing with layers=[256, 128, 64, 32], encoding_dim=12, batch_size=128, epochs=50, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "8/8 - 2s - 304ms/step - loss: 1.2313\n",
      "Epoch 2/50\n",
      "8/8 - 0s - 6ms/step - loss: 1.1163\n",
      "Epoch 3/50\n",
      "8/8 - 0s - 6ms/step - loss: 1.0416\n",
      "Epoch 4/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.9912\n",
      "Epoch 5/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.9611\n",
      "Epoch 6/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.9405\n",
      "Epoch 7/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.9239\n",
      "Epoch 8/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.9117\n",
      "Epoch 9/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.8982\n",
      "Epoch 10/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.8921\n",
      "Epoch 11/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.8822\n",
      "Epoch 12/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.8767\n",
      "Epoch 13/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.8681\n",
      "Epoch 14/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.8649\n",
      "Epoch 15/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.8535\n",
      "Epoch 16/50\n",
      "8/8 - 0s - 8ms/step - loss: 0.8509\n",
      "Epoch 17/50\n",
      "8/8 - 0s - 8ms/step - loss: 0.8471\n",
      "Epoch 18/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.8413\n",
      "Epoch 19/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.8356\n",
      "Epoch 20/50\n",
      "8/8 - 0s - 10ms/step - loss: 0.8344\n",
      "Epoch 21/50\n",
      "8/8 - 0s - 12ms/step - loss: 0.8276\n",
      "Epoch 22/50\n",
      "8/8 - 0s - 9ms/step - loss: 0.8285\n",
      "Epoch 23/50\n",
      "8/8 - 0s - 11ms/step - loss: 0.8211\n",
      "Epoch 24/50\n",
      "8/8 - 0s - 12ms/step - loss: 0.8185\n",
      "Epoch 25/50\n",
      "8/8 - 0s - 12ms/step - loss: 0.8158\n",
      "Epoch 26/50\n",
      "8/8 - 0s - 13ms/step - loss: 0.8089\n",
      "Epoch 27/50\n",
      "8/8 - 0s - 10ms/step - loss: 0.8081\n",
      "Epoch 28/50\n",
      "8/8 - 0s - 11ms/step - loss: 0.8059\n",
      "Epoch 29/50\n",
      "8/8 - 0s - 11ms/step - loss: 0.8017\n",
      "Epoch 30/50\n",
      "8/8 - 0s - 13ms/step - loss: 0.7996\n",
      "Epoch 31/50\n",
      "8/8 - 0s - 13ms/step - loss: 0.7945\n",
      "Epoch 32/50\n",
      "8/8 - 0s - 12ms/step - loss: 0.7941\n",
      "Epoch 33/50\n",
      "8/8 - 0s - 11ms/step - loss: 0.7952\n",
      "Epoch 34/50\n",
      "8/8 - 0s - 12ms/step - loss: 0.7860\n",
      "Epoch 35/50\n",
      "8/8 - 0s - 12ms/step - loss: 0.7851\n",
      "Epoch 36/50\n",
      "8/8 - 0s - 11ms/step - loss: 0.7866\n",
      "Epoch 37/50\n",
      "8/8 - 0s - 11ms/step - loss: 0.7820\n",
      "Epoch 38/50\n",
      "8/8 - 0s - 13ms/step - loss: 0.7793\n",
      "Epoch 39/50\n",
      "8/8 - 0s - 12ms/step - loss: 0.7827\n",
      "Epoch 40/50\n",
      "8/8 - 0s - 8ms/step - loss: 0.7775\n",
      "Epoch 41/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.7760\n",
      "Epoch 42/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.7764\n",
      "Epoch 43/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.7746\n",
      "Epoch 44/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.7724\n",
      "Epoch 45/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.7741\n",
      "Epoch 46/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.7701\n",
      "Epoch 47/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.7707\n",
      "Epoch 48/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.7679\n",
      "Epoch 49/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.7684\n",
      "Epoch 50/50\n",
      "8/8 - 0s - 8ms/step - loss: 0.7660\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step\n",
      "Testing with layers=[256, 128, 64, 32], encoding_dim=12, batch_size=128, epochs=100, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "8/8 - 2s - 309ms/step - loss: 1.2261\n",
      "Epoch 2/100\n",
      "8/8 - 0s - 6ms/step - loss: 1.0793\n",
      "Epoch 3/100\n",
      "8/8 - 0s - 4ms/step - loss: 1.0054\n",
      "Epoch 4/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.9549\n",
      "Epoch 5/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.9259\n",
      "Epoch 6/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.9041\n",
      "Epoch 7/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8858\n",
      "Epoch 8/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8692\n",
      "Epoch 9/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8569\n",
      "Epoch 10/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8468\n",
      "Epoch 11/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8383\n",
      "Epoch 12/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8270\n",
      "Epoch 13/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8208\n",
      "Epoch 14/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8119\n",
      "Epoch 15/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.8097\n",
      "Epoch 16/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8054\n",
      "Epoch 17/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8009\n",
      "Epoch 18/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7938\n",
      "Epoch 19/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7884\n",
      "Epoch 20/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7818\n",
      "Epoch 21/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7785\n",
      "Epoch 22/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7748\n",
      "Epoch 23/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7719\n",
      "Epoch 24/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7683\n",
      "Epoch 25/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7660\n",
      "Epoch 26/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7631\n",
      "Epoch 27/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7581\n",
      "Epoch 28/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7575\n",
      "Epoch 29/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7541\n",
      "Epoch 30/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7535\n",
      "Epoch 31/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7462\n",
      "Epoch 32/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7466\n",
      "Epoch 33/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7412\n",
      "Epoch 34/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7421\n",
      "Epoch 35/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7395\n",
      "Epoch 36/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7368\n",
      "Epoch 37/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7354\n",
      "Epoch 38/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7334\n",
      "Epoch 39/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7308\n",
      "Epoch 40/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7283\n",
      "Epoch 41/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7274\n",
      "Epoch 42/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7255\n",
      "Epoch 43/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7250\n",
      "Epoch 44/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.7239\n",
      "Epoch 45/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.7200\n",
      "Epoch 46/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7182\n",
      "Epoch 47/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7173\n",
      "Epoch 48/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7185\n",
      "Epoch 49/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7174\n",
      "Epoch 50/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7133\n",
      "Epoch 51/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7129\n",
      "Epoch 52/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7090\n",
      "Epoch 53/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7128\n",
      "Epoch 54/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7112\n",
      "Epoch 55/100\n",
      "8/8 - 0s - 10ms/step - loss: 0.7069\n",
      "Epoch 56/100\n",
      "8/8 - 0s - 11ms/step - loss: 0.7058\n",
      "Epoch 57/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.7028\n",
      "Epoch 58/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7049\n",
      "Epoch 59/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.7027\n",
      "Epoch 60/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.7013\n",
      "Epoch 61/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.6983\n",
      "Epoch 62/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.6962\n",
      "Epoch 63/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.6950\n",
      "Epoch 64/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.6964\n",
      "Epoch 65/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.6945\n",
      "Epoch 66/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6939\n",
      "Epoch 67/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6911\n",
      "Epoch 68/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6938\n",
      "Epoch 69/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6879\n",
      "Epoch 70/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6901\n",
      "Epoch 71/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6880\n",
      "Epoch 72/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6843\n",
      "Epoch 73/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6866\n",
      "Epoch 74/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6880\n",
      "Epoch 75/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6867\n",
      "Epoch 76/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.6820\n",
      "Epoch 77/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6818\n",
      "Epoch 78/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6808\n",
      "Epoch 79/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6790\n",
      "Epoch 80/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6824\n",
      "Epoch 81/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6810\n",
      "Epoch 82/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.6768\n",
      "Epoch 83/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6806\n",
      "Epoch 84/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6760\n",
      "Epoch 85/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6779\n",
      "Epoch 86/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6780\n",
      "Epoch 87/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.6754\n",
      "Epoch 88/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6741\n",
      "Epoch 89/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6769\n",
      "Epoch 90/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6711\n",
      "Epoch 91/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6715\n",
      "Epoch 92/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6720\n",
      "Epoch 93/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6710\n",
      "Epoch 94/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6722\n",
      "Epoch 95/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6687\n",
      "Epoch 96/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6682\n",
      "Epoch 97/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6703\n",
      "Epoch 98/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6672\n",
      "Epoch 99/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6673\n",
      "Epoch 100/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6643\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Testing with layers=[256, 128, 64, 32], encoding_dim=12, batch_size=128, epochs=100, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "8/8 - 2s - 214ms/step - loss: 1.2532\n",
      "Epoch 2/100\n",
      "8/8 - 0s - 4ms/step - loss: 1.1220\n",
      "Epoch 3/100\n",
      "8/8 - 0s - 3ms/step - loss: 1.0471\n",
      "Epoch 4/100\n",
      "8/8 - 0s - 4ms/step - loss: 1.0014\n",
      "Epoch 5/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.9679\n",
      "Epoch 6/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.9450\n",
      "Epoch 7/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.9276\n",
      "Epoch 8/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.9114\n",
      "Epoch 9/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.9017\n",
      "Epoch 10/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8997\n",
      "Epoch 11/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8867\n",
      "Epoch 12/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8751\n",
      "Epoch 13/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8700\n",
      "Epoch 14/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8630\n",
      "Epoch 15/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8551\n",
      "Epoch 16/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8480\n",
      "Epoch 17/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8408\n",
      "Epoch 18/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8423\n",
      "Epoch 19/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.8340\n",
      "Epoch 20/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.8291\n",
      "Epoch 21/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.8229\n",
      "Epoch 22/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.8187\n",
      "Epoch 23/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.8161\n",
      "Epoch 24/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.8135\n",
      "Epoch 25/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.8123\n",
      "Epoch 26/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.8075\n",
      "Epoch 27/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7994\n",
      "Epoch 28/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.8030\n",
      "Epoch 29/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7962\n",
      "Epoch 30/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7958\n",
      "Epoch 31/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7892\n",
      "Epoch 32/100\n",
      "8/8 - 0s - 11ms/step - loss: 0.7850\n",
      "Epoch 33/100\n",
      "8/8 - 0s - 11ms/step - loss: 0.7871\n",
      "Epoch 34/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7824\n",
      "Epoch 35/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7843\n",
      "Epoch 36/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7851\n",
      "Epoch 37/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7758\n",
      "Epoch 38/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7755\n",
      "Epoch 39/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.7763\n",
      "Epoch 40/100\n",
      "8/8 - 0s - 27ms/step - loss: 0.7726\n",
      "Epoch 41/100\n",
      "8/8 - 0s - 9ms/step - loss: 0.7708\n",
      "Epoch 42/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.7695\n",
      "Epoch 43/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7697\n",
      "Epoch 44/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7688\n",
      "Epoch 45/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7700\n",
      "Epoch 46/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7629\n",
      "Epoch 47/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7634\n",
      "Epoch 48/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7626\n",
      "Epoch 49/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7622\n",
      "Epoch 50/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7578\n",
      "Epoch 51/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7577\n",
      "Epoch 52/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7575\n",
      "Epoch 53/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7542\n",
      "Epoch 54/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7508\n",
      "Epoch 55/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7528\n",
      "Epoch 56/100\n",
      "8/8 - 0s - 22ms/step - loss: 0.7525\n",
      "Epoch 57/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7489\n",
      "Epoch 58/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7516\n",
      "Epoch 59/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7504\n",
      "Epoch 60/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7476\n",
      "Epoch 61/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7455\n",
      "Epoch 62/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7457\n",
      "Epoch 63/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7420\n",
      "Epoch 64/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7420\n",
      "Epoch 65/100\n",
      "8/8 - 0s - 10ms/step - loss: 0.7408\n",
      "Epoch 66/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7404\n",
      "Epoch 67/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7378\n",
      "Epoch 68/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7398\n",
      "Epoch 69/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7407\n",
      "Epoch 70/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7399\n",
      "Epoch 71/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7342\n",
      "Epoch 72/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7335\n",
      "Epoch 73/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7381\n",
      "Epoch 74/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7326\n",
      "Epoch 75/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7344\n",
      "Epoch 76/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7337\n",
      "Epoch 77/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7320\n",
      "Epoch 78/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7351\n",
      "Epoch 79/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7278\n",
      "Epoch 80/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7317\n",
      "Epoch 81/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7306\n",
      "Epoch 82/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7264\n",
      "Epoch 83/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7311\n",
      "Epoch 84/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7312\n",
      "Epoch 85/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7262\n",
      "Epoch 86/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7251\n",
      "Epoch 87/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7251\n",
      "Epoch 88/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7200\n",
      "Epoch 89/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7257\n",
      "Epoch 90/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7252\n",
      "Epoch 91/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7217\n",
      "Epoch 92/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7254\n",
      "Epoch 93/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7251\n",
      "Epoch 94/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7239\n",
      "Epoch 95/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7247\n",
      "Epoch 96/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7216\n",
      "Epoch 97/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7209\n",
      "Epoch 98/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7217\n",
      "Epoch 99/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7240\n",
      "Epoch 100/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7226\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Testing with layers=[128, 64], encoding_dim=8, batch_size=32, epochs=50, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "32/32 - 2s - 59ms/step - loss: 1.1772\n",
      "Epoch 2/50\n",
      "32/32 - 0s - 2ms/step - loss: 1.0026\n",
      "Epoch 3/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.9362\n",
      "Epoch 4/50\n",
      "32/32 - 0s - 939us/step - loss: 0.8988\n",
      "Epoch 5/50\n",
      "32/32 - 0s - 920us/step - loss: 0.8704\n",
      "Epoch 6/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8525\n",
      "Epoch 7/50\n",
      "32/32 - 0s - 908us/step - loss: 0.8372\n",
      "Epoch 8/50\n",
      "32/32 - 0s - 975us/step - loss: 0.8249\n",
      "Epoch 9/50\n",
      "32/32 - 0s - 925us/step - loss: 0.8125\n",
      "Epoch 10/50\n",
      "32/32 - 0s - 904us/step - loss: 0.8058\n",
      "Epoch 11/50\n",
      "32/32 - 0s - 999us/step - loss: 0.7978\n",
      "Epoch 12/50\n",
      "32/32 - 0s - 944us/step - loss: 0.7922\n",
      "Epoch 13/50\n",
      "32/32 - 0s - 985us/step - loss: 0.7880\n",
      "Epoch 14/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7832\n",
      "Epoch 15/50\n",
      "32/32 - 0s - 945us/step - loss: 0.7793\n",
      "Epoch 16/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7743\n",
      "Epoch 17/50\n",
      "32/32 - 0s - 951us/step - loss: 0.7700\n",
      "Epoch 18/50\n",
      "32/32 - 0s - 934us/step - loss: 0.7646\n",
      "Epoch 19/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7661\n",
      "Epoch 20/50\n",
      "32/32 - 0s - 929us/step - loss: 0.7602\n",
      "Epoch 21/50\n",
      "32/32 - 0s - 993us/step - loss: 0.7620\n",
      "Epoch 22/50\n",
      "32/32 - 0s - 976us/step - loss: 0.7565\n",
      "Epoch 23/50\n",
      "32/32 - 0s - 958us/step - loss: 0.7560\n",
      "Epoch 24/50\n",
      "32/32 - 0s - 956us/step - loss: 0.7488\n",
      "Epoch 25/50\n",
      "32/32 - 0s - 962us/step - loss: 0.7511\n",
      "Epoch 26/50\n",
      "32/32 - 0s - 929us/step - loss: 0.7482\n",
      "Epoch 27/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7486\n",
      "Epoch 28/50\n",
      "32/32 - 0s - 961us/step - loss: 0.7416\n",
      "Epoch 29/50\n",
      "32/32 - 0s - 941us/step - loss: 0.7462\n",
      "Epoch 30/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7410\n",
      "Epoch 31/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7405\n",
      "Epoch 32/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7361\n",
      "Epoch 33/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7358\n",
      "Epoch 34/50\n",
      "32/32 - 0s - 950us/step - loss: 0.7301\n",
      "Epoch 35/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7321\n",
      "Epoch 36/50\n",
      "32/32 - 0s - 975us/step - loss: 0.7290\n",
      "Epoch 37/50\n",
      "32/32 - 0s - 912us/step - loss: 0.7296\n",
      "Epoch 38/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7292\n",
      "Epoch 39/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7266\n",
      "Epoch 40/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7245\n",
      "Epoch 41/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7255\n",
      "Epoch 42/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7201\n",
      "Epoch 43/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7227\n",
      "Epoch 44/50\n",
      "32/32 - 0s - 962us/step - loss: 0.7176\n",
      "Epoch 45/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7187\n",
      "Epoch 46/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7168\n",
      "Epoch 47/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7195\n",
      "Epoch 48/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7138\n",
      "Epoch 49/50\n",
      "32/32 - 0s - 987us/step - loss: 0.7162\n",
      "Epoch 50/50\n",
      "32/32 - 0s - 983us/step - loss: 0.7125\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Testing with layers=[128, 64], encoding_dim=8, batch_size=32, epochs=50, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "32/32 - 1s - 33ms/step - loss: 1.1825\n",
      "Epoch 2/50\n",
      "32/32 - 0s - 1ms/step - loss: 1.0228\n",
      "Epoch 3/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.9566\n",
      "Epoch 4/50\n",
      "32/32 - 0s - 994us/step - loss: 0.9107\n",
      "Epoch 5/50\n",
      "32/32 - 0s - 957us/step - loss: 0.8873\n",
      "Epoch 6/50\n",
      "32/32 - 0s - 953us/step - loss: 0.8697\n",
      "Epoch 7/50\n",
      "32/32 - 0s - 954us/step - loss: 0.8504\n",
      "Epoch 8/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8422\n",
      "Epoch 9/50\n",
      "32/32 - 0s - 917us/step - loss: 0.8362\n",
      "Epoch 10/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8232\n",
      "Epoch 11/50\n",
      "32/32 - 0s - 946us/step - loss: 0.8213\n",
      "Epoch 12/50\n",
      "32/32 - 0s - 909us/step - loss: 0.8125\n",
      "Epoch 13/50\n",
      "32/32 - 0s - 988us/step - loss: 0.8077\n",
      "Epoch 14/50\n",
      "32/32 - 0s - 924us/step - loss: 0.8021\n",
      "Epoch 15/50\n",
      "32/32 - 0s - 954us/step - loss: 0.7987\n",
      "Epoch 16/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7951\n",
      "Epoch 17/50\n",
      "32/32 - 0s - 907us/step - loss: 0.7917\n",
      "Epoch 18/50\n",
      "32/32 - 0s - 988us/step - loss: 0.7863\n",
      "Epoch 19/50\n",
      "32/32 - 0s - 984us/step - loss: 0.7837\n",
      "Epoch 20/50\n",
      "32/32 - 0s - 956us/step - loss: 0.7797\n",
      "Epoch 21/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7764\n",
      "Epoch 22/50\n",
      "32/32 - 0s - 1000us/step - loss: 0.7755\n",
      "Epoch 23/50\n",
      "32/32 - 0s - 962us/step - loss: 0.7746\n",
      "Epoch 24/50\n",
      "32/32 - 0s - 997us/step - loss: 0.7727\n",
      "Epoch 25/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7656\n",
      "Epoch 26/50\n",
      "32/32 - 0s - 929us/step - loss: 0.7641\n",
      "Epoch 27/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7646\n",
      "Epoch 28/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7641\n",
      "Epoch 29/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7602\n",
      "Epoch 30/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7561\n",
      "Epoch 31/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7578\n",
      "Epoch 32/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7568\n",
      "Epoch 33/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7530\n",
      "Epoch 34/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7523\n",
      "Epoch 35/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7523\n",
      "Epoch 36/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7485\n",
      "Epoch 37/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7513\n",
      "Epoch 38/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7465\n",
      "Epoch 39/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7472\n",
      "Epoch 40/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7432\n",
      "Epoch 41/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7461\n",
      "Epoch 42/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7485\n",
      "Epoch 43/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7435\n",
      "Epoch 44/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7416\n",
      "Epoch 45/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7403\n",
      "Epoch 46/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7410\n",
      "Epoch 47/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7394\n",
      "Epoch 48/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7368\n",
      "Epoch 49/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7360\n",
      "Epoch 50/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7367\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Testing with layers=[128, 64], encoding_dim=8, batch_size=32, epochs=100, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "32/32 - 1s - 36ms/step - loss: 1.1720\n",
      "Epoch 2/100\n",
      "32/32 - 0s - 1ms/step - loss: 1.0005\n",
      "Epoch 3/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.9315\n",
      "Epoch 4/100\n",
      "32/32 - 0s - 992us/step - loss: 0.8907\n",
      "Epoch 5/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8637\n",
      "Epoch 6/100\n",
      "32/32 - 0s - 945us/step - loss: 0.8481\n",
      "Epoch 7/100\n",
      "32/32 - 0s - 995us/step - loss: 0.8340\n",
      "Epoch 8/100\n",
      "32/32 - 0s - 924us/step - loss: 0.8237\n",
      "Epoch 9/100\n",
      "32/32 - 0s - 941us/step - loss: 0.8123\n",
      "Epoch 10/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8078\n",
      "Epoch 11/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7976\n",
      "Epoch 12/100\n",
      "32/32 - 0s - 974us/step - loss: 0.7909\n",
      "Epoch 13/100\n",
      "32/32 - 0s - 995us/step - loss: 0.7856\n",
      "Epoch 14/100\n",
      "32/32 - 0s - 897us/step - loss: 0.7799\n",
      "Epoch 15/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7716\n",
      "Epoch 16/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.7698\n",
      "Epoch 17/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7681\n",
      "Epoch 18/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7580\n",
      "Epoch 19/100\n",
      "32/32 - 0s - 999us/step - loss: 0.7577\n",
      "Epoch 20/100\n",
      "32/32 - 0s - 985us/step - loss: 0.7544\n",
      "Epoch 21/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7506\n",
      "Epoch 22/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7497\n",
      "Epoch 23/100\n",
      "32/32 - 0s - 954us/step - loss: 0.7460\n",
      "Epoch 24/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7439\n",
      "Epoch 25/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7404\n",
      "Epoch 26/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7396\n",
      "Epoch 27/100\n",
      "32/32 - 0s - 1000us/step - loss: 0.7401\n",
      "Epoch 28/100\n",
      "32/32 - 0s - 966us/step - loss: 0.7341\n",
      "Epoch 29/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7345\n",
      "Epoch 30/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7308\n",
      "Epoch 31/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7291\n",
      "Epoch 32/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7304\n",
      "Epoch 33/100\n",
      "32/32 - 0s - 953us/step - loss: 0.7271\n",
      "Epoch 34/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7269\n",
      "Epoch 35/100\n",
      "32/32 - 0s - 964us/step - loss: 0.7244\n",
      "Epoch 36/100\n",
      "32/32 - 0s - 956us/step - loss: 0.7206\n",
      "Epoch 37/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7206\n",
      "Epoch 38/100\n",
      "32/32 - 0s - 902us/step - loss: 0.7191\n",
      "Epoch 39/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7204\n",
      "Epoch 40/100\n",
      "32/32 - 0s - 996us/step - loss: 0.7177\n",
      "Epoch 41/100\n",
      "32/32 - 0s - 950us/step - loss: 0.7171\n",
      "Epoch 42/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7170\n",
      "Epoch 43/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7156\n",
      "Epoch 44/100\n",
      "32/32 - 0s - 957us/step - loss: 0.7110\n",
      "Epoch 45/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7142\n",
      "Epoch 46/100\n",
      "32/32 - 0s - 934us/step - loss: 0.7087\n",
      "Epoch 47/100\n",
      "32/32 - 0s - 981us/step - loss: 0.7098\n",
      "Epoch 48/100\n",
      "32/32 - 0s - 924us/step - loss: 0.7082\n",
      "Epoch 49/100\n",
      "32/32 - 0s - 973us/step - loss: 0.7081\n",
      "Epoch 50/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7063\n",
      "Epoch 51/100\n",
      "32/32 - 0s - 963us/step - loss: 0.7066\n",
      "Epoch 52/100\n",
      "32/32 - 0s - 890us/step - loss: 0.7071\n",
      "Epoch 53/100\n",
      "32/32 - 0s - 996us/step - loss: 0.7072\n",
      "Epoch 54/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7007\n",
      "Epoch 55/100\n",
      "32/32 - 0s - 937us/step - loss: 0.7019\n",
      "Epoch 56/100\n",
      "32/32 - 0s - 982us/step - loss: 0.7022\n",
      "Epoch 57/100\n",
      "32/32 - 0s - 976us/step - loss: 0.7001\n",
      "Epoch 58/100\n",
      "32/32 - 0s - 934us/step - loss: 0.7016\n",
      "Epoch 59/100\n",
      "32/32 - 0s - 986us/step - loss: 0.7011\n",
      "Epoch 60/100\n",
      "32/32 - 0s - 948us/step - loss: 0.6998\n",
      "Epoch 61/100\n",
      "32/32 - 0s - 923us/step - loss: 0.6988\n",
      "Epoch 62/100\n",
      "32/32 - 0s - 984us/step - loss: 0.6964\n",
      "Epoch 63/100\n",
      "32/32 - 0s - 965us/step - loss: 0.6982\n",
      "Epoch 64/100\n",
      "32/32 - 0s - 949us/step - loss: 0.6965\n",
      "Epoch 65/100\n",
      "32/32 - 0s - 983us/step - loss: 0.6945\n",
      "Epoch 66/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6953\n",
      "Epoch 67/100\n",
      "32/32 - 0s - 995us/step - loss: 0.6980\n",
      "Epoch 68/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6926\n",
      "Epoch 69/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6943\n",
      "Epoch 70/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6929\n",
      "Epoch 71/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6911\n",
      "Epoch 72/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6923\n",
      "Epoch 73/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6910\n",
      "Epoch 74/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6927\n",
      "Epoch 75/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6914\n",
      "Epoch 76/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6921\n",
      "Epoch 77/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6870\n",
      "Epoch 78/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6900\n",
      "Epoch 79/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6908\n",
      "Epoch 80/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6887\n",
      "Epoch 81/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.6895\n",
      "Epoch 82/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6868\n",
      "Epoch 83/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6872\n",
      "Epoch 84/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6862\n",
      "Epoch 85/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6871\n",
      "Epoch 86/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6890\n",
      "Epoch 87/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6873\n",
      "Epoch 88/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6859\n",
      "Epoch 89/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6857\n",
      "Epoch 90/100\n",
      "32/32 - 0s - 959us/step - loss: 0.6867\n",
      "Epoch 91/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6822\n",
      "Epoch 92/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6839\n",
      "Epoch 93/100\n",
      "32/32 - 0s - 956us/step - loss: 0.6843\n",
      "Epoch 94/100\n",
      "32/32 - 0s - 985us/step - loss: 0.6851\n",
      "Epoch 95/100\n",
      "32/32 - 0s - 974us/step - loss: 0.6851\n",
      "Epoch 96/100\n",
      "32/32 - 0s - 999us/step - loss: 0.6841\n",
      "Epoch 97/100\n",
      "32/32 - 0s - 977us/step - loss: 0.6807\n",
      "Epoch 98/100\n",
      "32/32 - 0s - 968us/step - loss: 0.6829\n",
      "Epoch 99/100\n",
      "32/32 - 0s - 954us/step - loss: 0.6817\n",
      "Epoch 100/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6821\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Testing with layers=[128, 64], encoding_dim=8, batch_size=32, epochs=100, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "32/32 - 1s - 37ms/step - loss: 1.1666\n",
      "Epoch 2/100\n",
      "32/32 - 0s - 1ms/step - loss: 1.0209\n",
      "Epoch 3/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.9491\n",
      "Epoch 4/100\n",
      "32/32 - 0s - 990us/step - loss: 0.9095\n",
      "Epoch 5/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8881\n",
      "Epoch 6/100\n",
      "32/32 - 0s - 940us/step - loss: 0.8692\n",
      "Epoch 7/100\n",
      "32/32 - 0s - 981us/step - loss: 0.8548\n",
      "Epoch 8/100\n",
      "32/32 - 0s - 925us/step - loss: 0.8495\n",
      "Epoch 9/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8364\n",
      "Epoch 10/100\n",
      "32/32 - 0s - 976us/step - loss: 0.8287\n",
      "Epoch 11/100\n",
      "32/32 - 0s - 992us/step - loss: 0.8193\n",
      "Epoch 12/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8132\n",
      "Epoch 13/100\n",
      "32/32 - 0s - 971us/step - loss: 0.8109\n",
      "Epoch 14/100\n",
      "32/32 - 0s - 925us/step - loss: 0.8067\n",
      "Epoch 15/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8039\n",
      "Epoch 16/100\n",
      "32/32 - 0s - 974us/step - loss: 0.7996\n",
      "Epoch 17/100\n",
      "32/32 - 0s - 919us/step - loss: 0.7944\n",
      "Epoch 18/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7918\n",
      "Epoch 19/100\n",
      "32/32 - 0s - 921us/step - loss: 0.7873\n",
      "Epoch 20/100\n",
      "32/32 - 0s - 998us/step - loss: 0.7859\n",
      "Epoch 21/100\n",
      "32/32 - 0s - 986us/step - loss: 0.7799\n",
      "Epoch 22/100\n",
      "32/32 - 0s - 949us/step - loss: 0.7779\n",
      "Epoch 23/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7757\n",
      "Epoch 24/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7753\n",
      "Epoch 25/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7705\n",
      "Epoch 26/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7714\n",
      "Epoch 27/100\n",
      "32/32 - 0s - 953us/step - loss: 0.7655\n",
      "Epoch 28/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7620\n",
      "Epoch 29/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7635\n",
      "Epoch 30/100\n",
      "32/32 - 0s - 939us/step - loss: 0.7631\n",
      "Epoch 31/100\n",
      "32/32 - 0s - 995us/step - loss: 0.7576\n",
      "Epoch 32/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7575\n",
      "Epoch 33/100\n",
      "32/32 - 0s - 939us/step - loss: 0.7540\n",
      "Epoch 34/100\n",
      "32/32 - 0s - 984us/step - loss: 0.7517\n",
      "Epoch 35/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7502\n",
      "Epoch 36/100\n",
      "32/32 - 0s - 941us/step - loss: 0.7491\n",
      "Epoch 37/100\n",
      "32/32 - 0s - 987us/step - loss: 0.7486\n",
      "Epoch 38/100\n",
      "32/32 - 0s - 962us/step - loss: 0.7456\n",
      "Epoch 39/100\n",
      "32/32 - 0s - 929us/step - loss: 0.7412\n",
      "Epoch 40/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7419\n",
      "Epoch 41/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7421\n",
      "Epoch 42/100\n",
      "32/32 - 0s - 962us/step - loss: 0.7411\n",
      "Epoch 43/100\n",
      "32/32 - 0s - 959us/step - loss: 0.7413\n",
      "Epoch 44/100\n",
      "32/32 - 0s - 954us/step - loss: 0.7373\n",
      "Epoch 45/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7385\n",
      "Epoch 46/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7351\n",
      "Epoch 47/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7347\n",
      "Epoch 48/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7354\n",
      "Epoch 49/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7326\n",
      "Epoch 50/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7341\n",
      "Epoch 51/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7310\n",
      "Epoch 52/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7307\n",
      "Epoch 53/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7289\n",
      "Epoch 54/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7285\n",
      "Epoch 55/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7283\n",
      "Epoch 56/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7266\n",
      "Epoch 57/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7272\n",
      "Epoch 58/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7254\n",
      "Epoch 59/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7233\n",
      "Epoch 60/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7261\n",
      "Epoch 61/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7212\n",
      "Epoch 62/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7239\n",
      "Epoch 63/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7218\n",
      "Epoch 64/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7193\n",
      "Epoch 65/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7239\n",
      "Epoch 66/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7221\n",
      "Epoch 67/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7184\n",
      "Epoch 68/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7171\n",
      "Epoch 69/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7171\n",
      "Epoch 70/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7198\n",
      "Epoch 71/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7138\n",
      "Epoch 72/100\n",
      "32/32 - 0s - 965us/step - loss: 0.7200\n",
      "Epoch 73/100\n",
      "32/32 - 0s - 994us/step - loss: 0.7156\n",
      "Epoch 74/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7147\n",
      "Epoch 75/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7146\n",
      "Epoch 76/100\n",
      "32/32 - 0s - 979us/step - loss: 0.7146\n",
      "Epoch 77/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7113\n",
      "Epoch 78/100\n",
      "32/32 - 0s - 948us/step - loss: 0.7155\n",
      "Epoch 79/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7166\n",
      "Epoch 80/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7111\n",
      "Epoch 81/100\n",
      "32/32 - 0s - 981us/step - loss: 0.7108\n",
      "Epoch 82/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7114\n",
      "Epoch 83/100\n",
      "32/32 - 0s - 947us/step - loss: 0.7097\n",
      "Epoch 84/100\n",
      "32/32 - 0s - 983us/step - loss: 0.7127\n",
      "Epoch 85/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7117\n",
      "Epoch 86/100\n",
      "32/32 - 0s - 941us/step - loss: 0.7103\n",
      "Epoch 87/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7118\n",
      "Epoch 88/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7081\n",
      "Epoch 89/100\n",
      "32/32 - 0s - 944us/step - loss: 0.7021\n",
      "Epoch 90/100\n",
      "32/32 - 0s - 988us/step - loss: 0.7077\n",
      "Epoch 91/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7099\n",
      "Epoch 92/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7072\n",
      "Epoch 93/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7081\n",
      "Epoch 94/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7078\n",
      "Epoch 95/100\n",
      "32/32 - 0s - 967us/step - loss: 0.7080\n",
      "Epoch 96/100\n",
      "32/32 - 0s - 973us/step - loss: 0.7035\n",
      "Epoch 97/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7068\n",
      "Epoch 98/100\n",
      "32/32 - 0s - 987us/step - loss: 0.7014\n",
      "Epoch 99/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7035\n",
      "Epoch 100/100\n",
      "32/32 - 0s - 920us/step - loss: 0.7057\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Testing with layers=[128, 64], encoding_dim=8, batch_size=64, epochs=50, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "16/16 - 1s - 67ms/step - loss: 1.1905\n",
      "Epoch 2/50\n",
      "16/16 - 0s - 2ms/step - loss: 1.0492\n",
      "Epoch 3/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.9794\n",
      "Epoch 4/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.9369\n",
      "Epoch 5/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.9051\n",
      "Epoch 6/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8817\n",
      "Epoch 7/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8657\n",
      "Epoch 8/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8539\n",
      "Epoch 9/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8449\n",
      "Epoch 10/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8334\n",
      "Epoch 11/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8218\n",
      "Epoch 12/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8161\n",
      "Epoch 13/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8081\n",
      "Epoch 14/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7999\n",
      "Epoch 15/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7935\n",
      "Epoch 16/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7913\n",
      "Epoch 17/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7859\n",
      "Epoch 18/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7790\n",
      "Epoch 19/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7778\n",
      "Epoch 20/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7683\n",
      "Epoch 21/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7695\n",
      "Epoch 22/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7673\n",
      "Epoch 23/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7628\n",
      "Epoch 24/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7592\n",
      "Epoch 25/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7575\n",
      "Epoch 26/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7554\n",
      "Epoch 27/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7488\n",
      "Epoch 28/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7511\n",
      "Epoch 29/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7457\n",
      "Epoch 30/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7461\n",
      "Epoch 31/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7423\n",
      "Epoch 32/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7406\n",
      "Epoch 33/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7385\n",
      "Epoch 34/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7415\n",
      "Epoch 35/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7355\n",
      "Epoch 36/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7351\n",
      "Epoch 37/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7327\n",
      "Epoch 38/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7297\n",
      "Epoch 39/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7295\n",
      "Epoch 40/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7300\n",
      "Epoch 41/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7263\n",
      "Epoch 42/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7254\n",
      "Epoch 43/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7273\n",
      "Epoch 44/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7245\n",
      "Epoch 45/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7251\n",
      "Epoch 46/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7221\n",
      "Epoch 47/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7203\n",
      "Epoch 48/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7206\n",
      "Epoch 49/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7184\n",
      "Epoch 50/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7195\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "Testing with layers=[128, 64], encoding_dim=8, batch_size=64, epochs=50, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "16/16 - 1s - 66ms/step - loss: 1.2015\n",
      "Epoch 2/50\n",
      "16/16 - 0s - 2ms/step - loss: 1.0859\n",
      "Epoch 3/50\n",
      "16/16 - 0s - 1ms/step - loss: 1.0130\n",
      "Epoch 4/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.9624\n",
      "Epoch 5/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.9371\n",
      "Epoch 6/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.9130\n",
      "Epoch 7/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8993\n",
      "Epoch 8/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8817\n",
      "Epoch 9/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8711\n",
      "Epoch 10/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8655\n",
      "Epoch 11/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8555\n",
      "Epoch 12/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8452\n",
      "Epoch 13/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8424\n",
      "Epoch 14/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8347\n",
      "Epoch 15/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8286\n",
      "Epoch 16/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8263\n",
      "Epoch 17/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8196\n",
      "Epoch 18/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8148\n",
      "Epoch 19/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8130\n",
      "Epoch 20/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8079\n",
      "Epoch 21/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8055\n",
      "Epoch 22/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7994\n",
      "Epoch 23/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7975\n",
      "Epoch 24/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7965\n",
      "Epoch 25/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7929\n",
      "Epoch 26/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7892\n",
      "Epoch 27/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7900\n",
      "Epoch 28/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7846\n",
      "Epoch 29/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7828\n",
      "Epoch 30/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7822\n",
      "Epoch 31/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7808\n",
      "Epoch 32/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7794\n",
      "Epoch 33/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7779\n",
      "Epoch 34/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7781\n",
      "Epoch 35/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7750\n",
      "Epoch 36/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7705\n",
      "Epoch 37/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7704\n",
      "Epoch 38/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7685\n",
      "Epoch 39/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7650\n",
      "Epoch 40/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7654\n",
      "Epoch 41/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7646\n",
      "Epoch 42/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7635\n",
      "Epoch 43/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7599\n",
      "Epoch 44/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7612\n",
      "Epoch 45/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7572\n",
      "Epoch 46/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7578\n",
      "Epoch 47/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7555\n",
      "Epoch 48/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7577\n",
      "Epoch 49/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7518\n",
      "Epoch 50/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7509\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Testing with layers=[128, 64], encoding_dim=8, batch_size=64, epochs=100, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "16/16 - 2s - 111ms/step - loss: 1.2279\n",
      "Epoch 2/100\n",
      "16/16 - 0s - 3ms/step - loss: 1.0879\n",
      "Epoch 3/100\n",
      "16/16 - 0s - 2ms/step - loss: 1.0080\n",
      "Epoch 4/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.9554\n",
      "Epoch 5/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.9238\n",
      "Epoch 6/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.9036\n",
      "Epoch 7/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8844\n",
      "Epoch 8/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8698\n",
      "Epoch 9/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8563\n",
      "Epoch 10/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8501\n",
      "Epoch 11/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8385\n",
      "Epoch 12/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8306\n",
      "Epoch 13/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8218\n",
      "Epoch 14/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8154\n",
      "Epoch 15/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8082\n",
      "Epoch 16/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8048\n",
      "Epoch 17/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7979\n",
      "Epoch 18/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7934\n",
      "Epoch 19/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7883\n",
      "Epoch 20/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7826\n",
      "Epoch 21/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7798\n",
      "Epoch 22/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7739\n",
      "Epoch 23/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7698\n",
      "Epoch 24/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7653\n",
      "Epoch 25/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7677\n",
      "Epoch 26/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7611\n",
      "Epoch 27/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7586\n",
      "Epoch 28/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7566\n",
      "Epoch 29/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7535\n",
      "Epoch 30/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7462\n",
      "Epoch 31/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7471\n",
      "Epoch 32/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7454\n",
      "Epoch 33/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7430\n",
      "Epoch 34/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7419\n",
      "Epoch 35/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7429\n",
      "Epoch 36/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7365\n",
      "Epoch 37/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7373\n",
      "Epoch 38/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7295\n",
      "Epoch 39/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7328\n",
      "Epoch 40/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7326\n",
      "Epoch 41/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7283\n",
      "Epoch 42/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7262\n",
      "Epoch 43/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7306\n",
      "Epoch 44/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7260\n",
      "Epoch 45/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7221\n",
      "Epoch 46/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7215\n",
      "Epoch 47/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7201\n",
      "Epoch 48/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7185\n",
      "Epoch 49/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7180\n",
      "Epoch 50/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7170\n",
      "Epoch 51/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7144\n",
      "Epoch 52/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7153\n",
      "Epoch 53/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7127\n",
      "Epoch 54/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7133\n",
      "Epoch 55/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7137\n",
      "Epoch 56/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7112\n",
      "Epoch 57/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7098\n",
      "Epoch 58/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7116\n",
      "Epoch 59/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7080\n",
      "Epoch 60/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7091\n",
      "Epoch 61/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7040\n",
      "Epoch 62/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7044\n",
      "Epoch 63/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7040\n",
      "Epoch 64/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7053\n",
      "Epoch 65/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7055\n",
      "Epoch 66/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6987\n",
      "Epoch 67/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6993\n",
      "Epoch 68/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7019\n",
      "Epoch 69/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7014\n",
      "Epoch 70/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7017\n",
      "Epoch 71/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7003\n",
      "Epoch 72/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6987\n",
      "Epoch 73/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6973\n",
      "Epoch 74/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6970\n",
      "Epoch 75/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6975\n",
      "Epoch 76/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6972\n",
      "Epoch 77/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6967\n",
      "Epoch 78/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6951\n",
      "Epoch 79/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6973\n",
      "Epoch 80/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6918\n",
      "Epoch 81/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6946\n",
      "Epoch 82/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6962\n",
      "Epoch 83/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6953\n",
      "Epoch 84/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6927\n",
      "Epoch 85/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6948\n",
      "Epoch 86/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6908\n",
      "Epoch 87/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6941\n",
      "Epoch 88/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6927\n",
      "Epoch 89/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6900\n",
      "Epoch 90/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6914\n",
      "Epoch 91/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6912\n",
      "Epoch 92/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6896\n",
      "Epoch 93/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6911\n",
      "Epoch 94/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6899\n",
      "Epoch 95/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6879\n",
      "Epoch 96/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6914\n",
      "Epoch 97/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6881\n",
      "Epoch 98/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6908\n",
      "Epoch 99/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6868\n",
      "Epoch 100/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6877\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Testing with layers=[128, 64], encoding_dim=8, batch_size=64, epochs=100, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "16/16 - 1s - 69ms/step - loss: 1.2431\n",
      "Epoch 2/100\n",
      "16/16 - 0s - 2ms/step - loss: 1.1126\n",
      "Epoch 3/100\n",
      "16/16 - 0s - 2ms/step - loss: 1.0284\n",
      "Epoch 4/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.9763\n",
      "Epoch 5/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.9408\n",
      "Epoch 6/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.9138\n",
      "Epoch 7/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8918\n",
      "Epoch 8/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8792\n",
      "Epoch 9/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8699\n",
      "Epoch 10/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8549\n",
      "Epoch 11/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8487\n",
      "Epoch 12/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8375\n",
      "Epoch 13/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8315\n",
      "Epoch 14/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8276\n",
      "Epoch 15/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8195\n",
      "Epoch 16/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8178\n",
      "Epoch 17/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8137\n",
      "Epoch 18/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8117\n",
      "Epoch 19/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8049\n",
      "Epoch 20/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.8014\n",
      "Epoch 21/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7950\n",
      "Epoch 22/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7954\n",
      "Epoch 23/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7903\n",
      "Epoch 24/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7870\n",
      "Epoch 25/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7846\n",
      "Epoch 26/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7838\n",
      "Epoch 27/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7810\n",
      "Epoch 28/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7781\n",
      "Epoch 29/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7756\n",
      "Epoch 30/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7763\n",
      "Epoch 31/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7741\n",
      "Epoch 32/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7711\n",
      "Epoch 33/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7683\n",
      "Epoch 34/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7659\n",
      "Epoch 35/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7625\n",
      "Epoch 36/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7605\n",
      "Epoch 37/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7618\n",
      "Epoch 38/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7598\n",
      "Epoch 39/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7558\n",
      "Epoch 40/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7530\n",
      "Epoch 41/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7544\n",
      "Epoch 42/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7533\n",
      "Epoch 43/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7500\n",
      "Epoch 44/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7493\n",
      "Epoch 45/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7463\n",
      "Epoch 46/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7464\n",
      "Epoch 47/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7450\n",
      "Epoch 48/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7430\n",
      "Epoch 49/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7407\n",
      "Epoch 50/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7413\n",
      "Epoch 51/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7402\n",
      "Epoch 52/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7378\n",
      "Epoch 53/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7364\n",
      "Epoch 54/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7348\n",
      "Epoch 55/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7335\n",
      "Epoch 56/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7329\n",
      "Epoch 57/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7302\n",
      "Epoch 58/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7278\n",
      "Epoch 59/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7281\n",
      "Epoch 60/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7269\n",
      "Epoch 61/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7282\n",
      "Epoch 62/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7276\n",
      "Epoch 63/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7251\n",
      "Epoch 64/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7238\n",
      "Epoch 65/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7231\n",
      "Epoch 66/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7214\n",
      "Epoch 67/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7196\n",
      "Epoch 68/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7205\n",
      "Epoch 69/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7177\n",
      "Epoch 70/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7168\n",
      "Epoch 71/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7185\n",
      "Epoch 72/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7169\n",
      "Epoch 73/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7149\n",
      "Epoch 74/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7132\n",
      "Epoch 75/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7113\n",
      "Epoch 76/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7137\n",
      "Epoch 77/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7114\n",
      "Epoch 78/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7118\n",
      "Epoch 79/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7112\n",
      "Epoch 80/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7075\n",
      "Epoch 81/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7073\n",
      "Epoch 82/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7086\n",
      "Epoch 83/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7066\n",
      "Epoch 84/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7056\n",
      "Epoch 85/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7073\n",
      "Epoch 86/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7052\n",
      "Epoch 87/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7065\n",
      "Epoch 88/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7023\n",
      "Epoch 89/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7028\n",
      "Epoch 90/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7006\n",
      "Epoch 91/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7036\n",
      "Epoch 92/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7034\n",
      "Epoch 93/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7007\n",
      "Epoch 94/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6989\n",
      "Epoch 95/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7016\n",
      "Epoch 96/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7005\n",
      "Epoch 97/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6983\n",
      "Epoch 98/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6981\n",
      "Epoch 99/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6970\n",
      "Epoch 100/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6964\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "New best score: 0.3412005305290222 with params: {'layer_sizes': [128, 64], 'encoding_dim': 8, 'batch_size': 64, 'epochs': 100, 'dropout_rate': 0.3}\n",
      "Testing with layers=[128, 64], encoding_dim=8, batch_size=128, epochs=50, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "8/8 - 1s - 130ms/step - loss: 1.2635\n",
      "Epoch 2/50\n",
      "8/8 - 0s - 3ms/step - loss: 1.1505\n",
      "Epoch 3/50\n",
      "8/8 - 0s - 3ms/step - loss: 1.0765\n",
      "Epoch 4/50\n",
      "8/8 - 0s - 3ms/step - loss: 1.0241\n",
      "Epoch 5/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.9865\n",
      "Epoch 6/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.9546\n",
      "Epoch 7/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.9331\n",
      "Epoch 8/50\n",
      "8/8 - 0s - 9ms/step - loss: 0.9149\n",
      "Epoch 9/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8975\n",
      "Epoch 10/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8854\n",
      "Epoch 11/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8721\n",
      "Epoch 12/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8657\n",
      "Epoch 13/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8562\n",
      "Epoch 14/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8451\n",
      "Epoch 15/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8405\n",
      "Epoch 16/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8325\n",
      "Epoch 17/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8276\n",
      "Epoch 18/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8236\n",
      "Epoch 19/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8175\n",
      "Epoch 20/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8158\n",
      "Epoch 21/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8121\n",
      "Epoch 22/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8065\n",
      "Epoch 23/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.8031\n",
      "Epoch 24/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8007\n",
      "Epoch 25/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7990\n",
      "Epoch 26/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7942\n",
      "Epoch 27/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7913\n",
      "Epoch 28/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7887\n",
      "Epoch 29/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7853\n",
      "Epoch 30/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7831\n",
      "Epoch 31/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7813\n",
      "Epoch 32/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7806\n",
      "Epoch 33/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7787\n",
      "Epoch 34/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7742\n",
      "Epoch 35/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7721\n",
      "Epoch 36/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7724\n",
      "Epoch 37/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7680\n",
      "Epoch 38/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7666\n",
      "Epoch 39/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7662\n",
      "Epoch 40/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7631\n",
      "Epoch 41/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7627\n",
      "Epoch 42/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7608\n",
      "Epoch 43/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7590\n",
      "Epoch 44/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7572\n",
      "Epoch 45/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7569\n",
      "Epoch 46/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7556\n",
      "Epoch 47/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7524\n",
      "Epoch 48/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7506\n",
      "Epoch 49/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7506\n",
      "Epoch 50/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7487\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Testing with layers=[128, 64], encoding_dim=8, batch_size=128, epochs=50, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "8/8 - 1s - 128ms/step - loss: 1.2704\n",
      "Epoch 2/50\n",
      "8/8 - 0s - 3ms/step - loss: 1.1778\n",
      "Epoch 3/50\n",
      "8/8 - 0s - 3ms/step - loss: 1.1065\n",
      "Epoch 4/50\n",
      "8/8 - 0s - 3ms/step - loss: 1.0614\n",
      "Epoch 5/50\n",
      "8/8 - 0s - 3ms/step - loss: 1.0163\n",
      "Epoch 6/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.9867\n",
      "Epoch 7/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.9637\n",
      "Epoch 8/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.9432\n",
      "Epoch 9/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.9237\n",
      "Epoch 10/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.9082\n",
      "Epoch 11/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8979\n",
      "Epoch 12/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8875\n",
      "Epoch 13/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8782\n",
      "Epoch 14/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8716\n",
      "Epoch 15/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8677\n",
      "Epoch 16/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8555\n",
      "Epoch 17/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8551\n",
      "Epoch 18/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8455\n",
      "Epoch 19/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8438\n",
      "Epoch 20/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8387\n",
      "Epoch 21/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8364\n",
      "Epoch 22/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8326\n",
      "Epoch 23/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8274\n",
      "Epoch 24/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8243\n",
      "Epoch 25/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8229\n",
      "Epoch 26/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8175\n",
      "Epoch 27/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.8161\n",
      "Epoch 28/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.8140\n",
      "Epoch 29/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.8129\n",
      "Epoch 30/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8060\n",
      "Epoch 31/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8080\n",
      "Epoch 32/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8050\n",
      "Epoch 33/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8001\n",
      "Epoch 34/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7973\n",
      "Epoch 35/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7951\n",
      "Epoch 36/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7926\n",
      "Epoch 37/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7927\n",
      "Epoch 38/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7893\n",
      "Epoch 39/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7864\n",
      "Epoch 40/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7886\n",
      "Epoch 41/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7827\n",
      "Epoch 42/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7812\n",
      "Epoch 43/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7817\n",
      "Epoch 44/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7814\n",
      "Epoch 45/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7814\n",
      "Epoch 46/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7775\n",
      "Epoch 47/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7797\n",
      "Epoch 48/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7780\n",
      "Epoch 49/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7695\n",
      "Epoch 50/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7743\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Testing with layers=[128, 64], encoding_dim=8, batch_size=128, epochs=100, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "8/8 - 1s - 125ms/step - loss: 1.2393\n",
      "Epoch 2/100\n",
      "8/8 - 0s - 3ms/step - loss: 1.1391\n",
      "Epoch 3/100\n",
      "8/8 - 0s - 3ms/step - loss: 1.0659\n",
      "Epoch 4/100\n",
      "8/8 - 0s - 3ms/step - loss: 1.0173\n",
      "Epoch 5/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.9838\n",
      "Epoch 6/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.9561\n",
      "Epoch 7/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.9347\n",
      "Epoch 8/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.9163\n",
      "Epoch 9/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.9011\n",
      "Epoch 10/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8901\n",
      "Epoch 11/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8800\n",
      "Epoch 12/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.8679\n",
      "Epoch 13/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8604\n",
      "Epoch 14/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8528\n",
      "Epoch 15/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8455\n",
      "Epoch 16/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8370\n",
      "Epoch 17/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8316\n",
      "Epoch 18/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8256\n",
      "Epoch 19/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8243\n",
      "Epoch 20/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.8158\n",
      "Epoch 21/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8126\n",
      "Epoch 22/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8091\n",
      "Epoch 23/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8032\n",
      "Epoch 24/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8013\n",
      "Epoch 25/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7975\n",
      "Epoch 26/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7912\n",
      "Epoch 27/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7903\n",
      "Epoch 28/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7864\n",
      "Epoch 29/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7831\n",
      "Epoch 30/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7783\n",
      "Epoch 31/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7753\n",
      "Epoch 32/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7756\n",
      "Epoch 33/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7682\n",
      "Epoch 34/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7707\n",
      "Epoch 35/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7656\n",
      "Epoch 36/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7633\n",
      "Epoch 37/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7614\n",
      "Epoch 38/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7607\n",
      "Epoch 39/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7574\n",
      "Epoch 40/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7563\n",
      "Epoch 41/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7510\n",
      "Epoch 42/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7487\n",
      "Epoch 43/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7473\n",
      "Epoch 44/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7451\n",
      "Epoch 45/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7449\n",
      "Epoch 46/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7428\n",
      "Epoch 47/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7431\n",
      "Epoch 48/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7390\n",
      "Epoch 49/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7396\n",
      "Epoch 50/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7381\n",
      "Epoch 51/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7372\n",
      "Epoch 52/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7358\n",
      "Epoch 53/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7331\n",
      "Epoch 54/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7310\n",
      "Epoch 55/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7284\n",
      "Epoch 56/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7289\n",
      "Epoch 57/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7299\n",
      "Epoch 58/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7252\n",
      "Epoch 59/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7286\n",
      "Epoch 60/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7237\n",
      "Epoch 61/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7216\n",
      "Epoch 62/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7193\n",
      "Epoch 63/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7198\n",
      "Epoch 64/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7200\n",
      "Epoch 65/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7209\n",
      "Epoch 66/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7146\n",
      "Epoch 67/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7159\n",
      "Epoch 68/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7145\n",
      "Epoch 69/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7163\n",
      "Epoch 70/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7166\n",
      "Epoch 71/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7142\n",
      "Epoch 72/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7115\n",
      "Epoch 73/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7107\n",
      "Epoch 74/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7117\n",
      "Epoch 75/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7094\n",
      "Epoch 76/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7113\n",
      "Epoch 77/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7097\n",
      "Epoch 78/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7080\n",
      "Epoch 79/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7094\n",
      "Epoch 80/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7073\n",
      "Epoch 81/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7069\n",
      "Epoch 82/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7056\n",
      "Epoch 83/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7047\n",
      "Epoch 84/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7023\n",
      "Epoch 85/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7031\n",
      "Epoch 86/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7006\n",
      "Epoch 87/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7039\n",
      "Epoch 88/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7025\n",
      "Epoch 89/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7024\n",
      "Epoch 90/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6997\n",
      "Epoch 91/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7026\n",
      "Epoch 92/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.6996\n",
      "Epoch 93/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6999\n",
      "Epoch 94/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6968\n",
      "Epoch 95/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7000\n",
      "Epoch 96/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6982\n",
      "Epoch 97/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6994\n",
      "Epoch 98/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6964\n",
      "Epoch 99/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6965\n",
      "Epoch 100/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6968\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step\n",
      "Testing with layers=[128, 64], encoding_dim=8, batch_size=128, epochs=100, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "8/8 - 1s - 135ms/step - loss: 1.2952\n",
      "Epoch 2/100\n",
      "8/8 - 0s - 3ms/step - loss: 1.1913\n",
      "Epoch 3/100\n",
      "8/8 - 0s - 3ms/step - loss: 1.1227\n",
      "Epoch 4/100\n",
      "8/8 - 0s - 3ms/step - loss: 1.0621\n",
      "Epoch 5/100\n",
      "8/8 - 0s - 3ms/step - loss: 1.0231\n",
      "Epoch 6/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.9929\n",
      "Epoch 7/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.9635\n",
      "Epoch 8/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.9469\n",
      "Epoch 9/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.9297\n",
      "Epoch 10/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.9151\n",
      "Epoch 11/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.9047\n",
      "Epoch 12/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8943\n",
      "Epoch 13/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8817\n",
      "Epoch 14/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8768\n",
      "Epoch 15/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8695\n",
      "Epoch 16/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8643\n",
      "Epoch 17/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8557\n",
      "Epoch 18/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8551\n",
      "Epoch 19/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8454\n",
      "Epoch 20/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8416\n",
      "Epoch 21/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8349\n",
      "Epoch 22/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8344\n",
      "Epoch 23/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8297\n",
      "Epoch 24/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8244\n",
      "Epoch 25/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8227\n",
      "Epoch 26/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8184\n",
      "Epoch 27/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8164\n",
      "Epoch 28/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8159\n",
      "Epoch 29/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8104\n",
      "Epoch 30/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8088\n",
      "Epoch 31/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8062\n",
      "Epoch 32/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.8035\n",
      "Epoch 33/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8037\n",
      "Epoch 34/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8002\n",
      "Epoch 35/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7964\n",
      "Epoch 36/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7931\n",
      "Epoch 37/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7915\n",
      "Epoch 38/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7903\n",
      "Epoch 39/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7887\n",
      "Epoch 40/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.7890\n",
      "Epoch 41/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7833\n",
      "Epoch 42/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7829\n",
      "Epoch 43/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7841\n",
      "Epoch 44/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7785\n",
      "Epoch 45/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7759\n",
      "Epoch 46/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7768\n",
      "Epoch 47/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7755\n",
      "Epoch 48/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7730\n",
      "Epoch 49/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7715\n",
      "Epoch 50/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7683\n",
      "Epoch 51/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7702\n",
      "Epoch 52/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7668\n",
      "Epoch 53/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7643\n",
      "Epoch 54/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7604\n",
      "Epoch 55/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7625\n",
      "Epoch 56/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7614\n",
      "Epoch 57/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7592\n",
      "Epoch 58/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7591\n",
      "Epoch 59/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7559\n",
      "Epoch 60/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7540\n",
      "Epoch 61/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7555\n",
      "Epoch 62/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7536\n",
      "Epoch 63/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7510\n",
      "Epoch 64/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7508\n",
      "Epoch 65/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7491\n",
      "Epoch 66/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7477\n",
      "Epoch 67/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7476\n",
      "Epoch 68/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7452\n",
      "Epoch 69/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7463\n",
      "Epoch 70/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7442\n",
      "Epoch 71/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7440\n",
      "Epoch 72/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7408\n",
      "Epoch 73/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7417\n",
      "Epoch 74/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7400\n",
      "Epoch 75/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7393\n",
      "Epoch 76/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7385\n",
      "Epoch 77/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7349\n",
      "Epoch 78/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7379\n",
      "Epoch 79/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7332\n",
      "Epoch 80/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7329\n",
      "Epoch 81/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7347\n",
      "Epoch 82/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7324\n",
      "Epoch 83/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7313\n",
      "Epoch 84/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7302\n",
      "Epoch 85/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7285\n",
      "Epoch 86/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7276\n",
      "Epoch 87/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7275\n",
      "Epoch 88/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7269\n",
      "Epoch 89/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7270\n",
      "Epoch 90/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7251\n",
      "Epoch 91/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7255\n",
      "Epoch 92/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7238\n",
      "Epoch 93/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7237\n",
      "Epoch 94/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7223\n",
      "Epoch 95/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7211\n",
      "Epoch 96/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7217\n",
      "Epoch 97/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7208\n",
      "Epoch 98/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7226\n",
      "Epoch 99/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7199\n",
      "Epoch 100/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7208\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Testing with layers=[128, 64], encoding_dim=10, batch_size=32, epochs=50, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "32/32 - 1s - 34ms/step - loss: 1.1114\n",
      "Epoch 2/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.9633\n",
      "Epoch 3/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.9061\n",
      "Epoch 4/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8739\n",
      "Epoch 5/50\n",
      "32/32 - 0s - 1000us/step - loss: 0.8484\n",
      "Epoch 6/50\n",
      "32/32 - 0s - 943us/step - loss: 0.8293\n",
      "Epoch 7/50\n",
      "32/32 - 0s - 936us/step - loss: 0.8106\n",
      "Epoch 8/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7955\n",
      "Epoch 9/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7852\n",
      "Epoch 10/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7751\n",
      "Epoch 11/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7670\n",
      "Epoch 12/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7570\n",
      "Epoch 13/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7539\n",
      "Epoch 14/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7456\n",
      "Epoch 15/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7406\n",
      "Epoch 16/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7350\n",
      "Epoch 17/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7317\n",
      "Epoch 18/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7295\n",
      "Epoch 19/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7233\n",
      "Epoch 20/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7205\n",
      "Epoch 21/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7155\n",
      "Epoch 22/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7120\n",
      "Epoch 23/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7120\n",
      "Epoch 24/50\n",
      "32/32 - 0s - 972us/step - loss: 0.7109\n",
      "Epoch 25/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7069\n",
      "Epoch 26/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7034\n",
      "Epoch 27/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.6991\n",
      "Epoch 28/50\n",
      "32/32 - 0s - 993us/step - loss: 0.6996\n",
      "Epoch 29/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.6960\n",
      "Epoch 30/50\n",
      "32/32 - 0s - 941us/step - loss: 0.6944\n",
      "Epoch 31/50\n",
      "32/32 - 0s - 969us/step - loss: 0.6940\n",
      "Epoch 32/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.6926\n",
      "Epoch 33/50\n",
      "32/32 - 0s - 953us/step - loss: 0.6904\n",
      "Epoch 34/50\n",
      "32/32 - 0s - 953us/step - loss: 0.6894\n",
      "Epoch 35/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.6866\n",
      "Epoch 36/50\n",
      "32/32 - 0s - 964us/step - loss: 0.6844\n",
      "Epoch 37/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.6835\n",
      "Epoch 38/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.6846\n",
      "Epoch 39/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.6811\n",
      "Epoch 40/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.6805\n",
      "Epoch 41/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.6826\n",
      "Epoch 42/50\n",
      "32/32 - 0s - 4ms/step - loss: 0.6779\n",
      "Epoch 43/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.6754\n",
      "Epoch 44/50\n",
      "32/32 - 0s - 975us/step - loss: 0.6758\n",
      "Epoch 45/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.6734\n",
      "Epoch 46/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.6735\n",
      "Epoch 47/50\n",
      "32/32 - 0s - 963us/step - loss: 0.6757\n",
      "Epoch 48/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.6708\n",
      "Epoch 49/50\n",
      "32/32 - 0s - 976us/step - loss: 0.6697\n",
      "Epoch 50/50\n",
      "32/32 - 0s - 986us/step - loss: 0.6685\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Testing with layers=[128, 64], encoding_dim=10, batch_size=32, epochs=50, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "32/32 - 1s - 44ms/step - loss: 1.1716\n",
      "Epoch 2/50\n",
      "32/32 - 0s - 1ms/step - loss: 1.0143\n",
      "Epoch 3/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.9462\n",
      "Epoch 4/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.9083\n",
      "Epoch 5/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8813\n",
      "Epoch 6/50\n",
      "32/32 - 0s - 908us/step - loss: 0.8589\n",
      "Epoch 7/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8439\n",
      "Epoch 8/50\n",
      "32/32 - 0s - 999us/step - loss: 0.8302\n",
      "Epoch 9/50\n",
      "32/32 - 0s - 935us/step - loss: 0.8171\n",
      "Epoch 10/50\n",
      "32/32 - 0s - 969us/step - loss: 0.8063\n",
      "Epoch 11/50\n",
      "32/32 - 0s - 978us/step - loss: 0.7979\n",
      "Epoch 12/50\n",
      "32/32 - 0s - 894us/step - loss: 0.7897\n",
      "Epoch 13/50\n",
      "32/32 - 0s - 940us/step - loss: 0.7824\n",
      "Epoch 14/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7733\n",
      "Epoch 15/50\n",
      "32/32 - 0s - 899us/step - loss: 0.7668\n",
      "Epoch 16/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7663\n",
      "Epoch 17/50\n",
      "32/32 - 0s - 965us/step - loss: 0.7623\n",
      "Epoch 18/50\n",
      "32/32 - 0s - 963us/step - loss: 0.7579\n",
      "Epoch 19/50\n",
      "32/32 - 0s - 938us/step - loss: 0.7543\n",
      "Epoch 20/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7512\n",
      "Epoch 21/50\n",
      "32/32 - 0s - 903us/step - loss: 0.7492\n",
      "Epoch 22/50\n",
      "32/32 - 0s - 918us/step - loss: 0.7454\n",
      "Epoch 23/50\n",
      "32/32 - 0s - 987us/step - loss: 0.7454\n",
      "Epoch 24/50\n",
      "32/32 - 0s - 972us/step - loss: 0.7426\n",
      "Epoch 25/50\n",
      "32/32 - 0s - 937us/step - loss: 0.7396\n",
      "Epoch 26/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7411\n",
      "Epoch 27/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7385\n",
      "Epoch 28/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7356\n",
      "Epoch 29/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7312\n",
      "Epoch 30/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7300\n",
      "Epoch 31/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7347\n",
      "Epoch 32/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7297\n",
      "Epoch 33/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7270\n",
      "Epoch 34/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7233\n",
      "Epoch 35/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7281\n",
      "Epoch 36/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7256\n",
      "Epoch 37/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7231\n",
      "Epoch 38/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7231\n",
      "Epoch 39/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7202\n",
      "Epoch 40/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7150\n",
      "Epoch 41/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7153\n",
      "Epoch 42/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7169\n",
      "Epoch 43/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7129\n",
      "Epoch 44/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7154\n",
      "Epoch 45/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7109\n",
      "Epoch 46/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7132\n",
      "Epoch 47/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7133\n",
      "Epoch 48/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7124\n",
      "Epoch 49/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7084\n",
      "Epoch 50/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7123\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Testing with layers=[128, 64], encoding_dim=10, batch_size=32, epochs=100, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "32/32 - 1s - 35ms/step - loss: 1.1567\n",
      "Epoch 2/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.9895\n",
      "Epoch 3/100\n",
      "32/32 - 0s - 996us/step - loss: 0.9108\n",
      "Epoch 4/100\n",
      "32/32 - 0s - 936us/step - loss: 0.8752\n",
      "Epoch 5/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8449\n",
      "Epoch 6/100\n",
      "32/32 - 0s - 903us/step - loss: 0.8238\n",
      "Epoch 7/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8102\n",
      "Epoch 8/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7921\n",
      "Epoch 9/100\n",
      "32/32 - 0s - 984us/step - loss: 0.7846\n",
      "Epoch 10/100\n",
      "32/32 - 0s - 930us/step - loss: 0.7708\n",
      "Epoch 11/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7632\n",
      "Epoch 12/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7584\n",
      "Epoch 13/100\n",
      "32/32 - 0s - 911us/step - loss: 0.7515\n",
      "Epoch 14/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7449\n",
      "Epoch 15/100\n",
      "32/32 - 0s - 969us/step - loss: 0.7425\n",
      "Epoch 16/100\n",
      "32/32 - 0s - 978us/step - loss: 0.7373\n",
      "Epoch 17/100\n",
      "32/32 - 0s - 990us/step - loss: 0.7334\n",
      "Epoch 18/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7277\n",
      "Epoch 19/100\n",
      "32/32 - 0s - 983us/step - loss: 0.7267\n",
      "Epoch 20/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7218\n",
      "Epoch 21/100\n",
      "32/32 - 0s - 952us/step - loss: 0.7226\n",
      "Epoch 22/100\n",
      "32/32 - 0s - 983us/step - loss: 0.7183\n",
      "Epoch 23/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7164\n",
      "Epoch 24/100\n",
      "32/32 - 0s - 986us/step - loss: 0.7153\n",
      "Epoch 25/100\n",
      "32/32 - 0s - 988us/step - loss: 0.7111\n",
      "Epoch 26/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7092\n",
      "Epoch 27/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7071\n",
      "Epoch 28/100\n",
      "32/32 - 0s - 918us/step - loss: 0.7083\n",
      "Epoch 29/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7049\n",
      "Epoch 30/100\n",
      "32/32 - 0s - 997us/step - loss: 0.6997\n",
      "Epoch 31/100\n",
      "32/32 - 0s - 964us/step - loss: 0.7019\n",
      "Epoch 32/100\n",
      "32/32 - 0s - 924us/step - loss: 0.6979\n",
      "Epoch 33/100\n",
      "32/32 - 0s - 984us/step - loss: 0.6984\n",
      "Epoch 34/100\n",
      "32/32 - 0s - 968us/step - loss: 0.6946\n",
      "Epoch 35/100\n",
      "32/32 - 0s - 965us/step - loss: 0.6940\n",
      "Epoch 36/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6929\n",
      "Epoch 37/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6923\n",
      "Epoch 38/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6907\n",
      "Epoch 39/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6897\n",
      "Epoch 40/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6862\n",
      "Epoch 41/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6842\n",
      "Epoch 42/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6855\n",
      "Epoch 43/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6837\n",
      "Epoch 44/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6836\n",
      "Epoch 45/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6797\n",
      "Epoch 46/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6797\n",
      "Epoch 47/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6769\n",
      "Epoch 48/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6759\n",
      "Epoch 49/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.6747\n",
      "Epoch 50/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.6726\n",
      "Epoch 51/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.6717\n",
      "Epoch 52/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6742\n",
      "Epoch 53/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.6693\n",
      "Epoch 54/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6706\n",
      "Epoch 55/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.6716\n",
      "Epoch 56/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6670\n",
      "Epoch 57/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6699\n",
      "Epoch 58/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6656\n",
      "Epoch 59/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6660\n",
      "Epoch 60/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6649\n",
      "Epoch 61/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6615\n",
      "Epoch 62/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6642\n",
      "Epoch 63/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6649\n",
      "Epoch 64/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6631\n",
      "Epoch 65/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6594\n",
      "Epoch 66/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6619\n",
      "Epoch 67/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6604\n",
      "Epoch 68/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6623\n",
      "Epoch 69/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6606\n",
      "Epoch 70/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6618\n",
      "Epoch 71/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6601\n",
      "Epoch 72/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6571\n",
      "Epoch 73/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6576\n",
      "Epoch 74/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6591\n",
      "Epoch 75/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6547\n",
      "Epoch 76/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6584\n",
      "Epoch 77/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6576\n",
      "Epoch 78/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6492\n",
      "Epoch 79/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6570\n",
      "Epoch 80/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6547\n",
      "Epoch 81/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6537\n",
      "Epoch 82/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6549\n",
      "Epoch 83/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6544\n",
      "Epoch 84/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6530\n",
      "Epoch 85/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6512\n",
      "Epoch 86/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6518\n",
      "Epoch 87/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6508\n",
      "Epoch 88/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6492\n",
      "Epoch 89/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6485\n",
      "Epoch 90/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6513\n",
      "Epoch 91/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6513\n",
      "Epoch 92/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6515\n",
      "Epoch 93/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6508\n",
      "Epoch 94/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6483\n",
      "Epoch 95/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6481\n",
      "Epoch 96/100\n",
      "32/32 - 0s - 959us/step - loss: 0.6487\n",
      "Epoch 97/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6446\n",
      "Epoch 98/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6488\n",
      "Epoch 99/100\n",
      "32/32 - 0s - 956us/step - loss: 0.6474\n",
      "Epoch 100/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6448\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Testing with layers=[128, 64], encoding_dim=10, batch_size=32, epochs=100, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "32/32 - 1s - 33ms/step - loss: 1.1771\n",
      "Epoch 2/100\n",
      "32/32 - 0s - 1ms/step - loss: 1.0264\n",
      "Epoch 3/100\n",
      "32/32 - 0s - 989us/step - loss: 0.9627\n",
      "Epoch 4/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.9183\n",
      "Epoch 5/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8956\n",
      "Epoch 6/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8725\n",
      "Epoch 7/100\n",
      "32/32 - 0s - 992us/step - loss: 0.8538\n",
      "Epoch 8/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8413\n",
      "Epoch 9/100\n",
      "32/32 - 0s - 946us/step - loss: 0.8274\n",
      "Epoch 10/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8171\n",
      "Epoch 11/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8075\n",
      "Epoch 12/100\n",
      "32/32 - 0s - 983us/step - loss: 0.7979\n",
      "Epoch 13/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7931\n",
      "Epoch 14/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7850\n",
      "Epoch 15/100\n",
      "32/32 - 0s - 987us/step - loss: 0.7806\n",
      "Epoch 16/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7728\n",
      "Epoch 17/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7694\n",
      "Epoch 18/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7703\n",
      "Epoch 19/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7590\n",
      "Epoch 20/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7615\n",
      "Epoch 21/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7550\n",
      "Epoch 22/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7524\n",
      "Epoch 23/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7503\n",
      "Epoch 24/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7464\n",
      "Epoch 25/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7415\n",
      "Epoch 26/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7397\n",
      "Epoch 27/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7344\n",
      "Epoch 28/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7418\n",
      "Epoch 29/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7366\n",
      "Epoch 30/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7332\n",
      "Epoch 31/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7324\n",
      "Epoch 32/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7294\n",
      "Epoch 33/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7304\n",
      "Epoch 34/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7253\n",
      "Epoch 35/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7225\n",
      "Epoch 36/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7249\n",
      "Epoch 37/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7212\n",
      "Epoch 38/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7195\n",
      "Epoch 39/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7183\n",
      "Epoch 40/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7199\n",
      "Epoch 41/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7161\n",
      "Epoch 42/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7170\n",
      "Epoch 43/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7187\n",
      "Epoch 44/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7124\n",
      "Epoch 45/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7113\n",
      "Epoch 46/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7097\n",
      "Epoch 47/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7114\n",
      "Epoch 48/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7082\n",
      "Epoch 49/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7072\n",
      "Epoch 50/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7053\n",
      "Epoch 51/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7046\n",
      "Epoch 52/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7065\n",
      "Epoch 53/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7039\n",
      "Epoch 54/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7004\n",
      "Epoch 55/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7035\n",
      "Epoch 56/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7012\n",
      "Epoch 57/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7023\n",
      "Epoch 58/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6974\n",
      "Epoch 59/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6975\n",
      "Epoch 60/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6987\n",
      "Epoch 61/100\n",
      "32/32 - 0s - 968us/step - loss: 0.6980\n",
      "Epoch 62/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6979\n",
      "Epoch 63/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6959\n",
      "Epoch 64/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6943\n",
      "Epoch 65/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6903\n",
      "Epoch 66/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6956\n",
      "Epoch 67/100\n",
      "32/32 - 0s - 996us/step - loss: 0.6943\n",
      "Epoch 68/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6937\n",
      "Epoch 69/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6867\n",
      "Epoch 70/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6908\n",
      "Epoch 71/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6906\n",
      "Epoch 72/100\n",
      "32/32 - 0s - 1000us/step - loss: 0.6876\n",
      "Epoch 73/100\n",
      "32/32 - 0s - 957us/step - loss: 0.6884\n",
      "Epoch 74/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.6882\n",
      "Epoch 75/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6866\n",
      "Epoch 76/100\n",
      "32/32 - 0s - 980us/step - loss: 0.6881\n",
      "Epoch 77/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6912\n",
      "Epoch 78/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6864\n",
      "Epoch 79/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6841\n",
      "Epoch 80/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6813\n",
      "Epoch 81/100\n",
      "32/32 - 0s - 956us/step - loss: 0.6849\n",
      "Epoch 82/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6813\n",
      "Epoch 83/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6829\n",
      "Epoch 84/100\n",
      "32/32 - 0s - 970us/step - loss: 0.6775\n",
      "Epoch 85/100\n",
      "32/32 - 0s - 979us/step - loss: 0.6823\n",
      "Epoch 86/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6781\n",
      "Epoch 87/100\n",
      "32/32 - 0s - 972us/step - loss: 0.6804\n",
      "Epoch 88/100\n",
      "32/32 - 0s - 953us/step - loss: 0.6798\n",
      "Epoch 89/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6812\n",
      "Epoch 90/100\n",
      "32/32 - 0s - 988us/step - loss: 0.6790\n",
      "Epoch 91/100\n",
      "32/32 - 0s - 936us/step - loss: 0.6756\n",
      "Epoch 92/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6771\n",
      "Epoch 93/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6754\n",
      "Epoch 94/100\n",
      "32/32 - 0s - 933us/step - loss: 0.6798\n",
      "Epoch 95/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6776\n",
      "Epoch 96/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6761\n",
      "Epoch 97/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6760\n",
      "Epoch 98/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6761\n",
      "Epoch 99/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6737\n",
      "Epoch 100/100\n",
      "32/32 - 0s - 981us/step - loss: 0.6704\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n",
      "Testing with layers=[128, 64], encoding_dim=10, batch_size=64, epochs=50, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "16/16 - 1s - 64ms/step - loss: 1.1835\n",
      "Epoch 2/50\n",
      "16/16 - 0s - 2ms/step - loss: 1.0346\n",
      "Epoch 3/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.9589\n",
      "Epoch 4/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.9136\n",
      "Epoch 5/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8847\n",
      "Epoch 6/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.8606\n",
      "Epoch 7/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8446\n",
      "Epoch 8/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8258\n",
      "Epoch 9/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8108\n",
      "Epoch 10/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.8017\n",
      "Epoch 11/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7900\n",
      "Epoch 12/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7796\n",
      "Epoch 13/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7723\n",
      "Epoch 14/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7685\n",
      "Epoch 15/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7573\n",
      "Epoch 16/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7561\n",
      "Epoch 17/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7476\n",
      "Epoch 18/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7441\n",
      "Epoch 19/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7407\n",
      "Epoch 20/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7343\n",
      "Epoch 21/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7307\n",
      "Epoch 22/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7250\n",
      "Epoch 23/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7240\n",
      "Epoch 24/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7205\n",
      "Epoch 25/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7169\n",
      "Epoch 26/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7174\n",
      "Epoch 27/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7124\n",
      "Epoch 28/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7095\n",
      "Epoch 29/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7046\n",
      "Epoch 30/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7044\n",
      "Epoch 31/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7026\n",
      "Epoch 32/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.6995\n",
      "Epoch 33/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.6984\n",
      "Epoch 34/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.6966\n",
      "Epoch 35/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.6941\n",
      "Epoch 36/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.6935\n",
      "Epoch 37/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.6916\n",
      "Epoch 38/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.6895\n",
      "Epoch 39/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.6869\n",
      "Epoch 40/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.6877\n",
      "Epoch 41/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.6842\n",
      "Epoch 42/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.6854\n",
      "Epoch 43/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.6834\n",
      "Epoch 44/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.6804\n",
      "Epoch 45/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.6792\n",
      "Epoch 46/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.6807\n",
      "Epoch 47/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.6763\n",
      "Epoch 48/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.6774\n",
      "Epoch 49/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.6752\n",
      "Epoch 50/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.6718\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Testing with layers=[128, 64], encoding_dim=10, batch_size=64, epochs=50, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "16/16 - 1s - 69ms/step - loss: 1.2312\n",
      "Epoch 2/50\n",
      "16/16 - 0s - 2ms/step - loss: 1.0958\n",
      "Epoch 3/50\n",
      "16/16 - 0s - 2ms/step - loss: 1.0137\n",
      "Epoch 4/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.9625\n",
      "Epoch 5/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.9325\n",
      "Epoch 6/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.9058\n",
      "Epoch 7/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8863\n",
      "Epoch 8/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8680\n",
      "Epoch 9/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8526\n",
      "Epoch 10/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8405\n",
      "Epoch 11/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8316\n",
      "Epoch 12/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8217\n",
      "Epoch 13/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8133\n",
      "Epoch 14/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8045\n",
      "Epoch 15/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7969\n",
      "Epoch 16/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7915\n",
      "Epoch 17/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7861\n",
      "Epoch 18/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7823\n",
      "Epoch 19/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7763\n",
      "Epoch 20/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7710\n",
      "Epoch 21/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7650\n",
      "Epoch 22/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7615\n",
      "Epoch 23/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7582\n",
      "Epoch 24/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7567\n",
      "Epoch 25/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7518\n",
      "Epoch 26/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7497\n",
      "Epoch 27/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7477\n",
      "Epoch 28/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7448\n",
      "Epoch 29/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7427\n",
      "Epoch 30/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7407\n",
      "Epoch 31/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7363\n",
      "Epoch 32/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7343\n",
      "Epoch 33/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7339\n",
      "Epoch 34/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7312\n",
      "Epoch 35/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7296\n",
      "Epoch 36/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7261\n",
      "Epoch 37/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7273\n",
      "Epoch 38/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7252\n",
      "Epoch 39/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7235\n",
      "Epoch 40/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7204\n",
      "Epoch 41/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7203\n",
      "Epoch 42/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7192\n",
      "Epoch 43/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7171\n",
      "Epoch 44/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7164\n",
      "Epoch 45/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7158\n",
      "Epoch 46/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7122\n",
      "Epoch 47/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7118\n",
      "Epoch 48/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7132\n",
      "Epoch 49/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7107\n",
      "Epoch 50/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7095\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Testing with layers=[128, 64], encoding_dim=10, batch_size=64, epochs=100, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "16/16 - 1s - 65ms/step - loss: 1.2103\n",
      "Epoch 2/100\n",
      "16/16 - 0s - 2ms/step - loss: 1.0642\n",
      "Epoch 3/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.9813\n",
      "Epoch 4/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.9274\n",
      "Epoch 5/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.8919\n",
      "Epoch 6/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.8701\n",
      "Epoch 7/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.8467\n",
      "Epoch 8/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8300\n",
      "Epoch 9/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8193\n",
      "Epoch 10/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.8057\n",
      "Epoch 11/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7948\n",
      "Epoch 12/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7880\n",
      "Epoch 13/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7795\n",
      "Epoch 14/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7732\n",
      "Epoch 15/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7663\n",
      "Epoch 16/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7603\n",
      "Epoch 17/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7573\n",
      "Epoch 18/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7515\n",
      "Epoch 19/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7470\n",
      "Epoch 20/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7463\n",
      "Epoch 21/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7420\n",
      "Epoch 22/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7368\n",
      "Epoch 23/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7333\n",
      "Epoch 24/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7350\n",
      "Epoch 25/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7284\n",
      "Epoch 26/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7244\n",
      "Epoch 27/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7250\n",
      "Epoch 28/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7207\n",
      "Epoch 29/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7196\n",
      "Epoch 30/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7163\n",
      "Epoch 31/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7109\n",
      "Epoch 32/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7136\n",
      "Epoch 33/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7084\n",
      "Epoch 34/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7084\n",
      "Epoch 35/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7071\n",
      "Epoch 36/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7058\n",
      "Epoch 37/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7008\n",
      "Epoch 38/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6998\n",
      "Epoch 39/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7001\n",
      "Epoch 40/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6978\n",
      "Epoch 41/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6937\n",
      "Epoch 42/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6928\n",
      "Epoch 43/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6914\n",
      "Epoch 44/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6926\n",
      "Epoch 45/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6890\n",
      "Epoch 46/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6884\n",
      "Epoch 47/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6895\n",
      "Epoch 48/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6864\n",
      "Epoch 49/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6893\n",
      "Epoch 50/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6871\n",
      "Epoch 51/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6833\n",
      "Epoch 52/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6825\n",
      "Epoch 53/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6816\n",
      "Epoch 54/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6819\n",
      "Epoch 55/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6799\n",
      "Epoch 56/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6788\n",
      "Epoch 57/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6816\n",
      "Epoch 58/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6783\n",
      "Epoch 59/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6772\n",
      "Epoch 60/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6747\n",
      "Epoch 61/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6762\n",
      "Epoch 62/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.6759\n",
      "Epoch 63/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6732\n",
      "Epoch 64/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6707\n",
      "Epoch 65/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6700\n",
      "Epoch 66/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6711\n",
      "Epoch 67/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6707\n",
      "Epoch 68/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.6688\n",
      "Epoch 69/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6668\n",
      "Epoch 70/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6670\n",
      "Epoch 71/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6659\n",
      "Epoch 72/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6694\n",
      "Epoch 73/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6659\n",
      "Epoch 74/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6637\n",
      "Epoch 75/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6639\n",
      "Epoch 76/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6635\n",
      "Epoch 77/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6661\n",
      "Epoch 78/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6657\n",
      "Epoch 79/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6650\n",
      "Epoch 80/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6659\n",
      "Epoch 81/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6622\n",
      "Epoch 82/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6636\n",
      "Epoch 83/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6595\n",
      "Epoch 84/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6626\n",
      "Epoch 85/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6588\n",
      "Epoch 86/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6603\n",
      "Epoch 87/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6591\n",
      "Epoch 88/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6611\n",
      "Epoch 89/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6597\n",
      "Epoch 90/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6590\n",
      "Epoch 91/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6568\n",
      "Epoch 92/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6595\n",
      "Epoch 93/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6575\n",
      "Epoch 94/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6584\n",
      "Epoch 95/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6556\n",
      "Epoch 96/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6563\n",
      "Epoch 97/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6563\n",
      "Epoch 98/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6561\n",
      "Epoch 99/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6524\n",
      "Epoch 100/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6543\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Testing with layers=[128, 64], encoding_dim=10, batch_size=64, epochs=100, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "16/16 - 1s - 67ms/step - loss: 1.2266\n",
      "Epoch 2/100\n",
      "16/16 - 0s - 2ms/step - loss: 1.0924\n",
      "Epoch 3/100\n",
      "16/16 - 0s - 3ms/step - loss: 1.0113\n",
      "Epoch 4/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.9576\n",
      "Epoch 5/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.9270\n",
      "Epoch 6/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.9035\n",
      "Epoch 7/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8875\n",
      "Epoch 8/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.8666\n",
      "Epoch 9/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8560\n",
      "Epoch 10/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8437\n",
      "Epoch 11/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8319\n",
      "Epoch 12/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.8231\n",
      "Epoch 13/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8149\n",
      "Epoch 14/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8100\n",
      "Epoch 15/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8000\n",
      "Epoch 16/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7960\n",
      "Epoch 17/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7902\n",
      "Epoch 18/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7824\n",
      "Epoch 19/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7796\n",
      "Epoch 20/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7735\n",
      "Epoch 21/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7689\n",
      "Epoch 22/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7659\n",
      "Epoch 23/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7653\n",
      "Epoch 24/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7612\n",
      "Epoch 25/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7582\n",
      "Epoch 26/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7538\n",
      "Epoch 27/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7503\n",
      "Epoch 28/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7493\n",
      "Epoch 29/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7434\n",
      "Epoch 30/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7423\n",
      "Epoch 31/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7411\n",
      "Epoch 32/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7393\n",
      "Epoch 33/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7348\n",
      "Epoch 34/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7358\n",
      "Epoch 35/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7344\n",
      "Epoch 36/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7283\n",
      "Epoch 37/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7279\n",
      "Epoch 38/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7302\n",
      "Epoch 39/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7242\n",
      "Epoch 40/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7267\n",
      "Epoch 41/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7206\n",
      "Epoch 42/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7198\n",
      "Epoch 43/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7185\n",
      "Epoch 44/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7185\n",
      "Epoch 45/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7165\n",
      "Epoch 46/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7149\n",
      "Epoch 47/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7147\n",
      "Epoch 48/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7122\n",
      "Epoch 49/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7125\n",
      "Epoch 50/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7099\n",
      "Epoch 51/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7093\n",
      "Epoch 52/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7087\n",
      "Epoch 53/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7056\n",
      "Epoch 54/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7106\n",
      "Epoch 55/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.7055\n",
      "Epoch 56/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7038\n",
      "Epoch 57/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7040\n",
      "Epoch 58/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7051\n",
      "Epoch 59/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7021\n",
      "Epoch 60/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7022\n",
      "Epoch 61/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6983\n",
      "Epoch 62/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7037\n",
      "Epoch 63/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6988\n",
      "Epoch 64/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6978\n",
      "Epoch 65/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6958\n",
      "Epoch 66/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6980\n",
      "Epoch 67/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6950\n",
      "Epoch 68/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6938\n",
      "Epoch 69/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6962\n",
      "Epoch 70/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6918\n",
      "Epoch 71/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6930\n",
      "Epoch 72/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6896\n",
      "Epoch 73/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6884\n",
      "Epoch 74/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6896\n",
      "Epoch 75/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6871\n",
      "Epoch 76/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6876\n",
      "Epoch 77/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6889\n",
      "Epoch 78/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6876\n",
      "Epoch 79/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6876\n",
      "Epoch 80/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6855\n",
      "Epoch 81/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6865\n",
      "Epoch 82/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6821\n",
      "Epoch 83/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6855\n",
      "Epoch 84/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6864\n",
      "Epoch 85/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6840\n",
      "Epoch 86/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6848\n",
      "Epoch 87/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6823\n",
      "Epoch 88/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6821\n",
      "Epoch 89/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6821\n",
      "Epoch 90/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6826\n",
      "Epoch 91/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6831\n",
      "Epoch 92/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6786\n",
      "Epoch 93/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6772\n",
      "Epoch 94/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6772\n",
      "Epoch 95/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6787\n",
      "Epoch 96/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6751\n",
      "Epoch 97/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6775\n",
      "Epoch 98/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6740\n",
      "Epoch 99/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6762\n",
      "Epoch 100/100\n",
      "16/16 - 0s - 1ms/step - loss: 0.6766\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n",
      "Testing with layers=[128, 64], encoding_dim=10, batch_size=128, epochs=50, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "8/8 - 1s - 134ms/step - loss: 1.2384\n",
      "Epoch 2/50\n",
      "8/8 - 0s - 3ms/step - loss: 1.1355\n",
      "Epoch 3/50\n",
      "8/8 - 0s - 3ms/step - loss: 1.0709\n",
      "Epoch 4/50\n",
      "8/8 - 0s - 3ms/step - loss: 1.0135\n",
      "Epoch 5/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.9718\n",
      "Epoch 6/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.9435\n",
      "Epoch 7/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.9196\n",
      "Epoch 8/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8997\n",
      "Epoch 9/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.8824\n",
      "Epoch 10/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.8673\n",
      "Epoch 11/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.8569\n",
      "Epoch 12/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8470\n",
      "Epoch 13/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8355\n",
      "Epoch 14/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.8267\n",
      "Epoch 15/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8172\n",
      "Epoch 16/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8093\n",
      "Epoch 17/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8029\n",
      "Epoch 18/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.7952\n",
      "Epoch 19/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7888\n",
      "Epoch 20/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7835\n",
      "Epoch 21/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7793\n",
      "Epoch 22/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7748\n",
      "Epoch 23/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7678\n",
      "Epoch 24/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7623\n",
      "Epoch 25/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7591\n",
      "Epoch 26/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7543\n",
      "Epoch 27/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.7493\n",
      "Epoch 28/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.7469\n",
      "Epoch 29/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.7418\n",
      "Epoch 30/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7409\n",
      "Epoch 31/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7369\n",
      "Epoch 32/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7339\n",
      "Epoch 33/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7301\n",
      "Epoch 34/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7289\n",
      "Epoch 35/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7248\n",
      "Epoch 36/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7248\n",
      "Epoch 37/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7213\n",
      "Epoch 38/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7203\n",
      "Epoch 39/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7164\n",
      "Epoch 40/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7139\n",
      "Epoch 41/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7135\n",
      "Epoch 42/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7109\n",
      "Epoch 43/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7105\n",
      "Epoch 44/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7086\n",
      "Epoch 45/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7067\n",
      "Epoch 46/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7029\n",
      "Epoch 47/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7033\n",
      "Epoch 48/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7035\n",
      "Epoch 49/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7013\n",
      "Epoch 50/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7008\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Testing with layers=[128, 64], encoding_dim=10, batch_size=128, epochs=50, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "8/8 - 1s - 134ms/step - loss: 1.2402\n",
      "Epoch 2/50\n",
      "8/8 - 0s - 3ms/step - loss: 1.1383\n",
      "Epoch 3/50\n",
      "8/8 - 0s - 3ms/step - loss: 1.0765\n",
      "Epoch 4/50\n",
      "8/8 - 0s - 3ms/step - loss: 1.0238\n",
      "Epoch 5/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.9890\n",
      "Epoch 6/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.9619\n",
      "Epoch 7/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.9401\n",
      "Epoch 8/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.9194\n",
      "Epoch 9/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.9041\n",
      "Epoch 10/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.8918\n",
      "Epoch 11/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8804\n",
      "Epoch 12/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8668\n",
      "Epoch 13/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8609\n",
      "Epoch 14/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8507\n",
      "Epoch 15/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8424\n",
      "Epoch 16/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.8334\n",
      "Epoch 17/50\n",
      "8/8 - 0s - 8ms/step - loss: 0.8247\n",
      "Epoch 18/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8192\n",
      "Epoch 19/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.8106\n",
      "Epoch 20/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8076\n",
      "Epoch 21/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8005\n",
      "Epoch 22/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7982\n",
      "Epoch 23/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7921\n",
      "Epoch 24/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7878\n",
      "Epoch 25/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7849\n",
      "Epoch 26/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7809\n",
      "Epoch 27/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7750\n",
      "Epoch 28/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7701\n",
      "Epoch 29/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7729\n",
      "Epoch 30/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7666\n",
      "Epoch 31/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7634\n",
      "Epoch 32/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7621\n",
      "Epoch 33/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7579\n",
      "Epoch 34/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7541\n",
      "Epoch 35/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7531\n",
      "Epoch 36/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7513\n",
      "Epoch 37/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7477\n",
      "Epoch 38/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7512\n",
      "Epoch 39/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7460\n",
      "Epoch 40/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7454\n",
      "Epoch 41/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7430\n",
      "Epoch 42/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7389\n",
      "Epoch 43/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7389\n",
      "Epoch 44/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7385\n",
      "Epoch 45/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7384\n",
      "Epoch 46/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7370\n",
      "Epoch 47/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7342\n",
      "Epoch 48/50\n",
      "8/8 - 0s - 2ms/step - loss: 0.7326\n",
      "Epoch 49/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7310\n",
      "Epoch 50/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7290\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Testing with layers=[128, 64], encoding_dim=10, batch_size=128, epochs=100, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "8/8 - 1s - 131ms/step - loss: 1.2092\n",
      "Epoch 2/100\n",
      "8/8 - 0s - 3ms/step - loss: 1.1114\n",
      "Epoch 3/100\n",
      "8/8 - 0s - 3ms/step - loss: 1.0429\n",
      "Epoch 4/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.9961\n",
      "Epoch 5/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.9594\n",
      "Epoch 6/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.9280\n",
      "Epoch 7/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.9049\n",
      "Epoch 8/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8855\n",
      "Epoch 9/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8699\n",
      "Epoch 10/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8565\n",
      "Epoch 11/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8423\n",
      "Epoch 12/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8352\n",
      "Epoch 13/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8208\n",
      "Epoch 14/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8125\n",
      "Epoch 15/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8068\n",
      "Epoch 16/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8029\n",
      "Epoch 17/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7947\n",
      "Epoch 18/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7866\n",
      "Epoch 19/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7802\n",
      "Epoch 20/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7756\n",
      "Epoch 21/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7696\n",
      "Epoch 22/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7680\n",
      "Epoch 23/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7637\n",
      "Epoch 24/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7617\n",
      "Epoch 25/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7536\n",
      "Epoch 26/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7533\n",
      "Epoch 27/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7497\n",
      "Epoch 28/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7450\n",
      "Epoch 29/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7415\n",
      "Epoch 30/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7414\n",
      "Epoch 31/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7358\n",
      "Epoch 32/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7343\n",
      "Epoch 33/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7330\n",
      "Epoch 34/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7312\n",
      "Epoch 35/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7275\n",
      "Epoch 36/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7264\n",
      "Epoch 37/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7227\n",
      "Epoch 38/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7204\n",
      "Epoch 39/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7198\n",
      "Epoch 40/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7165\n",
      "Epoch 41/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7151\n",
      "Epoch 42/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7133\n",
      "Epoch 43/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7103\n",
      "Epoch 44/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7112\n",
      "Epoch 45/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7104\n",
      "Epoch 46/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7071\n",
      "Epoch 47/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7054\n",
      "Epoch 48/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7055\n",
      "Epoch 49/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7012\n",
      "Epoch 50/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7019\n",
      "Epoch 51/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6995\n",
      "Epoch 52/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6985\n",
      "Epoch 53/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6986\n",
      "Epoch 54/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6995\n",
      "Epoch 55/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6966\n",
      "Epoch 56/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6939\n",
      "Epoch 57/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6946\n",
      "Epoch 58/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6938\n",
      "Epoch 59/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6935\n",
      "Epoch 60/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6924\n",
      "Epoch 61/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.6899\n",
      "Epoch 62/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6884\n",
      "Epoch 63/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6889\n",
      "Epoch 64/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6888\n",
      "Epoch 65/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.6848\n",
      "Epoch 66/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.6838\n",
      "Epoch 67/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.6855\n",
      "Epoch 68/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6827\n",
      "Epoch 69/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6806\n",
      "Epoch 70/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6822\n",
      "Epoch 71/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6793\n",
      "Epoch 72/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6793\n",
      "Epoch 73/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6794\n",
      "Epoch 74/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6785\n",
      "Epoch 75/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6779\n",
      "Epoch 76/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6744\n",
      "Epoch 77/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6743\n",
      "Epoch 78/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.6736\n",
      "Epoch 79/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6738\n",
      "Epoch 80/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6720\n",
      "Epoch 81/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6739\n",
      "Epoch 82/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.6698\n",
      "Epoch 83/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.6703\n",
      "Epoch 84/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6726\n",
      "Epoch 85/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6704\n",
      "Epoch 86/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6696\n",
      "Epoch 87/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6693\n",
      "Epoch 88/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.6691\n",
      "Epoch 89/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.6666\n",
      "Epoch 90/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6674\n",
      "Epoch 91/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6693\n",
      "Epoch 92/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6658\n",
      "Epoch 93/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6669\n",
      "Epoch 94/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6651\n",
      "Epoch 95/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6644\n",
      "Epoch 96/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.6627\n",
      "Epoch 97/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.6627\n",
      "Epoch 98/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.6640\n",
      "Epoch 99/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6626\n",
      "Epoch 100/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.6609\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Testing with layers=[128, 64], encoding_dim=10, batch_size=128, epochs=100, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "8/8 - 1s - 134ms/step - loss: 1.2444\n",
      "Epoch 2/100\n",
      "8/8 - 0s - 3ms/step - loss: 1.1524\n",
      "Epoch 3/100\n",
      "8/8 - 0s - 3ms/step - loss: 1.0860\n",
      "Epoch 4/100\n",
      "8/8 - 0s - 3ms/step - loss: 1.0345\n",
      "Epoch 5/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.9980\n",
      "Epoch 6/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.9705\n",
      "Epoch 7/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.9428\n",
      "Epoch 8/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.9215\n",
      "Epoch 9/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.9068\n",
      "Epoch 10/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8934\n",
      "Epoch 11/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8807\n",
      "Epoch 12/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8686\n",
      "Epoch 13/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8615\n",
      "Epoch 14/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8555\n",
      "Epoch 15/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8462\n",
      "Epoch 16/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8354\n",
      "Epoch 17/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8304\n",
      "Epoch 18/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8242\n",
      "Epoch 19/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8169\n",
      "Epoch 20/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8119\n",
      "Epoch 21/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8075\n",
      "Epoch 22/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8065\n",
      "Epoch 23/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7964\n",
      "Epoch 24/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7942\n",
      "Epoch 25/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7883\n",
      "Epoch 26/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7833\n",
      "Epoch 27/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7818\n",
      "Epoch 28/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7786\n",
      "Epoch 29/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7725\n",
      "Epoch 30/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7717\n",
      "Epoch 31/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7690\n",
      "Epoch 32/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7686\n",
      "Epoch 33/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7628\n",
      "Epoch 34/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7616\n",
      "Epoch 35/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7597\n",
      "Epoch 36/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7546\n",
      "Epoch 37/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7545\n",
      "Epoch 38/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7524\n",
      "Epoch 39/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7510\n",
      "Epoch 40/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7521\n",
      "Epoch 41/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7459\n",
      "Epoch 42/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7421\n",
      "Epoch 43/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7401\n",
      "Epoch 44/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7399\n",
      "Epoch 45/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7394\n",
      "Epoch 46/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7397\n",
      "Epoch 47/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7384\n",
      "Epoch 48/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7324\n",
      "Epoch 49/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7335\n",
      "Epoch 50/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7335\n",
      "Epoch 51/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7269\n",
      "Epoch 52/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7307\n",
      "Epoch 53/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7309\n",
      "Epoch 54/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7268\n",
      "Epoch 55/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7228\n",
      "Epoch 56/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7238\n",
      "Epoch 57/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7211\n",
      "Epoch 58/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7235\n",
      "Epoch 59/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7212\n",
      "Epoch 60/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7191\n",
      "Epoch 61/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7170\n",
      "Epoch 62/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7194\n",
      "Epoch 63/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7173\n",
      "Epoch 64/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7157\n",
      "Epoch 65/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7160\n",
      "Epoch 66/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7139\n",
      "Epoch 67/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7140\n",
      "Epoch 68/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7099\n",
      "Epoch 69/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.7098\n",
      "Epoch 70/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7071\n",
      "Epoch 71/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7089\n",
      "Epoch 72/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7074\n",
      "Epoch 73/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7069\n",
      "Epoch 74/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7081\n",
      "Epoch 75/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7060\n",
      "Epoch 76/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7076\n",
      "Epoch 77/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7065\n",
      "Epoch 78/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7042\n",
      "Epoch 79/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7037\n",
      "Epoch 80/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7017\n",
      "Epoch 81/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7046\n",
      "Epoch 82/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7050\n",
      "Epoch 83/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7002\n",
      "Epoch 84/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7012\n",
      "Epoch 85/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7009\n",
      "Epoch 86/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6983\n",
      "Epoch 87/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7002\n",
      "Epoch 88/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6972\n",
      "Epoch 89/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7005\n",
      "Epoch 90/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.6953\n",
      "Epoch 91/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6965\n",
      "Epoch 92/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.6997\n",
      "Epoch 93/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6962\n",
      "Epoch 94/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6945\n",
      "Epoch 95/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.6946\n",
      "Epoch 96/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.6939\n",
      "Epoch 97/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.6929\n",
      "Epoch 98/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6922\n",
      "Epoch 99/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6916\n",
      "Epoch 100/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.6908\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Testing with layers=[128, 64], encoding_dim=12, batch_size=32, epochs=50, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "32/32 - 1s - 32ms/step - loss: 1.1630\n",
      "Epoch 2/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.9845\n",
      "Epoch 3/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.9100\n",
      "Epoch 4/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8650\n",
      "Epoch 5/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8386\n",
      "Epoch 6/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8128\n",
      "Epoch 7/50\n",
      "32/32 - 0s - 992us/step - loss: 0.7930\n",
      "Epoch 8/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7755\n",
      "Epoch 9/50\n",
      "32/32 - 0s - 976us/step - loss: 0.7594\n",
      "Epoch 10/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7537\n",
      "Epoch 11/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7433\n",
      "Epoch 12/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7334\n",
      "Epoch 13/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7277\n",
      "Epoch 14/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7203\n",
      "Epoch 15/50\n",
      "32/32 - 0s - 948us/step - loss: 0.7149\n",
      "Epoch 16/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7126\n",
      "Epoch 17/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7054\n",
      "Epoch 18/50\n",
      "32/32 - 0s - 956us/step - loss: 0.6998\n",
      "Epoch 19/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.6958\n",
      "Epoch 20/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.6936\n",
      "Epoch 21/50\n",
      "32/32 - 0s - 970us/step - loss: 0.6895\n",
      "Epoch 22/50\n",
      "32/32 - 0s - 982us/step - loss: 0.6862\n",
      "Epoch 23/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.6835\n",
      "Epoch 24/50\n",
      "32/32 - 0s - 993us/step - loss: 0.6829\n",
      "Epoch 25/50\n",
      "32/32 - 0s - 972us/step - loss: 0.6820\n",
      "Epoch 26/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.6742\n",
      "Epoch 27/50\n",
      "32/32 - 0s - 972us/step - loss: 0.6724\n",
      "Epoch 28/50\n",
      "32/32 - 0s - 922us/step - loss: 0.6752\n",
      "Epoch 29/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.6750\n",
      "Epoch 30/50\n",
      "32/32 - 0s - 917us/step - loss: 0.6708\n",
      "Epoch 31/50\n",
      "32/32 - 0s - 919us/step - loss: 0.6673\n",
      "Epoch 32/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.6665\n",
      "Epoch 33/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.6642\n",
      "Epoch 34/50\n",
      "32/32 - 0s - 931us/step - loss: 0.6640\n",
      "Epoch 35/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.6626\n",
      "Epoch 36/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.6654\n",
      "Epoch 37/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.6641\n",
      "Epoch 38/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.6591\n",
      "Epoch 39/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.6569\n",
      "Epoch 40/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.6562\n",
      "Epoch 41/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.6535\n",
      "Epoch 42/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.6513\n",
      "Epoch 43/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.6522\n",
      "Epoch 44/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.6502\n",
      "Epoch 45/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.6508\n",
      "Epoch 46/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.6515\n",
      "Epoch 47/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.6479\n",
      "Epoch 48/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.6527\n",
      "Epoch 49/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.6464\n",
      "Epoch 50/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.6505\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step\n",
      "Testing with layers=[128, 64], encoding_dim=12, batch_size=32, epochs=50, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "32/32 - 1s - 34ms/step - loss: 1.1646\n",
      "Epoch 2/50\n",
      "32/32 - 0s - 1ms/step - loss: 1.0059\n",
      "Epoch 3/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.9345\n",
      "Epoch 4/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8926\n",
      "Epoch 5/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8683\n",
      "Epoch 6/50\n",
      "32/32 - 0s - 935us/step - loss: 0.8432\n",
      "Epoch 7/50\n",
      "32/32 - 0s - 929us/step - loss: 0.8272\n",
      "Epoch 8/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.8131\n",
      "Epoch 9/50\n",
      "32/32 - 0s - 990us/step - loss: 0.8026\n",
      "Epoch 10/50\n",
      "32/32 - 0s - 976us/step - loss: 0.7944\n",
      "Epoch 11/50\n",
      "32/32 - 0s - 991us/step - loss: 0.7790\n",
      "Epoch 12/50\n",
      "32/32 - 0s - 947us/step - loss: 0.7679\n",
      "Epoch 13/50\n",
      "32/32 - 0s - 947us/step - loss: 0.7675\n",
      "Epoch 14/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7587\n",
      "Epoch 15/50\n",
      "32/32 - 0s - 912us/step - loss: 0.7531\n",
      "Epoch 16/50\n",
      "32/32 - 0s - 913us/step - loss: 0.7468\n",
      "Epoch 17/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7400\n",
      "Epoch 18/50\n",
      "32/32 - 0s - 948us/step - loss: 0.7338\n",
      "Epoch 19/50\n",
      "32/32 - 0s - 927us/step - loss: 0.7284\n",
      "Epoch 20/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7241\n",
      "Epoch 21/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7200\n",
      "Epoch 22/50\n",
      "32/32 - 0s - 1000us/step - loss: 0.7165\n",
      "Epoch 23/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7156\n",
      "Epoch 24/50\n",
      "32/32 - 0s - 2ms/step - loss: 0.7138\n",
      "Epoch 25/50\n",
      "32/32 - 0s - 3ms/step - loss: 0.7101\n",
      "Epoch 26/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7090\n",
      "Epoch 27/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7058\n",
      "Epoch 28/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7008\n",
      "Epoch 29/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7008\n",
      "Epoch 30/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.7015\n",
      "Epoch 31/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.6963\n",
      "Epoch 32/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.6978\n",
      "Epoch 33/50\n",
      "32/32 - 0s - 967us/step - loss: 0.6931\n",
      "Epoch 34/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.6946\n",
      "Epoch 35/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.6921\n",
      "Epoch 36/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.6904\n",
      "Epoch 37/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.6881\n",
      "Epoch 38/50\n",
      "32/32 - 0s - 994us/step - loss: 0.6864\n",
      "Epoch 39/50\n",
      "32/32 - 0s - 952us/step - loss: 0.6834\n",
      "Epoch 40/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.6836\n",
      "Epoch 41/50\n",
      "32/32 - 0s - 958us/step - loss: 0.6836\n",
      "Epoch 42/50\n",
      "32/32 - 0s - 968us/step - loss: 0.6847\n",
      "Epoch 43/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.6810\n",
      "Epoch 44/50\n",
      "32/32 - 0s - 976us/step - loss: 0.6808\n",
      "Epoch 45/50\n",
      "32/32 - 0s - 929us/step - loss: 0.6791\n",
      "Epoch 46/50\n",
      "32/32 - 0s - 950us/step - loss: 0.6774\n",
      "Epoch 47/50\n",
      "32/32 - 0s - 932us/step - loss: 0.6772\n",
      "Epoch 48/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.6759\n",
      "Epoch 49/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.6744\n",
      "Epoch 50/50\n",
      "32/32 - 0s - 1ms/step - loss: 0.6741\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Testing with layers=[128, 64], encoding_dim=12, batch_size=32, epochs=100, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "32/32 - 1s - 34ms/step - loss: 1.1371\n",
      "Epoch 2/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.9720\n",
      "Epoch 3/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.9059\n",
      "Epoch 4/100\n",
      "32/32 - 0s - 919us/step - loss: 0.8644\n",
      "Epoch 5/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8322\n",
      "Epoch 6/100\n",
      "32/32 - 0s - 910us/step - loss: 0.8080\n",
      "Epoch 7/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7879\n",
      "Epoch 8/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7743\n",
      "Epoch 9/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7630\n",
      "Epoch 10/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7525\n",
      "Epoch 11/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7390\n",
      "Epoch 12/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7331\n",
      "Epoch 13/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7266\n",
      "Epoch 14/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7191\n",
      "Epoch 15/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7113\n",
      "Epoch 16/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7093\n",
      "Epoch 17/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7006\n",
      "Epoch 18/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6975\n",
      "Epoch 19/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6940\n",
      "Epoch 20/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6914\n",
      "Epoch 21/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6910\n",
      "Epoch 22/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6848\n",
      "Epoch 23/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.6831\n",
      "Epoch 24/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.6793\n",
      "Epoch 25/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6803\n",
      "Epoch 26/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6750\n",
      "Epoch 27/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6718\n",
      "Epoch 28/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6698\n",
      "Epoch 29/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6706\n",
      "Epoch 30/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6687\n",
      "Epoch 31/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6665\n",
      "Epoch 32/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6668\n",
      "Epoch 33/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6619\n",
      "Epoch 34/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6600\n",
      "Epoch 35/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6594\n",
      "Epoch 36/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6583\n",
      "Epoch 37/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6598\n",
      "Epoch 38/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6557\n",
      "Epoch 39/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6552\n",
      "Epoch 40/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6522\n",
      "Epoch 41/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6555\n",
      "Epoch 42/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6531\n",
      "Epoch 43/100\n",
      "32/32 - 0s - 961us/step - loss: 0.6492\n",
      "Epoch 44/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6490\n",
      "Epoch 45/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6486\n",
      "Epoch 46/100\n",
      "32/32 - 0s - 976us/step - loss: 0.6482\n",
      "Epoch 47/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6466\n",
      "Epoch 48/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6470\n",
      "Epoch 49/100\n",
      "32/32 - 0s - 938us/step - loss: 0.6478\n",
      "Epoch 50/100\n",
      "32/32 - 0s - 934us/step - loss: 0.6447\n",
      "Epoch 51/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6451\n",
      "Epoch 52/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6411\n",
      "Epoch 53/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6398\n",
      "Epoch 54/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6396\n",
      "Epoch 55/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6381\n",
      "Epoch 56/100\n",
      "32/32 - 0s - 985us/step - loss: 0.6380\n",
      "Epoch 57/100\n",
      "32/32 - 0s - 973us/step - loss: 0.6369\n",
      "Epoch 58/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6405\n",
      "Epoch 59/100\n",
      "32/32 - 0s - 960us/step - loss: 0.6386\n",
      "Epoch 60/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6378\n",
      "Epoch 61/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6368\n",
      "Epoch 62/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6357\n",
      "Epoch 63/100\n",
      "32/32 - 0s - 994us/step - loss: 0.6385\n",
      "Epoch 64/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6306\n",
      "Epoch 65/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6366\n",
      "Epoch 66/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6311\n",
      "Epoch 67/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6350\n",
      "Epoch 68/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6334\n",
      "Epoch 69/100\n",
      "32/32 - 0s - 974us/step - loss: 0.6356\n",
      "Epoch 70/100\n",
      "32/32 - 0s - 970us/step - loss: 0.6321\n",
      "Epoch 71/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6332\n",
      "Epoch 72/100\n",
      "32/32 - 0s - 997us/step - loss: 0.6314\n",
      "Epoch 73/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6284\n",
      "Epoch 74/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6298\n",
      "Epoch 75/100\n",
      "32/32 - 0s - 956us/step - loss: 0.6286\n",
      "Epoch 76/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6294\n",
      "Epoch 77/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6289\n",
      "Epoch 78/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6298\n",
      "Epoch 79/100\n",
      "32/32 - 0s - 993us/step - loss: 0.6323\n",
      "Epoch 80/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6262\n",
      "Epoch 81/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6290\n",
      "Epoch 82/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6276\n",
      "Epoch 83/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6277\n",
      "Epoch 84/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6274\n",
      "Epoch 85/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6246\n",
      "Epoch 86/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6244\n",
      "Epoch 87/100\n",
      "32/32 - 0s - 908us/step - loss: 0.6251\n",
      "Epoch 88/100\n",
      "32/32 - 0s - 962us/step - loss: 0.6258\n",
      "Epoch 89/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6254\n",
      "Epoch 90/100\n",
      "32/32 - 0s - 983us/step - loss: 0.6201\n",
      "Epoch 91/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6187\n",
      "Epoch 92/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6246\n",
      "Epoch 93/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6240\n",
      "Epoch 94/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6224\n",
      "Epoch 95/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6231\n",
      "Epoch 96/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6248\n",
      "Epoch 97/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6204\n",
      "Epoch 98/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6244\n",
      "Epoch 99/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6235\n",
      "Epoch 100/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6204\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Testing with layers=[128, 64], encoding_dim=12, batch_size=32, epochs=100, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "32/32 - 1s - 43ms/step - loss: 1.2102\n",
      "Epoch 2/100\n",
      "32/32 - 0s - 1ms/step - loss: 1.0314\n",
      "Epoch 3/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.9463\n",
      "Epoch 4/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.9037\n",
      "Epoch 5/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8755\n",
      "Epoch 6/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8525\n",
      "Epoch 7/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8326\n",
      "Epoch 8/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8191\n",
      "Epoch 9/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.8063\n",
      "Epoch 10/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7910\n",
      "Epoch 11/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7814\n",
      "Epoch 12/100\n",
      "32/32 - 0s - 4ms/step - loss: 0.7681\n",
      "Epoch 13/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.7606\n",
      "Epoch 14/100\n",
      "32/32 - 0s - 945us/step - loss: 0.7545\n",
      "Epoch 15/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7435\n",
      "Epoch 16/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7399\n",
      "Epoch 17/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7364\n",
      "Epoch 18/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7300\n",
      "Epoch 19/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7265\n",
      "Epoch 20/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7209\n",
      "Epoch 21/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7189\n",
      "Epoch 22/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7140\n",
      "Epoch 23/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7108\n",
      "Epoch 24/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7094\n",
      "Epoch 25/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7081\n",
      "Epoch 26/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.7047\n",
      "Epoch 27/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.7014\n",
      "Epoch 28/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6999\n",
      "Epoch 29/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6969\n",
      "Epoch 30/100\n",
      "32/32 - 0s - 985us/step - loss: 0.6958\n",
      "Epoch 31/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6976\n",
      "Epoch 32/100\n",
      "32/32 - 0s - 890us/step - loss: 0.6940\n",
      "Epoch 33/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6907\n",
      "Epoch 34/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6933\n",
      "Epoch 35/100\n",
      "32/32 - 0s - 960us/step - loss: 0.6881\n",
      "Epoch 36/100\n",
      "32/32 - 0s - 969us/step - loss: 0.6881\n",
      "Epoch 37/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6881\n",
      "Epoch 38/100\n",
      "32/32 - 0s - 924us/step - loss: 0.6848\n",
      "Epoch 39/100\n",
      "32/32 - 0s - 955us/step - loss: 0.6835\n",
      "Epoch 40/100\n",
      "32/32 - 0s - 975us/step - loss: 0.6832\n",
      "Epoch 41/100\n",
      "32/32 - 0s - 942us/step - loss: 0.6817\n",
      "Epoch 42/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6806\n",
      "Epoch 43/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6780\n",
      "Epoch 44/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6773\n",
      "Epoch 45/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6783\n",
      "Epoch 46/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6805\n",
      "Epoch 47/100\n",
      "32/32 - 0s - 973us/step - loss: 0.6751\n",
      "Epoch 48/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6758\n",
      "Epoch 49/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6741\n",
      "Epoch 50/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6757\n",
      "Epoch 51/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6734\n",
      "Epoch 52/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6733\n",
      "Epoch 53/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6714\n",
      "Epoch 54/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6683\n",
      "Epoch 55/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6648\n",
      "Epoch 56/100\n",
      "32/32 - 0s - 991us/step - loss: 0.6651\n",
      "Epoch 57/100\n",
      "32/32 - 0s - 974us/step - loss: 0.6682\n",
      "Epoch 58/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6644\n",
      "Epoch 59/100\n",
      "32/32 - 0s - 991us/step - loss: 0.6677\n",
      "Epoch 60/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6663\n",
      "Epoch 61/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6661\n",
      "Epoch 62/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6634\n",
      "Epoch 63/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6631\n",
      "Epoch 64/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6625\n",
      "Epoch 65/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6628\n",
      "Epoch 66/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6618\n",
      "Epoch 67/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6610\n",
      "Epoch 68/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6619\n",
      "Epoch 69/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6608\n",
      "Epoch 70/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6568\n",
      "Epoch 71/100\n",
      "32/32 - 0s - 994us/step - loss: 0.6596\n",
      "Epoch 72/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6607\n",
      "Epoch 73/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6548\n",
      "Epoch 74/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6569\n",
      "Epoch 75/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6539\n",
      "Epoch 76/100\n",
      "32/32 - 0s - 1ms/step - loss: 0.6577\n",
      "Epoch 77/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6524\n",
      "Epoch 78/100\n",
      "32/32 - 0s - 9ms/step - loss: 0.6559\n",
      "Epoch 79/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.6517\n",
      "Epoch 80/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6537\n",
      "Epoch 81/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6553\n",
      "Epoch 82/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6528\n",
      "Epoch 83/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6511\n",
      "Epoch 84/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.6524\n",
      "Epoch 85/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6529\n",
      "Epoch 86/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.6501\n",
      "Epoch 87/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6477\n",
      "Epoch 88/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6480\n",
      "Epoch 89/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.6484\n",
      "Epoch 90/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.6502\n",
      "Epoch 91/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6445\n",
      "Epoch 92/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6462\n",
      "Epoch 93/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.6468\n",
      "Epoch 94/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.6433\n",
      "Epoch 95/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6467\n",
      "Epoch 96/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6465\n",
      "Epoch 97/100\n",
      "32/32 - 0s - 3ms/step - loss: 0.6422\n",
      "Epoch 98/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6416\n",
      "Epoch 99/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6415\n",
      "Epoch 100/100\n",
      "32/32 - 0s - 2ms/step - loss: 0.6462\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Testing with layers=[128, 64], encoding_dim=12, batch_size=64, epochs=50, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "16/16 - 2s - 108ms/step - loss: 1.1932\n",
      "Epoch 2/50\n",
      "16/16 - 0s - 2ms/step - loss: 1.0453\n",
      "Epoch 3/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.9689\n",
      "Epoch 4/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.9201\n",
      "Epoch 5/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8834\n",
      "Epoch 6/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8540\n",
      "Epoch 7/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8292\n",
      "Epoch 8/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.8144\n",
      "Epoch 9/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7955\n",
      "Epoch 10/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7796\n",
      "Epoch 11/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7651\n",
      "Epoch 12/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7577\n",
      "Epoch 13/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7468\n",
      "Epoch 14/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7369\n",
      "Epoch 15/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7319\n",
      "Epoch 16/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7248\n",
      "Epoch 17/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.7194\n",
      "Epoch 18/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7145\n",
      "Epoch 19/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7079\n",
      "Epoch 20/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7036\n",
      "Epoch 21/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.7028\n",
      "Epoch 22/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.6966\n",
      "Epoch 23/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.6920\n",
      "Epoch 24/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.6913\n",
      "Epoch 25/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.6879\n",
      "Epoch 26/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.6875\n",
      "Epoch 27/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.6845\n",
      "Epoch 28/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.6807\n",
      "Epoch 29/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.6801\n",
      "Epoch 30/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.6762\n",
      "Epoch 31/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.6769\n",
      "Epoch 32/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.6727\n",
      "Epoch 33/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.6706\n",
      "Epoch 34/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.6688\n",
      "Epoch 35/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.6691\n",
      "Epoch 36/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.6665\n",
      "Epoch 37/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.6659\n",
      "Epoch 38/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.6646\n",
      "Epoch 39/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.6624\n",
      "Epoch 40/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.6606\n",
      "Epoch 41/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.6581\n",
      "Epoch 42/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.6561\n",
      "Epoch 43/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.6557\n",
      "Epoch 44/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.6540\n",
      "Epoch 45/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.6566\n",
      "Epoch 46/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.6558\n",
      "Epoch 47/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.6504\n",
      "Epoch 48/50\n",
      "16/16 - 0s - 1ms/step - loss: 0.6483\n",
      "Epoch 49/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.6507\n",
      "Epoch 50/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.6462\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Testing with layers=[128, 64], encoding_dim=12, batch_size=64, epochs=50, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "16/16 - 1s - 88ms/step - loss: 1.2041\n",
      "Epoch 2/50\n",
      "16/16 - 0s - 3ms/step - loss: 1.0647\n",
      "Epoch 3/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.9946\n",
      "Epoch 4/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.9466\n",
      "Epoch 5/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.9109\n",
      "Epoch 6/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.8877\n",
      "Epoch 7/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8707\n",
      "Epoch 8/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8498\n",
      "Epoch 9/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.8394\n",
      "Epoch 10/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.8278\n",
      "Epoch 11/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.8110\n",
      "Epoch 12/50\n",
      "16/16 - 0s - 5ms/step - loss: 0.8011\n",
      "Epoch 13/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7936\n",
      "Epoch 14/50\n",
      "16/16 - 0s - 5ms/step - loss: 0.7885\n",
      "Epoch 15/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7749\n",
      "Epoch 16/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7765\n",
      "Epoch 17/50\n",
      "16/16 - 0s - 5ms/step - loss: 0.7665\n",
      "Epoch 18/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7605\n",
      "Epoch 19/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.7551\n",
      "Epoch 20/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7505\n",
      "Epoch 21/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7444\n",
      "Epoch 22/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7395\n",
      "Epoch 23/50\n",
      "16/16 - 0s - 6ms/step - loss: 0.7345\n",
      "Epoch 24/50\n",
      "16/16 - 0s - 5ms/step - loss: 0.7329\n",
      "Epoch 25/50\n",
      "16/16 - 0s - 5ms/step - loss: 0.7259\n",
      "Epoch 26/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7248\n",
      "Epoch 27/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7210\n",
      "Epoch 28/50\n",
      "16/16 - 0s - 6ms/step - loss: 0.7182\n",
      "Epoch 29/50\n",
      "16/16 - 0s - 5ms/step - loss: 0.7201\n",
      "Epoch 30/50\n",
      "16/16 - 0s - 5ms/step - loss: 0.7156\n",
      "Epoch 31/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7103\n",
      "Epoch 32/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.7108\n",
      "Epoch 33/50\n",
      "16/16 - 0s - 5ms/step - loss: 0.7080\n",
      "Epoch 34/50\n",
      "16/16 - 0s - 5ms/step - loss: 0.7091\n",
      "Epoch 35/50\n",
      "16/16 - 0s - 5ms/step - loss: 0.7047\n",
      "Epoch 36/50\n",
      "16/16 - 0s - 5ms/step - loss: 0.7019\n",
      "Epoch 37/50\n",
      "16/16 - 0s - 5ms/step - loss: 0.7012\n",
      "Epoch 38/50\n",
      "16/16 - 0s - 5ms/step - loss: 0.6962\n",
      "Epoch 39/50\n",
      "16/16 - 0s - 5ms/step - loss: 0.7005\n",
      "Epoch 40/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.6968\n",
      "Epoch 41/50\n",
      "16/16 - 0s - 4ms/step - loss: 0.6963\n",
      "Epoch 42/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.6899\n",
      "Epoch 43/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.6908\n",
      "Epoch 44/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.6921\n",
      "Epoch 45/50\n",
      "16/16 - 0s - 3ms/step - loss: 0.6916\n",
      "Epoch 46/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.6861\n",
      "Epoch 47/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.6866\n",
      "Epoch 48/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.6850\n",
      "Epoch 49/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.6837\n",
      "Epoch 50/50\n",
      "16/16 - 0s - 2ms/step - loss: 0.6802\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "Testing with layers=[128, 64], encoding_dim=12, batch_size=64, epochs=100, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "16/16 - 2s - 144ms/step - loss: 1.2028\n",
      "Epoch 2/100\n",
      "16/16 - 0s - 4ms/step - loss: 1.0457\n",
      "Epoch 3/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.9643\n",
      "Epoch 4/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.9124\n",
      "Epoch 5/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.8783\n",
      "Epoch 6/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8502\n",
      "Epoch 7/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.8309\n",
      "Epoch 8/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.8121\n",
      "Epoch 9/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7967\n",
      "Epoch 10/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7841\n",
      "Epoch 11/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7706\n",
      "Epoch 12/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7590\n",
      "Epoch 13/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7508\n",
      "Epoch 14/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7430\n",
      "Epoch 15/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7357\n",
      "Epoch 16/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7252\n",
      "Epoch 17/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7204\n",
      "Epoch 18/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7145\n",
      "Epoch 19/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7106\n",
      "Epoch 20/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7042\n",
      "Epoch 21/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7007\n",
      "Epoch 22/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6952\n",
      "Epoch 23/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6924\n",
      "Epoch 24/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6892\n",
      "Epoch 25/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6869\n",
      "Epoch 26/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6820\n",
      "Epoch 27/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6819\n",
      "Epoch 28/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6784\n",
      "Epoch 29/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6780\n",
      "Epoch 30/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6753\n",
      "Epoch 31/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6703\n",
      "Epoch 32/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6685\n",
      "Epoch 33/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6672\n",
      "Epoch 34/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6652\n",
      "Epoch 35/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6626\n",
      "Epoch 36/100\n",
      "16/16 - 0s - 6ms/step - loss: 0.6642\n",
      "Epoch 37/100\n",
      "16/16 - 0s - 9ms/step - loss: 0.6608\n",
      "Epoch 38/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6595\n",
      "Epoch 39/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6559\n",
      "Epoch 40/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6546\n",
      "Epoch 41/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6559\n",
      "Epoch 42/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6507\n",
      "Epoch 43/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6513\n",
      "Epoch 44/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6512\n",
      "Epoch 45/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6518\n",
      "Epoch 46/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6479\n",
      "Epoch 47/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6452\n",
      "Epoch 48/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6480\n",
      "Epoch 49/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6456\n",
      "Epoch 50/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6417\n",
      "Epoch 51/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.6415\n",
      "Epoch 52/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6400\n",
      "Epoch 53/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.6394\n",
      "Epoch 54/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.6385\n",
      "Epoch 55/100\n",
      "16/16 - 0s - 6ms/step - loss: 0.6376\n",
      "Epoch 56/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.6381\n",
      "Epoch 57/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.6375\n",
      "Epoch 58/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.6341\n",
      "Epoch 59/100\n",
      "16/16 - 0s - 7ms/step - loss: 0.6357\n",
      "Epoch 60/100\n",
      "16/16 - 0s - 6ms/step - loss: 0.6337\n",
      "Epoch 61/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6326\n",
      "Epoch 62/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.6318\n",
      "Epoch 63/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.6299\n",
      "Epoch 64/100\n",
      "16/16 - 0s - 6ms/step - loss: 0.6318\n",
      "Epoch 65/100\n",
      "16/16 - 0s - 6ms/step - loss: 0.6332\n",
      "Epoch 66/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.6287\n",
      "Epoch 67/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6300\n",
      "Epoch 68/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.6268\n",
      "Epoch 69/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.6276\n",
      "Epoch 70/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6295\n",
      "Epoch 71/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.6281\n",
      "Epoch 72/100\n",
      "16/16 - 0s - 10ms/step - loss: 0.6271\n",
      "Epoch 73/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.6246\n",
      "Epoch 74/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.6231\n",
      "Epoch 75/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6240\n",
      "Epoch 76/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6243\n",
      "Epoch 77/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6215\n",
      "Epoch 78/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6260\n",
      "Epoch 79/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6227\n",
      "Epoch 80/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6241\n",
      "Epoch 81/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6198\n",
      "Epoch 82/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6242\n",
      "Epoch 83/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6193\n",
      "Epoch 84/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6192\n",
      "Epoch 85/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6211\n",
      "Epoch 86/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6226\n",
      "Epoch 87/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6206\n",
      "Epoch 88/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6190\n",
      "Epoch 89/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6188\n",
      "Epoch 90/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6148\n",
      "Epoch 91/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6179\n",
      "Epoch 92/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6190\n",
      "Epoch 93/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6181\n",
      "Epoch 94/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6150\n",
      "Epoch 95/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6183\n",
      "Epoch 96/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6124\n",
      "Epoch 97/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.6163\n",
      "Epoch 98/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6162\n",
      "Epoch 99/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6161\n",
      "Epoch 100/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6140\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Testing with layers=[128, 64], encoding_dim=12, batch_size=64, epochs=100, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "16/16 - 2s - 107ms/step - loss: 1.2389\n",
      "Epoch 2/100\n",
      "16/16 - 0s - 5ms/step - loss: 1.1017\n",
      "Epoch 3/100\n",
      "16/16 - 0s - 2ms/step - loss: 1.0188\n",
      "Epoch 4/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.9631\n",
      "Epoch 5/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.9247\n",
      "Epoch 6/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.8956\n",
      "Epoch 7/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8704\n",
      "Epoch 8/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8546\n",
      "Epoch 9/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8394\n",
      "Epoch 10/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8259\n",
      "Epoch 11/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.8147\n",
      "Epoch 12/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.8043\n",
      "Epoch 13/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7970\n",
      "Epoch 14/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7853\n",
      "Epoch 15/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7804\n",
      "Epoch 16/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.7751\n",
      "Epoch 17/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7651\n",
      "Epoch 18/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7596\n",
      "Epoch 19/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7539\n",
      "Epoch 20/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7524\n",
      "Epoch 21/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7435\n",
      "Epoch 22/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7379\n",
      "Epoch 23/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7335\n",
      "Epoch 24/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7281\n",
      "Epoch 25/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7270\n",
      "Epoch 26/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7232\n",
      "Epoch 27/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7224\n",
      "Epoch 28/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7171\n",
      "Epoch 29/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7179\n",
      "Epoch 30/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7116\n",
      "Epoch 31/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7108\n",
      "Epoch 32/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7091\n",
      "Epoch 33/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7094\n",
      "Epoch 34/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7021\n",
      "Epoch 35/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6998\n",
      "Epoch 36/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.7007\n",
      "Epoch 37/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.7002\n",
      "Epoch 38/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6988\n",
      "Epoch 39/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6976\n",
      "Epoch 40/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6956\n",
      "Epoch 41/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6934\n",
      "Epoch 42/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6911\n",
      "Epoch 43/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6908\n",
      "Epoch 44/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6905\n",
      "Epoch 45/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6901\n",
      "Epoch 46/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6883\n",
      "Epoch 47/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.6869\n",
      "Epoch 48/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.6873\n",
      "Epoch 49/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.6823\n",
      "Epoch 50/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6846\n",
      "Epoch 51/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.6839\n",
      "Epoch 52/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6809\n",
      "Epoch 53/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.6801\n",
      "Epoch 54/100\n",
      "16/16 - 0s - 7ms/step - loss: 0.6776\n",
      "Epoch 55/100\n",
      "16/16 - 0s - 6ms/step - loss: 0.6804\n",
      "Epoch 56/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.6805\n",
      "Epoch 57/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.6777\n",
      "Epoch 58/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6761\n",
      "Epoch 59/100\n",
      "16/16 - 0s - 6ms/step - loss: 0.6743\n",
      "Epoch 60/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.6751\n",
      "Epoch 61/100\n",
      "16/16 - 0s - 6ms/step - loss: 0.6752\n",
      "Epoch 62/100\n",
      "16/16 - 0s - 6ms/step - loss: 0.6711\n",
      "Epoch 63/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.6699\n",
      "Epoch 64/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.6738\n",
      "Epoch 65/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.6711\n",
      "Epoch 66/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6719\n",
      "Epoch 67/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6712\n",
      "Epoch 68/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6711\n",
      "Epoch 69/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6706\n",
      "Epoch 70/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6673\n",
      "Epoch 71/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6698\n",
      "Epoch 72/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6674\n",
      "Epoch 73/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6661\n",
      "Epoch 74/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6673\n",
      "Epoch 75/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6644\n",
      "Epoch 76/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6643\n",
      "Epoch 77/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6668\n",
      "Epoch 78/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6653\n",
      "Epoch 79/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6652\n",
      "Epoch 80/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6630\n",
      "Epoch 81/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6621\n",
      "Epoch 82/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6605\n",
      "Epoch 83/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6644\n",
      "Epoch 84/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6626\n",
      "Epoch 85/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6604\n",
      "Epoch 86/100\n",
      "16/16 - 0s - 4ms/step - loss: 0.6647\n",
      "Epoch 87/100\n",
      "16/16 - 0s - 5ms/step - loss: 0.6643\n",
      "Epoch 88/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6610\n",
      "Epoch 89/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6599\n",
      "Epoch 90/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6606\n",
      "Epoch 91/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6597\n",
      "Epoch 92/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6557\n",
      "Epoch 93/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6574\n",
      "Epoch 94/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6595\n",
      "Epoch 95/100\n",
      "16/16 - 0s - 3ms/step - loss: 0.6584\n",
      "Epoch 96/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6589\n",
      "Epoch 97/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6579\n",
      "Epoch 98/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6577\n",
      "Epoch 99/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6563\n",
      "Epoch 100/100\n",
      "16/16 - 0s - 2ms/step - loss: 0.6561\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Testing with layers=[128, 64], encoding_dim=12, batch_size=128, epochs=50, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "8/8 - 2s - 204ms/step - loss: 1.1970\n",
      "Epoch 2/50\n",
      "8/8 - 0s - 5ms/step - loss: 1.0926\n",
      "Epoch 3/50\n",
      "8/8 - 0s - 4ms/step - loss: 1.0238\n",
      "Epoch 4/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.9792\n",
      "Epoch 5/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.9446\n",
      "Epoch 6/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.9140\n",
      "Epoch 7/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8875\n",
      "Epoch 8/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8723\n",
      "Epoch 9/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8530\n",
      "Epoch 10/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.8365\n",
      "Epoch 11/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.8236\n",
      "Epoch 12/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8131\n",
      "Epoch 13/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8009\n",
      "Epoch 14/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7894\n",
      "Epoch 15/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7796\n",
      "Epoch 16/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7717\n",
      "Epoch 17/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7619\n",
      "Epoch 18/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7590\n",
      "Epoch 19/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7502\n",
      "Epoch 20/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.7461\n",
      "Epoch 21/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.7404\n",
      "Epoch 22/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7345\n",
      "Epoch 23/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7292\n",
      "Epoch 24/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7267\n",
      "Epoch 25/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.7221\n",
      "Epoch 26/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.7169\n",
      "Epoch 27/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7160\n",
      "Epoch 28/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7106\n",
      "Epoch 29/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7080\n",
      "Epoch 30/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7045\n",
      "Epoch 31/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7031\n",
      "Epoch 32/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.7036\n",
      "Epoch 33/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.6998\n",
      "Epoch 34/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.6953\n",
      "Epoch 35/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.6939\n",
      "Epoch 36/50\n",
      "8/8 - 0s - 9ms/step - loss: 0.6915\n",
      "Epoch 37/50\n",
      "8/8 - 0s - 8ms/step - loss: 0.6889\n",
      "Epoch 38/50\n",
      "8/8 - 0s - 9ms/step - loss: 0.6859\n",
      "Epoch 39/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.6848\n",
      "Epoch 40/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.6843\n",
      "Epoch 41/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.6834\n",
      "Epoch 42/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.6797\n",
      "Epoch 43/50\n",
      "8/8 - 0s - 8ms/step - loss: 0.6782\n",
      "Epoch 44/50\n",
      "8/8 - 0s - 18ms/step - loss: 0.6777\n",
      "Epoch 45/50\n",
      "8/8 - 0s - 8ms/step - loss: 0.6754\n",
      "Epoch 46/50\n",
      "8/8 - 0s - 8ms/step - loss: 0.6755\n",
      "Epoch 47/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.6739\n",
      "Epoch 48/50\n",
      "8/8 - 0s - 8ms/step - loss: 0.6709\n",
      "Epoch 49/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.6705\n",
      "Epoch 50/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.6701\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step\n",
      "Testing with layers=[128, 64], encoding_dim=12, batch_size=128, epochs=50, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/50\n",
      "8/8 - 2s - 202ms/step - loss: 1.2717\n",
      "Epoch 2/50\n",
      "8/8 - 0s - 6ms/step - loss: 1.1632\n",
      "Epoch 3/50\n",
      "8/8 - 0s - 5ms/step - loss: 1.0900\n",
      "Epoch 4/50\n",
      "8/8 - 0s - 6ms/step - loss: 1.0343\n",
      "Epoch 5/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.9899\n",
      "Epoch 6/50\n",
      "8/8 - 0s - 8ms/step - loss: 0.9621\n",
      "Epoch 7/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.9358\n",
      "Epoch 8/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.9120\n",
      "Epoch 9/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.9014\n",
      "Epoch 10/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.8836\n",
      "Epoch 11/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8720\n",
      "Epoch 12/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8588\n",
      "Epoch 13/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.8482\n",
      "Epoch 14/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8420\n",
      "Epoch 15/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.8341\n",
      "Epoch 16/50\n",
      "8/8 - 0s - 8ms/step - loss: 0.8258\n",
      "Epoch 17/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.8139\n",
      "Epoch 18/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8094\n",
      "Epoch 19/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.8013\n",
      "Epoch 20/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7945\n",
      "Epoch 21/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7908\n",
      "Epoch 22/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7847\n",
      "Epoch 23/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.7794\n",
      "Epoch 24/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.7711\n",
      "Epoch 25/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7669\n",
      "Epoch 26/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7655\n",
      "Epoch 27/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7575\n",
      "Epoch 28/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.7537\n",
      "Epoch 29/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.7505\n",
      "Epoch 30/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.7515\n",
      "Epoch 31/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7433\n",
      "Epoch 32/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.7408\n",
      "Epoch 33/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7404\n",
      "Epoch 34/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.7358\n",
      "Epoch 35/50\n",
      "8/8 - 0s - 7ms/step - loss: 0.7354\n",
      "Epoch 36/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7328\n",
      "Epoch 37/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7266\n",
      "Epoch 38/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.7249\n",
      "Epoch 39/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7234\n",
      "Epoch 40/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7241\n",
      "Epoch 41/50\n",
      "8/8 - 0s - 5ms/step - loss: 0.7212\n",
      "Epoch 42/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7185\n",
      "Epoch 43/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7168\n",
      "Epoch 44/50\n",
      "8/8 - 0s - 3ms/step - loss: 0.7098\n",
      "Epoch 45/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7140\n",
      "Epoch 46/50\n",
      "8/8 - 0s - 6ms/step - loss: 0.7126\n",
      "Epoch 47/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7124\n",
      "Epoch 48/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7069\n",
      "Epoch 49/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7092\n",
      "Epoch 50/50\n",
      "8/8 - 0s - 4ms/step - loss: 0.7078\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Testing with layers=[128, 64], encoding_dim=12, batch_size=128, epochs=100, dropout_rate=0.2\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "8/8 - 2s - 190ms/step - loss: 1.2859\n",
      "Epoch 2/100\n",
      "8/8 - 0s - 5ms/step - loss: 1.1724\n",
      "Epoch 3/100\n",
      "8/8 - 0s - 4ms/step - loss: 1.0910\n",
      "Epoch 4/100\n",
      "8/8 - 0s - 5ms/step - loss: 1.0361\n",
      "Epoch 5/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.9843\n",
      "Epoch 6/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.9521\n",
      "Epoch 7/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.9204\n",
      "Epoch 8/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8950\n",
      "Epoch 9/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8752\n",
      "Epoch 10/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.8603\n",
      "Epoch 11/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.8458\n",
      "Epoch 12/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8323\n",
      "Epoch 13/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.8207\n",
      "Epoch 14/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.8114\n",
      "Epoch 15/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8024\n",
      "Epoch 16/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7927\n",
      "Epoch 17/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7815\n",
      "Epoch 18/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7743\n",
      "Epoch 19/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7674\n",
      "Epoch 20/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7627\n",
      "Epoch 21/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7581\n",
      "Epoch 22/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7519\n",
      "Epoch 23/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7461\n",
      "Epoch 24/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7388\n",
      "Epoch 25/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7343\n",
      "Epoch 26/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7315\n",
      "Epoch 27/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7250\n",
      "Epoch 28/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7215\n",
      "Epoch 29/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7223\n",
      "Epoch 30/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7142\n",
      "Epoch 31/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7131\n",
      "Epoch 32/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7103\n",
      "Epoch 33/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.7082\n",
      "Epoch 34/100\n",
      "8/8 - 0s - 9ms/step - loss: 0.7036\n",
      "Epoch 35/100\n",
      "8/8 - 0s - 9ms/step - loss: 0.7007\n",
      "Epoch 36/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.6963\n",
      "Epoch 37/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.6977\n",
      "Epoch 38/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.6934\n",
      "Epoch 39/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.6937\n",
      "Epoch 40/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.6892\n",
      "Epoch 41/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.6902\n",
      "Epoch 42/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.6852\n",
      "Epoch 43/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.6854\n",
      "Epoch 44/100\n",
      "8/8 - 0s - 9ms/step - loss: 0.6815\n",
      "Epoch 45/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.6799\n",
      "Epoch 46/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.6783\n",
      "Epoch 47/100\n",
      "8/8 - 0s - 9ms/step - loss: 0.6786\n",
      "Epoch 48/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.6792\n",
      "Epoch 49/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.6743\n",
      "Epoch 50/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.6741\n",
      "Epoch 51/100\n",
      "8/8 - 0s - 9ms/step - loss: 0.6730\n",
      "Epoch 52/100\n",
      "8/8 - 0s - 9ms/step - loss: 0.6708\n",
      "Epoch 53/100\n",
      "8/8 - 0s - 9ms/step - loss: 0.6703\n",
      "Epoch 54/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.6698\n",
      "Epoch 55/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.6678\n",
      "Epoch 56/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.6666\n",
      "Epoch 57/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.6660\n",
      "Epoch 58/100\n",
      "8/8 - 0s - 9ms/step - loss: 0.6654\n",
      "Epoch 59/100\n",
      "8/8 - 0s - 9ms/step - loss: 0.6638\n",
      "Epoch 60/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.6614\n",
      "Epoch 61/100\n",
      "8/8 - 0s - 8ms/step - loss: 0.6614\n",
      "Epoch 62/100\n",
      "8/8 - 0s - 10ms/step - loss: 0.6598\n",
      "Epoch 63/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.6584\n",
      "Epoch 64/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.6571\n",
      "Epoch 65/100\n",
      "8/8 - 0s - 7ms/step - loss: 0.6565\n",
      "Epoch 66/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.6576\n",
      "Epoch 67/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6560\n",
      "Epoch 68/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6568\n",
      "Epoch 69/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6515\n",
      "Epoch 70/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6531\n",
      "Epoch 71/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.6522\n",
      "Epoch 72/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6490\n",
      "Epoch 73/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6476\n",
      "Epoch 74/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6510\n",
      "Epoch 75/100\n",
      "8/8 - 0s - 14ms/step - loss: 0.6471\n",
      "Epoch 76/100\n",
      "8/8 - 0s - 9ms/step - loss: 0.6470\n",
      "Epoch 77/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6467\n",
      "Epoch 78/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6452\n",
      "Epoch 79/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6456\n",
      "Epoch 80/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6423\n",
      "Epoch 81/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6439\n",
      "Epoch 82/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6409\n",
      "Epoch 83/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6426\n",
      "Epoch 84/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6388\n",
      "Epoch 85/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6418\n",
      "Epoch 86/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6421\n",
      "Epoch 87/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6387\n",
      "Epoch 88/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6416\n",
      "Epoch 89/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6387\n",
      "Epoch 90/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6378\n",
      "Epoch 91/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.6395\n",
      "Epoch 92/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6356\n",
      "Epoch 93/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6354\n",
      "Epoch 94/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.6365\n",
      "Epoch 95/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6343\n",
      "Epoch 96/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6348\n",
      "Epoch 97/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6317\n",
      "Epoch 98/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6316\n",
      "Epoch 99/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.6310\n",
      "Epoch 100/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6306\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Testing with layers=[128, 64], encoding_dim=12, batch_size=128, epochs=100, dropout_rate=0.3\n",
      "Data shape: (1000, 20)\n",
      "Epoch 1/100\n",
      "8/8 - 1s - 136ms/step - loss: 1.2797\n",
      "Epoch 2/100\n",
      "8/8 - 0s - 2ms/step - loss: 1.1800\n",
      "Epoch 3/100\n",
      "8/8 - 0s - 3ms/step - loss: 1.1103\n",
      "Epoch 4/100\n",
      "8/8 - 0s - 3ms/step - loss: 1.0553\n",
      "Epoch 5/100\n",
      "8/8 - 0s - 3ms/step - loss: 1.0127\n",
      "Epoch 6/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.9793\n",
      "Epoch 7/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.9504\n",
      "Epoch 8/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.9299\n",
      "Epoch 9/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.9110\n",
      "Epoch 10/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8937\n",
      "Epoch 11/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8802\n",
      "Epoch 12/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8669\n",
      "Epoch 13/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8563\n",
      "Epoch 14/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8439\n",
      "Epoch 15/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8346\n",
      "Epoch 16/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8293\n",
      "Epoch 17/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8220\n",
      "Epoch 18/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.8108\n",
      "Epoch 19/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.8055\n",
      "Epoch 20/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7970\n",
      "Epoch 21/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7957\n",
      "Epoch 22/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7868\n",
      "Epoch 23/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7805\n",
      "Epoch 24/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7759\n",
      "Epoch 25/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7711\n",
      "Epoch 26/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7666\n",
      "Epoch 27/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7614\n",
      "Epoch 28/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7581\n",
      "Epoch 29/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7529\n",
      "Epoch 30/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7484\n",
      "Epoch 31/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7452\n",
      "Epoch 32/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7422\n",
      "Epoch 33/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7396\n",
      "Epoch 34/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7376\n",
      "Epoch 35/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7343\n",
      "Epoch 36/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7283\n",
      "Epoch 37/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7269\n",
      "Epoch 38/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7274\n",
      "Epoch 39/100\n",
      "8/8 - 0s - 2ms/step - loss: 0.7211\n",
      "Epoch 40/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7226\n",
      "Epoch 41/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7203\n",
      "Epoch 42/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7167\n",
      "Epoch 43/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7140\n",
      "Epoch 44/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7127\n",
      "Epoch 45/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7132\n",
      "Epoch 46/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7097\n",
      "Epoch 47/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.7081\n",
      "Epoch 48/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.7085\n",
      "Epoch 49/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7072\n",
      "Epoch 50/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7079\n",
      "Epoch 51/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.7014\n",
      "Epoch 52/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7044\n",
      "Epoch 53/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.7024\n",
      "Epoch 54/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6990\n",
      "Epoch 55/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6976\n",
      "Epoch 56/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.6976\n",
      "Epoch 57/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6983\n",
      "Epoch 58/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6962\n",
      "Epoch 59/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6938\n",
      "Epoch 60/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.6932\n",
      "Epoch 61/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6923\n",
      "Epoch 62/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6935\n",
      "Epoch 63/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6899\n",
      "Epoch 64/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.6864\n",
      "Epoch 65/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.6862\n",
      "Epoch 66/100\n",
      "8/8 - 0s - 6ms/step - loss: 0.6873\n",
      "Epoch 67/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.6866\n",
      "Epoch 68/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6887\n",
      "Epoch 69/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6835\n",
      "Epoch 70/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.6838\n",
      "Epoch 71/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6836\n",
      "Epoch 72/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6834\n",
      "Epoch 73/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6803\n",
      "Epoch 74/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6824\n",
      "Epoch 75/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6797\n",
      "Epoch 76/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6805\n",
      "Epoch 77/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.6790\n",
      "Epoch 78/100\n",
      "8/8 - 0s - 5ms/step - loss: 0.6782\n",
      "Epoch 79/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6802\n",
      "Epoch 80/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6787\n",
      "Epoch 81/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6764\n",
      "Epoch 82/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6714\n",
      "Epoch 83/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6773\n",
      "Epoch 84/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6753\n",
      "Epoch 85/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6768\n",
      "Epoch 86/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6747\n",
      "Epoch 87/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6735\n",
      "Epoch 88/100\n",
      "8/8 - 0s - 4ms/step - loss: 0.6708\n",
      "Epoch 89/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6725\n",
      "Epoch 90/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6715\n",
      "Epoch 91/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6721\n",
      "Epoch 92/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6714\n",
      "Epoch 93/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6704\n",
      "Epoch 94/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6669\n",
      "Epoch 95/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6691\n",
      "Epoch 96/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6692\n",
      "Epoch 97/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6676\n",
      "Epoch 98/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6664\n",
      "Epoch 99/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6664\n",
      "Epoch 100/100\n",
      "8/8 - 0s - 3ms/step - loss: 0.6670\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n",
      "Best parameters found: {'layer_sizes': [128, 64], 'encoding_dim': 8, 'batch_size': 64, 'epochs': 100, 'dropout_rate': 0.3} with silhouette score: 0.3412005305290222\n"
     ]
    }
   ],
   "execution_count": 241
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T11:59:33.616175Z",
     "start_time": "2024-07-10T11:59:33.049934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Validate the Best Model\n",
    "best_autoencoder = create_autoencoder(\n",
    "    input_dim=input_dim,\n",
    "    encoding_dim=best_params['encoding_dim'],\n",
    "    layer_sizes=best_params['layer_sizes'],\n",
    "    dropout_rate=best_params['dropout_rate']\n",
    ")"
   ],
   "id": "5793643f99ca8160",
   "outputs": [],
   "execution_count": 262
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:08:46.041377Z",
     "start_time": "2024-07-10T12:08:46.019370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "train_data, test_data = train_test_split(df_scaled, test_size=0.2, random_state=42)"
   ],
   "id": "f3105358317bedd6",
   "outputs": [],
   "execution_count": 273
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:08:47.658806Z",
     "start_time": "2024-07-10T12:08:47.649634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_multiple_autoencoders(num_autoencoders, input_dim, best_params, data):\n",
    "    autoencoders = []\n",
    "    for _ in range(num_autoencoders):\n",
    "        autoencoder = create_autoencoder(\n",
    "            input_dim=input_dim,\n",
    "            encoding_dim=best_params['encoding_dim'],\n",
    "            layer_sizes=best_params['layer_sizes'],\n",
    "            dropout_rate=best_params['dropout_rate']\n",
    "        )\n",
    "        train_autoencoder(autoencoder, data, epochs=best_params['epochs'], batch_size=best_params['batch_size'])\n",
    "        autoencoders.append(autoencoder)\n",
    "    return autoencoders\n"
   ],
   "id": "bfe52ed91da874dd",
   "outputs": [],
   "execution_count": 274
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:08:49.061081Z",
     "start_time": "2024-07-10T12:08:49.044698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def ensemble_encoding(autoencoders, data):\n",
    "    encoded_representations = [get_encoded_data(autoencoder, data) for autoencoder in autoencoders]\n",
    "    combined_encoding = np.mean(encoded_representations, axis=0)\n",
    "    return combined_encoding"
   ],
   "id": "b1c67c60accad9a4",
   "outputs": [],
   "execution_count": 275
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:08:52.535282Z",
     "start_time": "2024-07-10T12:08:52.522568Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def cross_validate_ensemble_model(autoencoder_func, train_data, n_splits=5, num_autoencoders=3):\n",
    "    kf = KFold(n_splits=n_splits)\n",
    "    fold = 1\n",
    "    for train_index, val_index in kf.split(train_data):\n",
    "        kf_train_data, val_data = train_data[train_index], train_data[val_index]\n",
    "        autoencoders = autoencoder_func(num_autoencoders, input_dim, best_params, kf_train_data)\n",
    "        combined_encoding = ensemble_encoding(autoencoders, val_data)\n",
    "        \n",
    "        optimal_clusters_kmeans = find_optimal_clusters(combined_encoding, apply_kmeans_clustering, range(2, 11))\n",
    "        best_labels_kmeans = apply_kmeans_clustering(combined_encoding, optimal_clusters_kmeans)\n",
    "        silhouette_avg_kmeans, davies_bouldin_kmeans = evaluate_clustering(combined_encoding, best_labels_kmeans)\n",
    "        \n",
    "        print(f'Fold {fold} - KMeans Silhouette Score: {silhouette_avg_kmeans}, Davies-Bouldin Score: {davies_bouldin_kmeans}')\n",
    "        \n",
    "        optimal_clusters_agg = find_optimal_clusters(combined_encoding, apply_agglomerative_clustering, range(2, 11))\n",
    "        best_labels_agg = apply_agglomerative_clustering(combined_encoding, optimal_clusters_agg)\n",
    "        silhouette_avg_agg, davies_bouldin_agg = evaluate_clustering(combined_encoding, best_labels_agg)\n",
    "    \n",
    "        print(f'Fold {fold} - Agglomerative Silhouette Score: {silhouette_avg_agg}, Davies-Bouldin Score: {davies_bouldin_agg}')\n",
    "        \n",
    "        fold += 1"
   ],
   "id": "87ebb2c6243d1137",
   "outputs": [],
   "execution_count": 276
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:09:06.699023Z",
     "start_time": "2024-07-10T12:09:06.692295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def autoencoder_func(num_autoencoders, input_dim, best_params, data):\n",
    "    return train_multiple_autoencoders(num_autoencoders, input_dim, best_params, data)"
   ],
   "id": "7481fcba0a815a4",
   "outputs": [],
   "execution_count": 277
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:09:21.202498Z",
     "start_time": "2024-07-10T12:09:20.988630Z"
    }
   },
   "cell_type": "code",
   "source": "cross_validate_ensemble_model(autoencoder_func, train_data)",
   "id": "2176d8896800e399",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index([160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\\n       ...\\n       790, 791, 792, 793, 794, 795, 796, 797, 798, 799],\\n      dtype='int64', name='Field', length=640)] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[278], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mcross_validate_ensemble_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mautoencoder_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_data\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[276], line 5\u001B[0m, in \u001B[0;36mcross_validate_ensemble_model\u001B[0;34m(autoencoder_func, train_data, n_splits, num_autoencoders)\u001B[0m\n\u001B[1;32m      3\u001B[0m fold \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m train_index, val_index \u001B[38;5;129;01min\u001B[39;00m kf\u001B[38;5;241m.\u001B[39msplit(train_data):\n\u001B[0;32m----> 5\u001B[0m     kf_train_data, val_data \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_data\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtrain_index\u001B[49m\u001B[43m]\u001B[49m, train_data[val_index]\n\u001B[1;32m      6\u001B[0m     autoencoders \u001B[38;5;241m=\u001B[39m autoencoder_func(num_autoencoders, input_dim, best_params, kf_train_data)\n\u001B[1;32m      7\u001B[0m     combined_encoding \u001B[38;5;241m=\u001B[39m ensemble_encoding(autoencoders, val_data)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/frame.py:4096\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   4094\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_iterator(key):\n\u001B[1;32m   4095\u001B[0m         key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(key)\n\u001B[0;32m-> 4096\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_indexer_strict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcolumns\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m[\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m   4098\u001B[0m \u001B[38;5;66;03m# take() does not accept boolean indexers\u001B[39;00m\n\u001B[1;32m   4099\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(indexer, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mbool\u001B[39m:\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:6200\u001B[0m, in \u001B[0;36mIndex._get_indexer_strict\u001B[0;34m(self, key, axis_name)\u001B[0m\n\u001B[1;32m   6197\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   6198\u001B[0m     keyarr, indexer, new_indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reindex_non_unique(keyarr)\n\u001B[0;32m-> 6200\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_raise_if_missing\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkeyarr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   6202\u001B[0m keyarr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtake(indexer)\n\u001B[1;32m   6203\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, Index):\n\u001B[1;32m   6204\u001B[0m     \u001B[38;5;66;03m# GH 42790 - Preserve name from an Index\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:6249\u001B[0m, in \u001B[0;36mIndex._raise_if_missing\u001B[0;34m(self, key, indexer, axis_name)\u001B[0m\n\u001B[1;32m   6247\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m nmissing:\n\u001B[1;32m   6248\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m nmissing \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mlen\u001B[39m(indexer):\n\u001B[0;32m-> 6249\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNone of [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m] are in the [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00maxis_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   6251\u001B[0m     not_found \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(ensure_index(key)[missing_mask\u001B[38;5;241m.\u001B[39mnonzero()[\u001B[38;5;241m0\u001B[39m]]\u001B[38;5;241m.\u001B[39munique())\n\u001B[1;32m   6252\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnot_found\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not in index\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mKeyError\u001B[0m: \"None of [Index([160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\\n       ...\\n       790, 791, 792, 793, 794, 795, 796, 797, 798, 799],\\n      dtype='int64', name='Field', length=640)] are in the [columns]\""
     ]
    }
   ],
   "execution_count": 278
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
